{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SYkAbHbfcku-"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2L_yKE1IgpA0"
   },
   "outputs": [],
   "source": [
    "#%autoreload # When utils.py is updated\n",
    "#from utils_unet_resunet import *\n",
    "from ops import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from model.models import Model_3\n",
    "from model.losses import WBCE\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'imgs/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kylt2BueckvP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image stack: (10000, 7000, 24)\n",
      "Labels stack: (10000, 7000)\n"
     ]
    }
   ],
   "source": [
    "# Define data type (L8-Landsat8, S2-Sentinel2, S1-Sentinel1)\n",
    "img_type = 'FUSION'\n",
    "\n",
    "if img_type == 'FUSION':\n",
    "    image_array = np.load(root_path+'New_Images/fus_stack.npy')\n",
    "    \n",
    "\n",
    "if img_type == 'OPT':\n",
    "    image_array = np.load(root_path+'New_Images/opt_stack.npy')\n",
    "    \n",
    "    \n",
    "if img_type == 'SAR':\n",
    "    image_array = np.load(root_path+'New_Images/sar_stack.npy')\n",
    "print('Image stack:', image_array.shape)\n",
    "\n",
    "final_mask1 = np.load(root_path+'New_Images/'+'final_mask1.npy')\n",
    "print('Labels stack:', final_mask1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_x = 4000\n",
    "lim_y = 2800\n",
    "image_array = image_array[:lim_x, :lim_y, :]\n",
    "final_mask1 = final_mask1[:lim_x, :lim_y]\n",
    "h_, w_, channels = image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "knelmZc2HRTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:  (4000, 2800)\n",
      "image stack:  (4000, 2800, 24)\n",
      "ref : (4000, 2800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ce7c0d0ac0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create tile mask\n",
    "mask_tiles = create_mask(final_mask1.shape[0], final_mask1.shape[1], grid_size=(5, 4))\n",
    "image_array = image_array[:mask_tiles.shape[0], :mask_tiles.shape[1],:]\n",
    "final_mask1 = final_mask1[:mask_tiles.shape[0], :mask_tiles.shape[1]]\n",
    "\n",
    "print('mask: ',mask_tiles.shape)\n",
    "print('image stack: ', image_array.shape)\n",
    "print('ref :', final_mask1.shape)\n",
    "plt.imshow(mask_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gExq8XOCckvb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ce8271dbe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(final_mask1, cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OKaXQmmGoxLz"
   },
   "outputs": [],
   "source": [
    "# Define tiles for training, validation, and test sets\n",
    "tiles_tr = [1,3,5,8,11,13,14,20]\n",
    "tiles_val = [6,19]\n",
    "tiles_ts = (list(set(np.arange(20)+1)-set(tiles_tr)-set(tiles_val)))\n",
    "\n",
    "mask_tr_val = np.zeros((mask_tiles.shape)).astype('float32')\n",
    "# Training and validation mask\n",
    "for tr_ in tiles_tr:\n",
    "    mask_tr_val[mask_tiles == tr_] = 1\n",
    "\n",
    "for val_ in tiles_val:\n",
    "    mask_tr_val[mask_tiles == val_] = 2\n",
    "\n",
    "mask_amazon_ts = np.zeros((mask_tiles.shape)).astype('float32')\n",
    "for ts_ in tiles_ts:\n",
    "    mask_amazon_ts[mask_tiles == ts_] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QI8Gc-NQrr44"
   },
   "outputs": [],
   "source": [
    "# Create ixd image to extract patches\n",
    "overlap = 0.7\n",
    "patch_size = 128\n",
    "batch_size = 32\n",
    "im_idx = create_idx_image(final_mask1)\n",
    "\n",
    "patches_idx = extract_patches(im_idx, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1,patch_size, patch_size) #ndice do pixel de cada patch\n",
    "patches_mask = extract_patches(mask_tr_val, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1, patch_size, patch_size) #1 se pixel for de treinamento 2 se for val\n",
    "del im_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1V39Gf4owRBa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training patches:   2237 Number of validation patches 510\n"
     ]
    }
   ],
   "source": [
    "# Selecting index trn val and test patches idx\n",
    "idx_trn = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==patch_size**2)) #extrai apenas idx dos patches com todos os valores == 1 (train)\n",
    "idx_val = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==2*patch_size**2)) #extrai apenas idx dos patches com todos os valores == 2 (val)\n",
    "del patches_mask\n",
    "\n",
    "patches_idx_trn = patches_idx[idx_trn]\n",
    "patches_idx_val = patches_idx[idx_val]\n",
    "del idx_trn, idx_val\n",
    "\n",
    "print('Number of training patches:  ', len(patches_idx_trn), 'Number of validation patches', len(patches_idx_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ycpxzOJblJvr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 128, 128) (15, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Extract patches with at least 2% of deforestation class\n",
    "X_train = retrieve_idx_percentage(final_mask1, patches_idx_trn, patch_size, pertentage = 2)\n",
    "X_valid = retrieve_idx_percentage(final_mask1, patches_idx_val, patch_size, pertentage = 2)\n",
    "print(X_train.shape, X_valid.shape)\n",
    "del patches_idx_trn, patches_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(horizontal_flip = True,\n",
    "                                   vertical_flip = True)\n",
    "valid_datagen = ImageDataGenerator(horizontal_flip = True, \n",
    "                                   vertical_flip = True)\n",
    "\n",
    "Y_train = np.zeros_like(X_train)\n",
    "Y_valid = np.zeros_like(X_valid)\n",
    "\n",
    "train_gen = train_datagen.flow(np.expand_dims(X_train, axis = -1), Y_train,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_gen = valid_datagen.flow(np.expand_dims(X_valid, axis = -1), Y_valid,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "number_class = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batches, image, reference, target_size, number_class):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    image = image.reshape(-1, image.shape[-1])\n",
    "    reference = reference.reshape(final_mask1.shape[0]*final_mask1.shape[1])\n",
    "    while True:\n",
    "        batch_x, _ = next(batches)\n",
    "        batch_x = np.squeeze(batch_x.astype('int64'))\n",
    "        #print(batch_x.shape)\n",
    "        batch_img = np.zeros((batch_x.shape[0], target_size, target_size, image.shape[-1]))\n",
    "        batch_ref = np.zeros((batch_x.shape[0], target_size, target_size, number_class))\n",
    "        \n",
    "        for i in range(batch_x.shape[0]):\n",
    "            if np.random.rand()>0.5:\n",
    "                batch_x[i] = np.rot90(batch_x[i], 1)\n",
    "            batch_img[i] = image[batch_x[i]] \n",
    "            batch_ref[i] = to_categorical(reference[batch_x[i]] , number_class)\n",
    "                       \n",
    "        yield (batch_img, batch_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_crops = batch_generator(train_gen, image_array, final_mask1, patch_size, number_class)\n",
    "valid_gen_crops = batch_generator(valid_gen, image_array, final_mask1, patch_size, number_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QfJK-atSgFTG"
   },
   "outputs": [],
   "source": [
    "exp = 3\n",
    "path_exp = root_path+'experiments/exp'+str(exp)\n",
    "path_models = path_exp+'/models'\n",
    "path_maps = path_exp+'/pred_maps'\n",
    "\n",
    "if not os.path.exists(path_exp):\n",
    "    os.makedirs(path_exp)   \n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)   \n",
    "if not os.path.exists(path_maps):\n",
    "    os.makedirs(path_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ol_1Ci3TlbrM"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "input_shape = (patch_size, patch_size, channels)\n",
    "nb_filters = [2, 4, 8]\n",
    "\n",
    "method = 'unet'\n",
    "n_opt_layers = 20\n",
    "model = Model_3(nb_filters, number_class, n_opt_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s4Ql8N-flPbi"
   },
   "outputs": [],
   "source": [
    "# Parameters of the model\n",
    "weights = [0.2, 0.8, 0]\n",
    "adam = Adam(lr = 1e-3 , beta_1=0.9)\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "loss = WBCE(weights = weights)\n",
    "#loss = WBCE(weights = weights, class_indexes = [0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "568DB3nZLrHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0\n",
      "Model: \"model_3_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "opt_encoder (UNET_Encoder)   multiple                  2486      \n",
      "_________________________________________________________________\n",
      "sar_encoder (UNET_Encoder)   multiple                  2198      \n",
      "_________________________________________________________________\n",
      "opt_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "sar_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "opt_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "sar_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "fus_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "combination (CombinationLaye multiple                  3         \n",
      "_________________________________________________________________\n",
      "opt_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "opt_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7229 - sar_accuracy: 0.5944 - fus_accuracy: 0.7131 - opt_loss: 0.1521 - sar_loss: 0.1703 - fus_loss: 0.1613 - loss: 0.4836\n",
      "Epoch 00001: val_loss improved from inf to 0.34655, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 4s 239ms/step - opt_accuracy: 0.7229 - sar_accuracy: 0.5944 - fus_accuracy: 0.7131 - opt_loss: 0.1521 - sar_loss: 0.1703 - fus_loss: 0.1613 - loss: 0.4836 - val_opt_accuracy: 0.7147 - val_sar_accuracy: 0.6813 - val_fus_accuracy: 0.7066 - val_opt_loss: 0.1166 - val_sar_loss: 0.1154 - val_fus_loss: 0.1145 - val_loss: 0.3465\n",
      "Epoch 2/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.7932 - sar_accuracy: 0.6464 - fus_accuracy: 0.7780 - opt_loss: 0.1302 - sar_loss: 0.1522 - fus_loss: 0.1443 - loss: 0.4267\n",
      "Epoch 00002: val_loss improved from 0.34655 to 0.33526, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.7932 - sar_accuracy: 0.6462 - fus_accuracy: 0.7778 - opt_loss: 0.1318 - sar_loss: 0.1546 - fus_loss: 0.1468 - loss: 0.4333 - val_opt_accuracy: 0.7441 - val_sar_accuracy: 0.6930 - val_fus_accuracy: 0.7178 - val_opt_loss: 0.1096 - val_sar_loss: 0.1177 - val_fus_loss: 0.1080 - val_loss: 0.3353\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7976 - sar_accuracy: 0.6825 - fus_accuracy: 0.7500 - opt_loss: 0.1281 - sar_loss: 0.1439 - fus_loss: 0.1380 - loss: 0.4099\n",
      "Epoch 00003: val_loss improved from 0.33526 to 0.33234, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.7976 - sar_accuracy: 0.6825 - fus_accuracy: 0.7500 - opt_loss: 0.1281 - sar_loss: 0.1439 - fus_loss: 0.1380 - loss: 0.4099 - val_opt_accuracy: 0.7437 - val_sar_accuracy: 0.6932 - val_fus_accuracy: 0.7249 - val_opt_loss: 0.1094 - val_sar_loss: 0.1174 - val_fus_loss: 0.1055 - val_loss: 0.3323\n",
      "Epoch 4/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.7972 - sar_accuracy: 0.6924 - fus_accuracy: 0.7808 - opt_loss: 0.1185 - sar_loss: 0.1346 - fus_loss: 0.1217 - loss: 0.3748\n",
      "Epoch 00004: val_loss improved from 0.33234 to 0.32321, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.7979 - sar_accuracy: 0.6923 - fus_accuracy: 0.7815 - opt_loss: 0.1157 - sar_loss: 0.1330 - fus_loss: 0.1188 - loss: 0.3675 - val_opt_accuracy: 0.7441 - val_sar_accuracy: 0.6931 - val_fus_accuracy: 0.7321 - val_opt_loss: 0.1006 - val_sar_loss: 0.1203 - val_fus_loss: 0.1023 - val_loss: 0.3232\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8054 - sar_accuracy: 0.6961 - fus_accuracy: 0.7942 - opt_loss: 0.1184 - sar_loss: 0.1417 - fus_loss: 0.1251 - loss: 0.3853\n",
      "Epoch 00005: val_loss improved from 0.32321 to 0.32052, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8054 - sar_accuracy: 0.6961 - fus_accuracy: 0.7942 - opt_loss: 0.1184 - sar_loss: 0.1417 - fus_loss: 0.1251 - loss: 0.3853 - val_opt_accuracy: 0.7988 - val_sar_accuracy: 0.6978 - val_fus_accuracy: 0.7426 - val_opt_loss: 0.0977 - val_sar_loss: 0.1191 - val_fus_loss: 0.1037 - val_loss: 0.3205\n",
      "Epoch 6/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8532 - sar_accuracy: 0.7081 - fus_accuracy: 0.8007 - opt_loss: 0.1060 - sar_loss: 0.1337 - fus_loss: 0.1150 - loss: 0.3547\n",
      "Epoch 00006: val_loss improved from 0.32052 to 0.31372, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8536 - sar_accuracy: 0.7080 - fus_accuracy: 0.8014 - opt_loss: 0.1052 - sar_loss: 0.1340 - fus_loss: 0.1140 - loss: 0.3531 - val_opt_accuracy: 0.8225 - val_sar_accuracy: 0.6992 - val_fus_accuracy: 0.7607 - val_opt_loss: 0.0951 - val_sar_loss: 0.1172 - val_fus_loss: 0.1014 - val_loss: 0.3137\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8623 - sar_accuracy: 0.7101 - fus_accuracy: 0.8198 - opt_loss: 0.1073 - sar_loss: 0.1373 - fus_loss: 0.1149 - loss: 0.3595\n",
      "Epoch 00007: val_loss improved from 0.31372 to 0.31222, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8623 - sar_accuracy: 0.7101 - fus_accuracy: 0.8198 - opt_loss: 0.1073 - sar_loss: 0.1373 - fus_loss: 0.1149 - loss: 0.3595 - val_opt_accuracy: 0.8324 - val_sar_accuracy: 0.7025 - val_fus_accuracy: 0.7888 - val_opt_loss: 0.0973 - val_sar_loss: 0.1158 - val_fus_loss: 0.0991 - val_loss: 0.3122\n",
      "Epoch 8/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8684 - sar_accuracy: 0.7320 - fus_accuracy: 0.8377 - opt_loss: 0.0994 - sar_loss: 0.1300 - fus_loss: 0.1061 - loss: 0.3355\n",
      "Epoch 00008: val_loss improved from 0.31222 to 0.30336, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8686 - sar_accuracy: 0.7321 - fus_accuracy: 0.8380 - opt_loss: 0.0982 - sar_loss: 0.1292 - fus_loss: 0.1047 - loss: 0.3322 - val_opt_accuracy: 0.8377 - val_sar_accuracy: 0.7057 - val_fus_accuracy: 0.8165 - val_opt_loss: 0.0933 - val_sar_loss: 0.1163 - val_fus_loss: 0.0937 - val_loss: 0.3034\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8688 - sar_accuracy: 0.7358 - fus_accuracy: 0.8514 - opt_loss: 0.0956 - sar_loss: 0.1294 - fus_loss: 0.0996 - loss: 0.3246\n",
      "Epoch 00009: val_loss improved from 0.30336 to 0.28132, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 128ms/step - opt_accuracy: 0.8688 - sar_accuracy: 0.7358 - fus_accuracy: 0.8514 - opt_loss: 0.0956 - sar_loss: 0.1294 - fus_loss: 0.0996 - loss: 0.3246 - val_opt_accuracy: 0.8367 - val_sar_accuracy: 0.7119 - val_fus_accuracy: 0.8256 - val_opt_loss: 0.0821 - val_sar_loss: 0.1142 - val_fus_loss: 0.0850 - val_loss: 0.2813\n",
      "Epoch 10/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8669 - sar_accuracy: 0.7365 - fus_accuracy: 0.8537 - opt_loss: 0.1015 - sar_loss: 0.1360 - fus_loss: 0.1052 - loss: 0.3427\n",
      "Epoch 00010: val_loss did not improve from 0.28132\n",
      "15/15 [==============================] - 2s 112ms/step - opt_accuracy: 0.8668 - sar_accuracy: 0.7362 - fus_accuracy: 0.8536 - opt_loss: 0.1043 - sar_loss: 0.1394 - fus_loss: 0.1078 - loss: 0.3514 - val_opt_accuracy: 0.8393 - val_sar_accuracy: 0.7049 - val_fus_accuracy: 0.8332 - val_opt_loss: 0.0886 - val_sar_loss: 0.1164 - val_fus_loss: 0.0864 - val_loss: 0.2914\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8722 - sar_accuracy: 0.7401 - fus_accuracy: 0.8618 - opt_loss: 0.0942 - sar_loss: 0.1295 - fus_loss: 0.0964 - loss: 0.3201\n",
      "Epoch 00011: val_loss improved from 0.28132 to 0.27999, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8722 - sar_accuracy: 0.7401 - fus_accuracy: 0.8618 - opt_loss: 0.0942 - sar_loss: 0.1295 - fus_loss: 0.0964 - loss: 0.3201 - val_opt_accuracy: 0.8449 - val_sar_accuracy: 0.7115 - val_fus_accuracy: 0.8380 - val_opt_loss: 0.0832 - val_sar_loss: 0.1152 - val_fus_loss: 0.0816 - val_loss: 0.2800\n",
      "Epoch 12/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8707 - sar_accuracy: 0.7491 - fus_accuracy: 0.8644 - opt_loss: 0.0978 - sar_loss: 0.1344 - fus_loss: 0.0997 - loss: 0.3319\n",
      "Epoch 00012: val_loss did not improve from 0.27999\n",
      "15/15 [==============================] - 2s 111ms/step - opt_accuracy: 0.8697 - sar_accuracy: 0.7486 - fus_accuracy: 0.8635 - opt_loss: 0.1030 - sar_loss: 0.1401 - fus_loss: 0.1048 - loss: 0.3478 - val_opt_accuracy: 0.8406 - val_sar_accuracy: 0.7080 - val_fus_accuracy: 0.8394 - val_opt_loss: 0.0872 - val_sar_loss: 0.1166 - val_fus_loss: 0.0813 - val_loss: 0.2851\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8737 - sar_accuracy: 0.7370 - fus_accuracy: 0.8687 - opt_loss: 0.0920 - sar_loss: 0.1308 - fus_loss: 0.0925 - loss: 0.3154\n",
      "Epoch 00013: val_loss improved from 0.27999 to 0.27461, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8737 - sar_accuracy: 0.7370 - fus_accuracy: 0.8687 - opt_loss: 0.0920 - sar_loss: 0.1308 - fus_loss: 0.0925 - loss: 0.3154 - val_opt_accuracy: 0.8449 - val_sar_accuracy: 0.7124 - val_fus_accuracy: 0.8392 - val_opt_loss: 0.0783 - val_sar_loss: 0.1171 - val_fus_loss: 0.0792 - val_loss: 0.2746\n",
      "Epoch 14/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8729 - sar_accuracy: 0.7613 - fus_accuracy: 0.8698 - opt_loss: 0.0908 - sar_loss: 0.1292 - fus_loss: 0.0913 - loss: 0.3114\n",
      "Epoch 00014: val_loss did not improve from 0.27461\n",
      "15/15 [==============================] - 2s 111ms/step - opt_accuracy: 0.8731 - sar_accuracy: 0.7615 - fus_accuracy: 0.8701 - opt_loss: 0.0883 - sar_loss: 0.1264 - fus_loss: 0.0887 - loss: 0.3035 - val_opt_accuracy: 0.8457 - val_sar_accuracy: 0.7157 - val_fus_accuracy: 0.8416 - val_opt_loss: 0.0850 - val_sar_loss: 0.1150 - val_fus_loss: 0.0816 - val_loss: 0.2816\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8736 - sar_accuracy: 0.7571 - fus_accuracy: 0.8705 - opt_loss: 0.0942 - sar_loss: 0.1330 - fus_loss: 0.0947 - loss: 0.3220\n",
      "Epoch 00015: val_loss improved from 0.27461 to 0.27093, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8736 - sar_accuracy: 0.7571 - fus_accuracy: 0.8705 - opt_loss: 0.0942 - sar_loss: 0.1330 - fus_loss: 0.0947 - loss: 0.3220 - val_opt_accuracy: 0.8428 - val_sar_accuracy: 0.7197 - val_fus_accuracy: 0.8423 - val_opt_loss: 0.0803 - val_sar_loss: 0.1132 - val_fus_loss: 0.0775 - val_loss: 0.2709\n",
      "Epoch 16/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8780 - sar_accuracy: 0.7704 - fus_accuracy: 0.8753 - opt_loss: 0.0861 - sar_loss: 0.1262 - fus_loss: 0.0860 - loss: 0.2983\n",
      "Epoch 00016: val_loss improved from 0.27093 to 0.26847, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8783 - sar_accuracy: 0.7708 - fus_accuracy: 0.8756 - opt_loss: 0.0854 - sar_loss: 0.1254 - fus_loss: 0.0852 - loss: 0.2960 - val_opt_accuracy: 0.8465 - val_sar_accuracy: 0.7216 - val_fus_accuracy: 0.8425 - val_opt_loss: 0.0775 - val_sar_loss: 0.1139 - val_fus_loss: 0.0771 - val_loss: 0.2685\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8778 - sar_accuracy: 0.7674 - fus_accuracy: 0.8762 - opt_loss: 0.0897 - sar_loss: 0.1321 - fus_loss: 0.0905 - loss: 0.3123\n",
      "Epoch 00017: val_loss did not improve from 0.26847\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8778 - sar_accuracy: 0.7674 - fus_accuracy: 0.8762 - opt_loss: 0.0897 - sar_loss: 0.1321 - fus_loss: 0.0905 - loss: 0.3123 - val_opt_accuracy: 0.8469 - val_sar_accuracy: 0.7228 - val_fus_accuracy: 0.8441 - val_opt_loss: 0.0845 - val_sar_loss: 0.1132 - val_fus_loss: 0.0805 - val_loss: 0.2782\n",
      "Epoch 18/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8792 - sar_accuracy: 0.7730 - fus_accuracy: 0.8790 - opt_loss: 0.0874 - sar_loss: 0.1300 - fus_loss: 0.0869 - loss: 0.3044\n",
      "Epoch 00018: val_loss improved from 0.26847 to 0.25932, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 121ms/step - opt_accuracy: 0.8795 - sar_accuracy: 0.7734 - fus_accuracy: 0.8792 - opt_loss: 0.0865 - sar_loss: 0.1284 - fus_loss: 0.0859 - loss: 0.3009 - val_opt_accuracy: 0.8494 - val_sar_accuracy: 0.7198 - val_fus_accuracy: 0.8448 - val_opt_loss: 0.0708 - val_sar_loss: 0.1149 - val_fus_loss: 0.0736 - val_loss: 0.2593\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8812 - sar_accuracy: 0.7770 - fus_accuracy: 0.8815 - opt_loss: 0.0837 - sar_loss: 0.1285 - fus_loss: 0.0840 - loss: 0.2962\n",
      "Epoch 00019: val_loss did not improve from 0.25932\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8812 - sar_accuracy: 0.7770 - fus_accuracy: 0.8815 - opt_loss: 0.0837 - sar_loss: 0.1285 - fus_loss: 0.0840 - loss: 0.2962 - val_opt_accuracy: 0.8484 - val_sar_accuracy: 0.7246 - val_fus_accuracy: 0.8485 - val_opt_loss: 0.0740 - val_sar_loss: 0.1127 - val_fus_loss: 0.0730 - val_loss: 0.2597\n",
      "Epoch 20/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8825 - sar_accuracy: 0.7792 - fus_accuracy: 0.8823 - opt_loss: 0.0784 - sar_loss: 0.1252 - fus_loss: 0.0790 - loss: 0.2827\n",
      "Epoch 00020: val_loss improved from 0.25932 to 0.25370, saving model to imgs/experiments/exp3/models\\unet_0.h5\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8825 - sar_accuracy: 0.7790 - fus_accuracy: 0.8823 - opt_loss: 0.0788 - sar_loss: 0.1255 - fus_loss: 0.0789 - loss: 0.2832 - val_opt_accuracy: 0.8516 - val_sar_accuracy: 0.7274 - val_fus_accuracy: 0.8490 - val_opt_loss: 0.0710 - val_sar_loss: 0.1122 - val_fus_loss: 0.0706 - val_loss: 0.2537\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8885 - sar_accuracy: 0.7790 - fus_accuracy: 0.8858 - opt_loss: 0.0792 - sar_loss: 0.1278 - fus_loss: 0.0799 - loss: 0.2868\n",
      "Epoch 00021: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8885 - sar_accuracy: 0.7790 - fus_accuracy: 0.8858 - opt_loss: 0.0792 - sar_loss: 0.1278 - fus_loss: 0.0799 - loss: 0.2868 - val_opt_accuracy: 0.8512 - val_sar_accuracy: 0.7188 - val_fus_accuracy: 0.8496 - val_opt_loss: 0.0734 - val_sar_loss: 0.1142 - val_fus_loss: 0.0743 - val_loss: 0.2619\n",
      "Epoch 22/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8848 - sar_accuracy: 0.7808 - fus_accuracy: 0.8844 - opt_loss: 0.0805 - sar_loss: 0.1276 - fus_loss: 0.0798 - loss: 0.2879\n",
      "Epoch 00022: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 111ms/step - opt_accuracy: 0.8849 - sar_accuracy: 0.7809 - fus_accuracy: 0.8845 - opt_loss: 0.0788 - sar_loss: 0.1243 - fus_loss: 0.0782 - loss: 0.2814 - val_opt_accuracy: 0.8510 - val_sar_accuracy: 0.7232 - val_fus_accuracy: 0.8482 - val_opt_loss: 0.0805 - val_sar_loss: 0.1148 - val_fus_loss: 0.0814 - val_loss: 0.2767\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8864 - sar_accuracy: 0.7784 - fus_accuracy: 0.8862 - opt_loss: 0.0798 - sar_loss: 0.1290 - fus_loss: 0.0800 - loss: 0.2887\n",
      "Epoch 00023: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8864 - sar_accuracy: 0.7784 - fus_accuracy: 0.8862 - opt_loss: 0.0798 - sar_loss: 0.1290 - fus_loss: 0.0800 - loss: 0.2887 - val_opt_accuracy: 0.8498 - val_sar_accuracy: 0.7203 - val_fus_accuracy: 0.8501 - val_opt_loss: 0.0737 - val_sar_loss: 0.1166 - val_fus_loss: 0.0746 - val_loss: 0.2649\n",
      "Epoch 24/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8901 - sar_accuracy: 0.7773 - fus_accuracy: 0.8897 - opt_loss: 0.0800 - sar_loss: 0.1336 - fus_loss: 0.0801 - loss: 0.2937\n",
      "Epoch 00024: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 112ms/step - opt_accuracy: 0.8903 - sar_accuracy: 0.7776 - fus_accuracy: 0.8898 - opt_loss: 0.0794 - sar_loss: 0.1332 - fus_loss: 0.0796 - loss: 0.2923 - val_opt_accuracy: 0.8519 - val_sar_accuracy: 0.7195 - val_fus_accuracy: 0.8505 - val_opt_loss: 0.0724 - val_sar_loss: 0.1175 - val_fus_loss: 0.0749 - val_loss: 0.2648\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8898 - sar_accuracy: 0.7825 - fus_accuracy: 0.8894 - opt_loss: 0.0767 - sar_loss: 0.1270 - fus_loss: 0.0768 - loss: 0.2805\n",
      "Epoch 00025: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8898 - sar_accuracy: 0.7825 - fus_accuracy: 0.8894 - opt_loss: 0.0767 - sar_loss: 0.1270 - fus_loss: 0.0768 - loss: 0.2805 - val_opt_accuracy: 0.8531 - val_sar_accuracy: 0.7220 - val_fus_accuracy: 0.8496 - val_opt_loss: 0.0777 - val_sar_loss: 0.1165 - val_fus_loss: 0.0799 - val_loss: 0.2742\n",
      "Epoch 26/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8902 - sar_accuracy: 0.7765 - fus_accuracy: 0.8888 - opt_loss: 0.0768 - sar_loss: 0.1324 - fus_loss: 0.0771 - loss: 0.2864\n",
      "Epoch 00026: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 115ms/step - opt_accuracy: 0.8902 - sar_accuracy: 0.7767 - fus_accuracy: 0.8887 - opt_loss: 0.0776 - sar_loss: 0.1312 - fus_loss: 0.0779 - loss: 0.2866 - val_opt_accuracy: 0.8517 - val_sar_accuracy: 0.7181 - val_fus_accuracy: 0.8464 - val_opt_loss: 0.0774 - val_sar_loss: 0.1204 - val_fus_loss: 0.0818 - val_loss: 0.2796\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8861 - sar_accuracy: 0.7794 - fus_accuracy: 0.8854 - opt_loss: 0.0805 - sar_loss: 0.1282 - fus_loss: 0.0802 - loss: 0.2889\n",
      "Epoch 00027: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8861 - sar_accuracy: 0.7794 - fus_accuracy: 0.8854 - opt_loss: 0.0805 - sar_loss: 0.1282 - fus_loss: 0.0802 - loss: 0.2889 - val_opt_accuracy: 0.8512 - val_sar_accuracy: 0.7200 - val_fus_accuracy: 0.8490 - val_opt_loss: 0.0819 - val_sar_loss: 0.1195 - val_fus_loss: 0.0841 - val_loss: 0.2856\n",
      "Epoch 28/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8895 - sar_accuracy: 0.7836 - fus_accuracy: 0.8894 - opt_loss: 0.0763 - sar_loss: 0.1292 - fus_loss: 0.0764 - loss: 0.2818\n",
      "Epoch 00028: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 113ms/step - opt_accuracy: 0.8894 - sar_accuracy: 0.7835 - fus_accuracy: 0.8895 - opt_loss: 0.0751 - sar_loss: 0.1264 - fus_loss: 0.0749 - loss: 0.2764 - val_opt_accuracy: 0.8516 - val_sar_accuracy: 0.7233 - val_fus_accuracy: 0.8497 - val_opt_loss: 0.0751 - val_sar_loss: 0.1168 - val_fus_loss: 0.0771 - val_loss: 0.2689\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8929 - sar_accuracy: 0.7833 - fus_accuracy: 0.8919 - opt_loss: 0.0730 - sar_loss: 0.1247 - fus_loss: 0.0724 - loss: 0.2701\n",
      "Epoch 00029: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8929 - sar_accuracy: 0.7833 - fus_accuracy: 0.8919 - opt_loss: 0.0730 - sar_loss: 0.1247 - fus_loss: 0.0724 - loss: 0.2701 - val_opt_accuracy: 0.8493 - val_sar_accuracy: 0.7264 - val_fus_accuracy: 0.8461 - val_opt_loss: 0.0777 - val_sar_loss: 0.1154 - val_fus_loss: 0.0798 - val_loss: 0.2728\n",
      "Epoch 30/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8904 - sar_accuracy: 0.7872 - fus_accuracy: 0.8904 - opt_loss: 0.0736 - sar_loss: 0.1239 - fus_loss: 0.0735 - loss: 0.2710\n",
      "Epoch 00030: val_loss did not improve from 0.25370\n",
      "15/15 [==============================] - 2s 113ms/step - opt_accuracy: 0.8904 - sar_accuracy: 0.7874 - fus_accuracy: 0.8904 - opt_loss: 0.0729 - sar_loss: 0.1225 - fus_loss: 0.0729 - loss: 0.2683 - val_opt_accuracy: 0.8487 - val_sar_accuracy: 0.7267 - val_fus_accuracy: 0.8478 - val_opt_loss: 0.0732 - val_sar_loss: 0.1182 - val_fus_loss: 0.0744 - val_loss: 0.2658\n",
      "Epoch 00030: early stopping\n",
      "time:  1\n",
      "Model: \"model_3_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "opt_encoder (UNET_Encoder)   multiple                  2486      \n",
      "_________________________________________________________________\n",
      "sar_encoder (UNET_Encoder)   multiple                  2198      \n",
      "_________________________________________________________________\n",
      "opt_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "sar_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "opt_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "sar_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "fus_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "combination (CombinationLaye multiple                  3         \n",
      "_________________________________________________________________\n",
      "opt_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "opt_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7679 - sar_accuracy: 0.6494 - fus_accuracy: 0.8222 - opt_loss: 0.1302 - sar_loss: 0.1909 - fus_loss: 0.1268 - loss: 0.4479\n",
      "Epoch 00001: val_loss improved from inf to 0.37951, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 158ms/step - opt_accuracy: 0.7679 - sar_accuracy: 0.6494 - fus_accuracy: 0.8222 - opt_loss: 0.1302 - sar_loss: 0.1909 - fus_loss: 0.1268 - loss: 0.4479 - val_opt_accuracy: 0.6517 - val_sar_accuracy: 0.6729 - val_fus_accuracy: 0.8190 - val_opt_loss: 0.1138 - val_sar_loss: 0.1710 - val_fus_loss: 0.0947 - val_loss: 0.3795\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7367 - sar_accuracy: 0.7119 - fus_accuracy: 0.8619 - opt_loss: 0.1210 - sar_loss: 0.1657 - fus_loss: 0.1055 - loss: 0.3923\n",
      "Epoch 00002: val_loss improved from 0.37951 to 0.35125, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.7367 - sar_accuracy: 0.7119 - fus_accuracy: 0.8619 - opt_loss: 0.1210 - sar_loss: 0.1657 - fus_loss: 0.1055 - loss: 0.3923 - val_opt_accuracy: 0.6752 - val_sar_accuracy: 0.6156 - val_fus_accuracy: 0.8368 - val_opt_loss: 0.1104 - val_sar_loss: 0.1501 - val_fus_loss: 0.0908 - val_loss: 0.3513\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7435 - sar_accuracy: 0.7087 - fus_accuracy: 0.8643 - opt_loss: 0.1217 - sar_loss: 0.1529 - fus_loss: 0.1030 - loss: 0.3776\n",
      "Epoch 00003: val_loss improved from 0.35125 to 0.34318, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.7435 - sar_accuracy: 0.7087 - fus_accuracy: 0.8643 - opt_loss: 0.1217 - sar_loss: 0.1529 - fus_loss: 0.1030 - loss: 0.3776 - val_opt_accuracy: 0.6660 - val_sar_accuracy: 0.6156 - val_fus_accuracy: 0.8383 - val_opt_loss: 0.1082 - val_sar_loss: 0.1467 - val_fus_loss: 0.0883 - val_loss: 0.3432\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7509 - sar_accuracy: 0.7111 - fus_accuracy: 0.8687 - opt_loss: 0.1146 - sar_loss: 0.1483 - fus_loss: 0.0993 - loss: 0.3623\n",
      "Epoch 00004: val_loss improved from 0.34318 to 0.34296, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.7509 - sar_accuracy: 0.7111 - fus_accuracy: 0.8687 - opt_loss: 0.1146 - sar_loss: 0.1483 - fus_loss: 0.0993 - loss: 0.3623 - val_opt_accuracy: 0.6629 - val_sar_accuracy: 0.6156 - val_fus_accuracy: 0.8343 - val_opt_loss: 0.1086 - val_sar_loss: 0.1442 - val_fus_loss: 0.0902 - val_loss: 0.3430\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7352 - sar_accuracy: 0.7065 - fus_accuracy: 0.8726 - opt_loss: 0.1152 - sar_loss: 0.1499 - fus_loss: 0.0957 - loss: 0.3609\n",
      "Epoch 00005: val_loss improved from 0.34296 to 0.34054, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.7352 - sar_accuracy: 0.7065 - fus_accuracy: 0.8726 - opt_loss: 0.1152 - sar_loss: 0.1499 - fus_loss: 0.0957 - loss: 0.3609 - val_opt_accuracy: 0.6506 - val_sar_accuracy: 0.6169 - val_fus_accuracy: 0.8320 - val_opt_loss: 0.1086 - val_sar_loss: 0.1427 - val_fus_loss: 0.0893 - val_loss: 0.3405\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7427 - sar_accuracy: 0.7191 - fus_accuracy: 0.8728 - opt_loss: 0.1102 - sar_loss: 0.1492 - fus_loss: 0.0953 - loss: 0.3547\n",
      "Epoch 00006: val_loss improved from 0.34054 to 0.33764, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.7427 - sar_accuracy: 0.7191 - fus_accuracy: 0.8728 - opt_loss: 0.1102 - sar_loss: 0.1492 - fus_loss: 0.0953 - loss: 0.3547 - val_opt_accuracy: 0.6475 - val_sar_accuracy: 0.6189 - val_fus_accuracy: 0.8312 - val_opt_loss: 0.1079 - val_sar_loss: 0.1413 - val_fus_loss: 0.0885 - val_loss: 0.3376\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7393 - sar_accuracy: 0.7100 - fus_accuracy: 0.8765 - opt_loss: 0.1087 - sar_loss: 0.1509 - fus_loss: 0.0954 - loss: 0.3550\n",
      "Epoch 00007: val_loss improved from 0.33764 to 0.33183, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.7393 - sar_accuracy: 0.7100 - fus_accuracy: 0.8765 - opt_loss: 0.1087 - sar_loss: 0.1509 - fus_loss: 0.0954 - loss: 0.3550 - val_opt_accuracy: 0.6500 - val_sar_accuracy: 0.6177 - val_fus_accuracy: 0.8337 - val_opt_loss: 0.1059 - val_sar_loss: 0.1385 - val_fus_loss: 0.0875 - val_loss: 0.3318\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7469 - sar_accuracy: 0.7112 - fus_accuracy: 0.8795 - opt_loss: 0.1026 - sar_loss: 0.1464 - fus_loss: 0.0898 - loss: 0.3388\n",
      "Epoch 00008: val_loss improved from 0.33183 to 0.32638, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.7469 - sar_accuracy: 0.7112 - fus_accuracy: 0.8795 - opt_loss: 0.1026 - sar_loss: 0.1464 - fus_loss: 0.0898 - loss: 0.3388 - val_opt_accuracy: 0.6615 - val_sar_accuracy: 0.6167 - val_fus_accuracy: 0.8341 - val_opt_loss: 0.1026 - val_sar_loss: 0.1366 - val_fus_loss: 0.0872 - val_loss: 0.3264\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7531 - sar_accuracy: 0.7117 - fus_accuracy: 0.8793 - opt_loss: 0.1010 - sar_loss: 0.1440 - fus_loss: 0.0873 - loss: 0.3323\n",
      "Epoch 00009: val_loss improved from 0.32638 to 0.32128, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.7531 - sar_accuracy: 0.7117 - fus_accuracy: 0.8793 - opt_loss: 0.1010 - sar_loss: 0.1440 - fus_loss: 0.0873 - loss: 0.3323 - val_opt_accuracy: 0.6961 - val_sar_accuracy: 0.6163 - val_fus_accuracy: 0.8365 - val_opt_loss: 0.0996 - val_sar_loss: 0.1359 - val_fus_loss: 0.0857 - val_loss: 0.3213\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7727 - sar_accuracy: 0.7176 - fus_accuracy: 0.8850 - opt_loss: 0.0918 - sar_loss: 0.1397 - fus_loss: 0.0793 - loss: 0.3109\n",
      "Epoch 00010: val_loss did not improve from 0.32128\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.7727 - sar_accuracy: 0.7176 - fus_accuracy: 0.8850 - opt_loss: 0.0918 - sar_loss: 0.1397 - fus_loss: 0.0793 - loss: 0.3109 - val_opt_accuracy: 0.6483 - val_sar_accuracy: 0.6163 - val_fus_accuracy: 0.8360 - val_opt_loss: 0.1012 - val_sar_loss: 0.1348 - val_fus_loss: 0.0879 - val_loss: 0.3239\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7676 - sar_accuracy: 0.7148 - fus_accuracy: 0.8867 - opt_loss: 0.0927 - sar_loss: 0.1417 - fus_loss: 0.0829 - loss: 0.3174\n",
      "Epoch 00011: val_loss did not improve from 0.32128\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.7676 - sar_accuracy: 0.7148 - fus_accuracy: 0.8867 - opt_loss: 0.0927 - sar_loss: 0.1417 - fus_loss: 0.0829 - loss: 0.3174 - val_opt_accuracy: 0.6469 - val_sar_accuracy: 0.6173 - val_fus_accuracy: 0.8370 - val_opt_loss: 0.1007 - val_sar_loss: 0.1334 - val_fus_loss: 0.0882 - val_loss: 0.3224\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7771 - sar_accuracy: 0.7154 - fus_accuracy: 0.8827 - opt_loss: 0.0979 - sar_loss: 0.1509 - fus_loss: 0.0861 - loss: 0.3349\n",
      "Epoch 00012: val_loss did not improve from 0.32128\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.7771 - sar_accuracy: 0.7154 - fus_accuracy: 0.8827 - opt_loss: 0.0979 - sar_loss: 0.1509 - fus_loss: 0.0861 - loss: 0.3349 - val_opt_accuracy: 0.6681 - val_sar_accuracy: 0.6295 - val_fus_accuracy: 0.8358 - val_opt_loss: 0.1005 - val_sar_loss: 0.1332 - val_fus_loss: 0.0886 - val_loss: 0.3223\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8090 - sar_accuracy: 0.7178 - fus_accuracy: 0.8846 - opt_loss: 0.0897 - sar_loss: 0.1413 - fus_loss: 0.0801 - loss: 0.3111\n",
      "Epoch 00013: val_loss improved from 0.32128 to 0.31188, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8090 - sar_accuracy: 0.7178 - fus_accuracy: 0.8846 - opt_loss: 0.0897 - sar_loss: 0.1413 - fus_loss: 0.0801 - loss: 0.3111 - val_opt_accuracy: 0.7493 - val_sar_accuracy: 0.6237 - val_fus_accuracy: 0.8377 - val_opt_loss: 0.0927 - val_sar_loss: 0.1302 - val_fus_loss: 0.0890 - val_loss: 0.3119\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8428 - sar_accuracy: 0.7206 - fus_accuracy: 0.8842 - opt_loss: 0.0868 - sar_loss: 0.1392 - fus_loss: 0.0817 - loss: 0.3077\n",
      "Epoch 00014: val_loss improved from 0.31188 to 0.30653, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8428 - sar_accuracy: 0.7206 - fus_accuracy: 0.8842 - opt_loss: 0.0868 - sar_loss: 0.1392 - fus_loss: 0.0817 - loss: 0.3077 - val_opt_accuracy: 0.7970 - val_sar_accuracy: 0.6287 - val_fus_accuracy: 0.8372 - val_opt_loss: 0.0891 - val_sar_loss: 0.1290 - val_fus_loss: 0.0884 - val_loss: 0.3065\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8658 - sar_accuracy: 0.7286 - fus_accuracy: 0.8872 - opt_loss: 0.0844 - sar_loss: 0.1401 - fus_loss: 0.0788 - loss: 0.3033\n",
      "Epoch 00015: val_loss improved from 0.30653 to 0.30310, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8658 - sar_accuracy: 0.7286 - fus_accuracy: 0.8872 - opt_loss: 0.0844 - sar_loss: 0.1401 - fus_loss: 0.0788 - loss: 0.3033 - val_opt_accuracy: 0.8191 - val_sar_accuracy: 0.6453 - val_fus_accuracy: 0.8377 - val_opt_loss: 0.0881 - val_sar_loss: 0.1286 - val_fus_loss: 0.0863 - val_loss: 0.3031\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8774 - sar_accuracy: 0.7377 - fus_accuracy: 0.8876 - opt_loss: 0.0806 - sar_loss: 0.1344 - fus_loss: 0.0771 - loss: 0.2921\n",
      "Epoch 00016: val_loss did not improve from 0.30310\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8774 - sar_accuracy: 0.7377 - fus_accuracy: 0.8876 - opt_loss: 0.0806 - sar_loss: 0.1344 - fus_loss: 0.0771 - loss: 0.2921 - val_opt_accuracy: 0.8246 - val_sar_accuracy: 0.6320 - val_fus_accuracy: 0.8385 - val_opt_loss: 0.0898 - val_sar_loss: 0.1267 - val_fus_loss: 0.0895 - val_loss: 0.3060\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8831 - sar_accuracy: 0.7470 - fus_accuracy: 0.8882 - opt_loss: 0.0823 - sar_loss: 0.1461 - fus_loss: 0.0810 - loss: 0.3093\n",
      "Epoch 00017: val_loss did not improve from 0.30310\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8831 - sar_accuracy: 0.7470 - fus_accuracy: 0.8882 - opt_loss: 0.0823 - sar_loss: 0.1461 - fus_loss: 0.0810 - loss: 0.3093 - val_opt_accuracy: 0.8266 - val_sar_accuracy: 0.6761 - val_fus_accuracy: 0.8366 - val_opt_loss: 0.0886 - val_sar_loss: 0.1263 - val_fus_loss: 0.0890 - val_loss: 0.3038\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8835 - sar_accuracy: 0.7537 - fus_accuracy: 0.8865 - opt_loss: 0.0808 - sar_loss: 0.1370 - fus_loss: 0.0796 - loss: 0.2974\n",
      "Epoch 00018: val_loss improved from 0.30310 to 0.29588, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8835 - sar_accuracy: 0.7537 - fus_accuracy: 0.8865 - opt_loss: 0.0808 - sar_loss: 0.1370 - fus_loss: 0.0796 - loss: 0.2974 - val_opt_accuracy: 0.8307 - val_sar_accuracy: 0.6722 - val_fus_accuracy: 0.8401 - val_opt_loss: 0.0878 - val_sar_loss: 0.1222 - val_fus_loss: 0.0859 - val_loss: 0.2959\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8822 - sar_accuracy: 0.7739 - fus_accuracy: 0.8844 - opt_loss: 0.0860 - sar_loss: 0.1368 - fus_loss: 0.0846 - loss: 0.3074\n",
      "Epoch 00019: val_loss improved from 0.29588 to 0.28941, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8822 - sar_accuracy: 0.7739 - fus_accuracy: 0.8844 - opt_loss: 0.0860 - sar_loss: 0.1368 - fus_loss: 0.0846 - loss: 0.3074 - val_opt_accuracy: 0.8369 - val_sar_accuracy: 0.6850 - val_fus_accuracy: 0.8420 - val_opt_loss: 0.0822 - val_sar_loss: 0.1198 - val_fus_loss: 0.0875 - val_loss: 0.2894\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8857 - sar_accuracy: 0.7864 - fus_accuracy: 0.8862 - opt_loss: 0.0823 - sar_loss: 0.1333 - fus_loss: 0.0812 - loss: 0.2968\n",
      "Epoch 00020: val_loss improved from 0.28941 to 0.28696, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8857 - sar_accuracy: 0.7864 - fus_accuracy: 0.8862 - opt_loss: 0.0823 - sar_loss: 0.1333 - fus_loss: 0.0812 - loss: 0.2968 - val_opt_accuracy: 0.8342 - val_sar_accuracy: 0.7223 - val_fus_accuracy: 0.8365 - val_opt_loss: 0.0813 - val_sar_loss: 0.1172 - val_fus_loss: 0.0884 - val_loss: 0.2870\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8849 - sar_accuracy: 0.7906 - fus_accuracy: 0.8846 - opt_loss: 0.0768 - sar_loss: 0.1266 - fus_loss: 0.0775 - loss: 0.2808\n",
      "Epoch 00021: val_loss did not improve from 0.28696\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8849 - sar_accuracy: 0.7906 - fus_accuracy: 0.8846 - opt_loss: 0.0768 - sar_loss: 0.1266 - fus_loss: 0.0775 - loss: 0.2808 - val_opt_accuracy: 0.8340 - val_sar_accuracy: 0.7181 - val_fus_accuracy: 0.8390 - val_opt_loss: 0.0885 - val_sar_loss: 0.1139 - val_fus_loss: 0.0908 - val_loss: 0.2932\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8888 - sar_accuracy: 0.8009 - fus_accuracy: 0.8900 - opt_loss: 0.0744 - sar_loss: 0.1234 - fus_loss: 0.0742 - loss: 0.2720\n",
      "Epoch 00022: val_loss improved from 0.28696 to 0.28414, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8888 - sar_accuracy: 0.8009 - fus_accuracy: 0.8900 - opt_loss: 0.0744 - sar_loss: 0.1234 - fus_loss: 0.0742 - loss: 0.2720 - val_opt_accuracy: 0.8357 - val_sar_accuracy: 0.7309 - val_fus_accuracy: 0.8384 - val_opt_loss: 0.0834 - val_sar_loss: 0.1122 - val_fus_loss: 0.0885 - val_loss: 0.2841\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8905 - sar_accuracy: 0.8009 - fus_accuracy: 0.8918 - opt_loss: 0.0750 - sar_loss: 0.1260 - fus_loss: 0.0753 - loss: 0.2763\n",
      "Epoch 00023: val_loss improved from 0.28414 to 0.27827, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8905 - sar_accuracy: 0.8009 - fus_accuracy: 0.8918 - opt_loss: 0.0750 - sar_loss: 0.1260 - fus_loss: 0.0753 - loss: 0.2763 - val_opt_accuracy: 0.8381 - val_sar_accuracy: 0.7324 - val_fus_accuracy: 0.8415 - val_opt_loss: 0.0812 - val_sar_loss: 0.1112 - val_fus_loss: 0.0859 - val_loss: 0.2783\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8908 - sar_accuracy: 0.8032 - fus_accuracy: 0.8905 - opt_loss: 0.0735 - sar_loss: 0.1219 - fus_loss: 0.0739 - loss: 0.2692\n",
      "Epoch 00024: val_loss did not improve from 0.27827\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8908 - sar_accuracy: 0.8032 - fus_accuracy: 0.8905 - opt_loss: 0.0735 - sar_loss: 0.1219 - fus_loss: 0.0739 - loss: 0.2692 - val_opt_accuracy: 0.8358 - val_sar_accuracy: 0.7385 - val_fus_accuracy: 0.8386 - val_opt_loss: 0.0855 - val_sar_loss: 0.1102 - val_fus_loss: 0.0885 - val_loss: 0.2842\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8927 - sar_accuracy: 0.8033 - fus_accuracy: 0.8922 - opt_loss: 0.0748 - sar_loss: 0.1271 - fus_loss: 0.0754 - loss: 0.2773\n",
      "Epoch 00025: val_loss did not improve from 0.27827\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8927 - sar_accuracy: 0.8033 - fus_accuracy: 0.8922 - opt_loss: 0.0748 - sar_loss: 0.1271 - fus_loss: 0.0754 - loss: 0.2773 - val_opt_accuracy: 0.8361 - val_sar_accuracy: 0.7384 - val_fus_accuracy: 0.8378 - val_opt_loss: 0.0828 - val_sar_loss: 0.1102 - val_fus_loss: 0.0880 - val_loss: 0.2810\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8934 - sar_accuracy: 0.8005 - fus_accuracy: 0.8940 - opt_loss: 0.0721 - sar_loss: 0.1252 - fus_loss: 0.0726 - loss: 0.2700\n",
      "Epoch 00026: val_loss did not improve from 0.27827\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8934 - sar_accuracy: 0.8005 - fus_accuracy: 0.8940 - opt_loss: 0.0721 - sar_loss: 0.1252 - fus_loss: 0.0726 - loss: 0.2700 - val_opt_accuracy: 0.8369 - val_sar_accuracy: 0.7370 - val_fus_accuracy: 0.8381 - val_opt_loss: 0.0821 - val_sar_loss: 0.1101 - val_fus_loss: 0.0878 - val_loss: 0.2800\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8929 - sar_accuracy: 0.8027 - fus_accuracy: 0.8913 - opt_loss: 0.0729 - sar_loss: 0.1263 - fus_loss: 0.0740 - loss: 0.2733\n",
      "Epoch 00027: val_loss did not improve from 0.27827\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8929 - sar_accuracy: 0.8027 - fus_accuracy: 0.8913 - opt_loss: 0.0729 - sar_loss: 0.1263 - fus_loss: 0.0740 - loss: 0.2733 - val_opt_accuracy: 0.8356 - val_sar_accuracy: 0.7378 - val_fus_accuracy: 0.8393 - val_opt_loss: 0.0892 - val_sar_loss: 0.1099 - val_fus_loss: 0.0890 - val_loss: 0.2881\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8954 - sar_accuracy: 0.8045 - fus_accuracy: 0.8952 - opt_loss: 0.0686 - sar_loss: 0.1204 - fus_loss: 0.0692 - loss: 0.2581\n",
      "Epoch 00028: val_loss improved from 0.27827 to 0.27572, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 128ms/step - opt_accuracy: 0.8954 - sar_accuracy: 0.8045 - fus_accuracy: 0.8952 - opt_loss: 0.0686 - sar_loss: 0.1204 - fus_loss: 0.0692 - loss: 0.2581 - val_opt_accuracy: 0.8384 - val_sar_accuracy: 0.7441 - val_fus_accuracy: 0.8387 - val_opt_loss: 0.0793 - val_sar_loss: 0.1098 - val_fus_loss: 0.0866 - val_loss: 0.2757\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8942 - sar_accuracy: 0.8031 - fus_accuracy: 0.8938 - opt_loss: 0.0692 - sar_loss: 0.1204 - fus_loss: 0.0704 - loss: 0.2600\n",
      "Epoch 00029: val_loss did not improve from 0.27572\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8942 - sar_accuracy: 0.8031 - fus_accuracy: 0.8938 - opt_loss: 0.0692 - sar_loss: 0.1204 - fus_loss: 0.0704 - loss: 0.2600 - val_opt_accuracy: 0.8383 - val_sar_accuracy: 0.7435 - val_fus_accuracy: 0.8408 - val_opt_loss: 0.0889 - val_sar_loss: 0.1095 - val_fus_loss: 0.0879 - val_loss: 0.2863\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8965 - sar_accuracy: 0.8048 - fus_accuracy: 0.8953 - opt_loss: 0.0700 - sar_loss: 0.1254 - fus_loss: 0.0714 - loss: 0.2669\n",
      "Epoch 00030: val_loss did not improve from 0.27572\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8965 - sar_accuracy: 0.8048 - fus_accuracy: 0.8953 - opt_loss: 0.0700 - sar_loss: 0.1254 - fus_loss: 0.0714 - loss: 0.2669 - val_opt_accuracy: 0.8396 - val_sar_accuracy: 0.7396 - val_fus_accuracy: 0.8430 - val_opt_loss: 0.0891 - val_sar_loss: 0.1093 - val_fus_loss: 0.0869 - val_loss: 0.2852\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8935 - sar_accuracy: 0.8036 - fus_accuracy: 0.8937 - opt_loss: 0.0728 - sar_loss: 0.1324 - fus_loss: 0.0737 - loss: 0.2788\n",
      "Epoch 00031: val_loss did not improve from 0.27572\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8935 - sar_accuracy: 0.8036 - fus_accuracy: 0.8937 - opt_loss: 0.0728 - sar_loss: 0.1324 - fus_loss: 0.0737 - loss: 0.2788 - val_opt_accuracy: 0.8388 - val_sar_accuracy: 0.7467 - val_fus_accuracy: 0.8401 - val_opt_loss: 0.0867 - val_sar_loss: 0.1107 - val_fus_loss: 0.0875 - val_loss: 0.2849\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8950 - sar_accuracy: 0.8038 - fus_accuracy: 0.8938 - opt_loss: 0.0725 - sar_loss: 0.1275 - fus_loss: 0.0732 - loss: 0.2731\n",
      "Epoch 00032: val_loss improved from 0.27572 to 0.27151, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 134ms/step - opt_accuracy: 0.8950 - sar_accuracy: 0.8038 - fus_accuracy: 0.8938 - opt_loss: 0.0725 - sar_loss: 0.1275 - fus_loss: 0.0732 - loss: 0.2731 - val_opt_accuracy: 0.8404 - val_sar_accuracy: 0.7427 - val_fus_accuracy: 0.8405 - val_opt_loss: 0.0774 - val_sar_loss: 0.1102 - val_fus_loss: 0.0839 - val_loss: 0.2715\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8962 - sar_accuracy: 0.8058 - fus_accuracy: 0.8951 - opt_loss: 0.0697 - sar_loss: 0.1279 - fus_loss: 0.0706 - loss: 0.2682\n",
      "Epoch 00033: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8962 - sar_accuracy: 0.8058 - fus_accuracy: 0.8951 - opt_loss: 0.0697 - sar_loss: 0.1279 - fus_loss: 0.0706 - loss: 0.2682 - val_opt_accuracy: 0.8383 - val_sar_accuracy: 0.7405 - val_fus_accuracy: 0.8379 - val_opt_loss: 0.0819 - val_sar_loss: 0.1117 - val_fus_loss: 0.0883 - val_loss: 0.2820\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8879 - sar_accuracy: 0.8067 - fus_accuracy: 0.8865 - opt_loss: 0.0815 - sar_loss: 0.1309 - fus_loss: 0.0841 - loss: 0.2965\n",
      "Epoch 00034: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8879 - sar_accuracy: 0.8067 - fus_accuracy: 0.8865 - opt_loss: 0.0815 - sar_loss: 0.1309 - fus_loss: 0.0841 - loss: 0.2965 - val_opt_accuracy: 0.8406 - val_sar_accuracy: 0.7402 - val_fus_accuracy: 0.8397 - val_opt_loss: 0.0806 - val_sar_loss: 0.1107 - val_fus_loss: 0.0830 - val_loss: 0.2743\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8942 - sar_accuracy: 0.8062 - fus_accuracy: 0.8937 - opt_loss: 0.0718 - sar_loss: 0.1207 - fus_loss: 0.0717 - loss: 0.2642\n",
      "Epoch 00035: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8942 - sar_accuracy: 0.8062 - fus_accuracy: 0.8937 - opt_loss: 0.0718 - sar_loss: 0.1207 - fus_loss: 0.0717 - loss: 0.2642 - val_opt_accuracy: 0.8396 - val_sar_accuracy: 0.7315 - val_fus_accuracy: 0.8397 - val_opt_loss: 0.0837 - val_sar_loss: 0.1128 - val_fus_loss: 0.0873 - val_loss: 0.2838\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8953 - sar_accuracy: 0.8046 - fus_accuracy: 0.8950 - opt_loss: 0.0677 - sar_loss: 0.1210 - fus_loss: 0.0685 - loss: 0.2571\n",
      "Epoch 00036: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8953 - sar_accuracy: 0.8046 - fus_accuracy: 0.8950 - opt_loss: 0.0677 - sar_loss: 0.1210 - fus_loss: 0.0685 - loss: 0.2571 - val_opt_accuracy: 0.8411 - val_sar_accuracy: 0.7416 - val_fus_accuracy: 0.8409 - val_opt_loss: 0.0805 - val_sar_loss: 0.1104 - val_fus_loss: 0.0836 - val_loss: 0.2745\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8989 - sar_accuracy: 0.8068 - fus_accuracy: 0.8985 - opt_loss: 0.0678 - sar_loss: 0.1238 - fus_loss: 0.0686 - loss: 0.2602\n",
      "Epoch 00037: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8989 - sar_accuracy: 0.8068 - fus_accuracy: 0.8985 - opt_loss: 0.0678 - sar_loss: 0.1238 - fus_loss: 0.0686 - loss: 0.2602 - val_opt_accuracy: 0.8416 - val_sar_accuracy: 0.7505 - val_fus_accuracy: 0.8414 - val_opt_loss: 0.0828 - val_sar_loss: 0.1102 - val_fus_loss: 0.0836 - val_loss: 0.2766\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8986 - sar_accuracy: 0.8088 - fus_accuracy: 0.8982 - opt_loss: 0.0671 - sar_loss: 0.1234 - fus_loss: 0.0679 - loss: 0.2583\n",
      "Epoch 00038: val_loss did not improve from 0.27151\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8986 - sar_accuracy: 0.8088 - fus_accuracy: 0.8982 - opt_loss: 0.0671 - sar_loss: 0.1234 - fus_loss: 0.0679 - loss: 0.2583 - val_opt_accuracy: 0.8428 - val_sar_accuracy: 0.7421 - val_fus_accuracy: 0.8430 - val_opt_loss: 0.0793 - val_sar_loss: 0.1106 - val_fus_loss: 0.0817 - val_loss: 0.2716\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8971 - sar_accuracy: 0.8082 - fus_accuracy: 0.8970 - opt_loss: 0.0679 - sar_loss: 0.1238 - fus_loss: 0.0689 - loss: 0.2606\n",
      "Epoch 00039: val_loss improved from 0.27151 to 0.26732, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8971 - sar_accuracy: 0.8082 - fus_accuracy: 0.8970 - opt_loss: 0.0679 - sar_loss: 0.1238 - fus_loss: 0.0689 - loss: 0.2606 - val_opt_accuracy: 0.8446 - val_sar_accuracy: 0.7475 - val_fus_accuracy: 0.8438 - val_opt_loss: 0.0762 - val_sar_loss: 0.1111 - val_fus_loss: 0.0801 - val_loss: 0.2673\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8971 - sar_accuracy: 0.8119 - fus_accuracy: 0.8966 - opt_loss: 0.0685 - sar_loss: 0.1195 - fus_loss: 0.0696 - loss: 0.2576\n",
      "Epoch 00040: val_loss improved from 0.26732 to 0.26318, saving model to imgs/experiments/exp3/models\\unet_1.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8971 - sar_accuracy: 0.8119 - fus_accuracy: 0.8966 - opt_loss: 0.0685 - sar_loss: 0.1195 - fus_loss: 0.0696 - loss: 0.2576 - val_opt_accuracy: 0.8461 - val_sar_accuracy: 0.7497 - val_fus_accuracy: 0.8451 - val_opt_loss: 0.0751 - val_sar_loss: 0.1097 - val_fus_loss: 0.0784 - val_loss: 0.2632\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8982 - sar_accuracy: 0.8082 - fus_accuracy: 0.8977 - opt_loss: 0.0661 - sar_loss: 0.1208 - fus_loss: 0.0667 - loss: 0.2535\n",
      "Epoch 00041: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8982 - sar_accuracy: 0.8082 - fus_accuracy: 0.8977 - opt_loss: 0.0661 - sar_loss: 0.1208 - fus_loss: 0.0667 - loss: 0.2535 - val_opt_accuracy: 0.8426 - val_sar_accuracy: 0.7487 - val_fus_accuracy: 0.8422 - val_opt_loss: 0.0809 - val_sar_loss: 0.1097 - val_fus_loss: 0.0823 - val_loss: 0.2728\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9002 - sar_accuracy: 0.8113 - fus_accuracy: 0.8998 - opt_loss: 0.0639 - sar_loss: 0.1214 - fus_loss: 0.0644 - loss: 0.2497\n",
      "Epoch 00042: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.9002 - sar_accuracy: 0.8113 - fus_accuracy: 0.8998 - opt_loss: 0.0639 - sar_loss: 0.1214 - fus_loss: 0.0644 - loss: 0.2497 - val_opt_accuracy: 0.8437 - val_sar_accuracy: 0.7578 - val_fus_accuracy: 0.8431 - val_opt_loss: 0.0792 - val_sar_loss: 0.1098 - val_fus_loss: 0.0805 - val_loss: 0.2695\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9015 - sar_accuracy: 0.8140 - fus_accuracy: 0.9006 - opt_loss: 0.0644 - sar_loss: 0.1226 - fus_loss: 0.0645 - loss: 0.2515\n",
      "Epoch 00043: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.9015 - sar_accuracy: 0.8140 - fus_accuracy: 0.9006 - opt_loss: 0.0644 - sar_loss: 0.1226 - fus_loss: 0.0645 - loss: 0.2515 - val_opt_accuracy: 0.8433 - val_sar_accuracy: 0.7467 - val_fus_accuracy: 0.8427 - val_opt_loss: 0.0824 - val_sar_loss: 0.1102 - val_fus_loss: 0.0818 - val_loss: 0.2744\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9013 - sar_accuracy: 0.8097 - fus_accuracy: 0.9008 - opt_loss: 0.0640 - sar_loss: 0.1238 - fus_loss: 0.0644 - loss: 0.2522\n",
      "Epoch 00044: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.9013 - sar_accuracy: 0.8097 - fus_accuracy: 0.9008 - opt_loss: 0.0640 - sar_loss: 0.1238 - fus_loss: 0.0644 - loss: 0.2522 - val_opt_accuracy: 0.8405 - val_sar_accuracy: 0.7268 - val_fus_accuracy: 0.8408 - val_opt_loss: 0.0867 - val_sar_loss: 0.1176 - val_fus_loss: 0.0870 - val_loss: 0.2913\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8996 - sar_accuracy: 0.8140 - fus_accuracy: 0.8991 - opt_loss: 0.0667 - sar_loss: 0.1204 - fus_loss: 0.0675 - loss: 0.2546\n",
      "Epoch 00045: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8996 - sar_accuracy: 0.8140 - fus_accuracy: 0.8991 - opt_loss: 0.0667 - sar_loss: 0.1204 - fus_loss: 0.0675 - loss: 0.2546 - val_opt_accuracy: 0.8425 - val_sar_accuracy: 0.7504 - val_fus_accuracy: 0.8423 - val_opt_loss: 0.0842 - val_sar_loss: 0.1090 - val_fus_loss: 0.0833 - val_loss: 0.2765\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8980 - sar_accuracy: 0.8135 - fus_accuracy: 0.8974 - opt_loss: 0.0668 - sar_loss: 0.1232 - fus_loss: 0.0669 - loss: 0.2569\n",
      "Epoch 00046: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8980 - sar_accuracy: 0.8135 - fus_accuracy: 0.8974 - opt_loss: 0.0668 - sar_loss: 0.1232 - fus_loss: 0.0669 - loss: 0.2569 - val_opt_accuracy: 0.8442 - val_sar_accuracy: 0.7488 - val_fus_accuracy: 0.8434 - val_opt_loss: 0.0801 - val_sar_loss: 0.1113 - val_fus_loss: 0.0808 - val_loss: 0.2721\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9021 - sar_accuracy: 0.8167 - fus_accuracy: 0.9012 - opt_loss: 0.0633 - sar_loss: 0.1182 - fus_loss: 0.0641 - loss: 0.2456\n",
      "Epoch 00047: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.9021 - sar_accuracy: 0.8167 - fus_accuracy: 0.9012 - opt_loss: 0.0633 - sar_loss: 0.1182 - fus_loss: 0.0641 - loss: 0.2456 - val_opt_accuracy: 0.8433 - val_sar_accuracy: 0.7588 - val_fus_accuracy: 0.8439 - val_opt_loss: 0.0787 - val_sar_loss: 0.1082 - val_fus_loss: 0.0788 - val_loss: 0.2657\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9017 - sar_accuracy: 0.8187 - fus_accuracy: 0.9004 - opt_loss: 0.0623 - sar_loss: 0.1139 - fus_loss: 0.0630 - loss: 0.2392\n",
      "Epoch 00048: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.9017 - sar_accuracy: 0.8187 - fus_accuracy: 0.9004 - opt_loss: 0.0623 - sar_loss: 0.1139 - fus_loss: 0.0630 - loss: 0.2392 - val_opt_accuracy: 0.8455 - val_sar_accuracy: 0.7625 - val_fus_accuracy: 0.8445 - val_opt_loss: 0.0802 - val_sar_loss: 0.1089 - val_fus_loss: 0.0796 - val_loss: 0.2687\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9010 - sar_accuracy: 0.8178 - fus_accuracy: 0.9003 - opt_loss: 0.0652 - sar_loss: 0.1174 - fus_loss: 0.0656 - loss: 0.2481\n",
      "Epoch 00049: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.9010 - sar_accuracy: 0.8178 - fus_accuracy: 0.9003 - opt_loss: 0.0652 - sar_loss: 0.1174 - fus_loss: 0.0656 - loss: 0.2481 - val_opt_accuracy: 0.8436 - val_sar_accuracy: 0.7484 - val_fus_accuracy: 0.8429 - val_opt_loss: 0.0784 - val_sar_loss: 0.1116 - val_fus_loss: 0.0798 - val_loss: 0.2697\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9019 - sar_accuracy: 0.8128 - fus_accuracy: 0.9009 - opt_loss: 0.0659 - sar_loss: 0.1301 - fus_loss: 0.0662 - loss: 0.2622\n",
      "Epoch 00050: val_loss did not improve from 0.26318\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.9019 - sar_accuracy: 0.8128 - fus_accuracy: 0.9009 - opt_loss: 0.0659 - sar_loss: 0.1301 - fus_loss: 0.0662 - loss: 0.2622 - val_opt_accuracy: 0.8412 - val_sar_accuracy: 0.7491 - val_fus_accuracy: 0.8403 - val_opt_loss: 0.0788 - val_sar_loss: 0.1150 - val_fus_loss: 0.0801 - val_loss: 0.2740\n",
      "Epoch 00050: early stopping\n",
      "time:  2\n",
      "Model: \"model_3_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "opt_encoder (UNET_Encoder)   multiple                  2486      \n",
      "_________________________________________________________________\n",
      "sar_encoder (UNET_Encoder)   multiple                  2198      \n",
      "_________________________________________________________________\n",
      "opt_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "sar_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "opt_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "sar_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "fus_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "combination (CombinationLaye multiple                  3         \n",
      "_________________________________________________________________\n",
      "opt_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "opt_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7433 - sar_accuracy: 0.5898 - fus_accuracy: 0.7165 - opt_loss: 0.1513 - sar_loss: 0.2518 - fus_loss: 0.1567 - loss: 0.5598\n",
      "Epoch 00001: val_loss improved from inf to 0.42131, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 145ms/step - opt_accuracy: 0.7433 - sar_accuracy: 0.5898 - fus_accuracy: 0.7165 - opt_loss: 0.1513 - sar_loss: 0.2518 - fus_loss: 0.1567 - loss: 0.5598 - val_opt_accuracy: 0.8223 - val_sar_accuracy: 0.6043 - val_fus_accuracy: 0.8144 - val_opt_loss: 0.0932 - val_sar_loss: 0.2114 - val_fus_loss: 0.1167 - val_loss: 0.4213\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8557 - sar_accuracy: 0.6187 - fus_accuracy: 0.8420 - opt_loss: 0.1137 - sar_loss: 0.2140 - fus_loss: 0.1236 - loss: 0.4512\n",
      "Epoch 00002: val_loss improved from 0.42131 to 0.39288, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 141ms/step - opt_accuracy: 0.8557 - sar_accuracy: 0.6187 - fus_accuracy: 0.8420 - opt_loss: 0.1137 - sar_loss: 0.2140 - fus_loss: 0.1236 - loss: 0.4512 - val_opt_accuracy: 0.8258 - val_sar_accuracy: 0.6253 - val_fus_accuracy: 0.8203 - val_opt_loss: 0.0881 - val_sar_loss: 0.1926 - val_fus_loss: 0.1121 - val_loss: 0.3929\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8646 - sar_accuracy: 0.6324 - fus_accuracy: 0.8574 - opt_loss: 0.1057 - sar_loss: 0.2033 - fus_loss: 0.1102 - loss: 0.4192\n",
      "Epoch 00003: val_loss improved from 0.39288 to 0.37919, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8646 - sar_accuracy: 0.6324 - fus_accuracy: 0.8574 - opt_loss: 0.1057 - sar_loss: 0.2033 - fus_loss: 0.1102 - loss: 0.4192 - val_opt_accuracy: 0.8298 - val_sar_accuracy: 0.6352 - val_fus_accuracy: 0.8225 - val_opt_loss: 0.0887 - val_sar_loss: 0.1847 - val_fus_loss: 0.1057 - val_loss: 0.3792\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8711 - sar_accuracy: 0.6406 - fus_accuracy: 0.8605 - opt_loss: 0.1029 - sar_loss: 0.1943 - fus_loss: 0.1067 - loss: 0.4039\n",
      "Epoch 00004: val_loss improved from 0.37919 to 0.37243, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8711 - sar_accuracy: 0.6406 - fus_accuracy: 0.8605 - opt_loss: 0.1029 - sar_loss: 0.1943 - fus_loss: 0.1067 - loss: 0.4039 - val_opt_accuracy: 0.8360 - val_sar_accuracy: 0.6447 - val_fus_accuracy: 0.8235 - val_opt_loss: 0.0892 - val_sar_loss: 0.1789 - val_fus_loss: 0.1043 - val_loss: 0.3724\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8693 - sar_accuracy: 0.6492 - fus_accuracy: 0.8603 - opt_loss: 0.1072 - sar_loss: 0.1923 - fus_loss: 0.1096 - loss: 0.4091\n",
      "Epoch 00005: val_loss improved from 0.37243 to 0.35966, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8693 - sar_accuracy: 0.6492 - fus_accuracy: 0.8603 - opt_loss: 0.1072 - sar_loss: 0.1923 - fus_loss: 0.1096 - loss: 0.4091 - val_opt_accuracy: 0.8322 - val_sar_accuracy: 0.6529 - val_fus_accuracy: 0.8234 - val_opt_loss: 0.0880 - val_sar_loss: 0.1736 - val_fus_loss: 0.0980 - val_loss: 0.3597\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8724 - sar_accuracy: 0.6561 - fus_accuracy: 0.8637 - opt_loss: 0.1004 - sar_loss: 0.1857 - fus_loss: 0.1027 - loss: 0.3888\n",
      "Epoch 00006: val_loss improved from 0.35966 to 0.35589, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8724 - sar_accuracy: 0.6561 - fus_accuracy: 0.8637 - opt_loss: 0.1004 - sar_loss: 0.1857 - fus_loss: 0.1027 - loss: 0.3888 - val_opt_accuracy: 0.8378 - val_sar_accuracy: 0.6583 - val_fus_accuracy: 0.8266 - val_opt_loss: 0.0886 - val_sar_loss: 0.1690 - val_fus_loss: 0.0982 - val_loss: 0.3559\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8742 - sar_accuracy: 0.6604 - fus_accuracy: 0.8651 - opt_loss: 0.1030 - sar_loss: 0.1823 - fus_loss: 0.1053 - loss: 0.3906\n",
      "Epoch 00007: val_loss improved from 0.35589 to 0.35139, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 134ms/step - opt_accuracy: 0.8742 - sar_accuracy: 0.6604 - fus_accuracy: 0.8651 - opt_loss: 0.1030 - sar_loss: 0.1823 - fus_loss: 0.1053 - loss: 0.3906 - val_opt_accuracy: 0.8426 - val_sar_accuracy: 0.6617 - val_fus_accuracy: 0.8316 - val_opt_loss: 0.0881 - val_sar_loss: 0.1651 - val_fus_loss: 0.0982 - val_loss: 0.3514\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8767 - sar_accuracy: 0.6630 - fus_accuracy: 0.8688 - opt_loss: 0.1005 - sar_loss: 0.1792 - fus_loss: 0.1014 - loss: 0.3811\n",
      "Epoch 00008: val_loss improved from 0.35139 to 0.34678, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8767 - sar_accuracy: 0.6630 - fus_accuracy: 0.8688 - opt_loss: 0.1005 - sar_loss: 0.1792 - fus_loss: 0.1014 - loss: 0.3811 - val_opt_accuracy: 0.8425 - val_sar_accuracy: 0.6637 - val_fus_accuracy: 0.8343 - val_opt_loss: 0.0879 - val_sar_loss: 0.1617 - val_fus_loss: 0.0972 - val_loss: 0.3468\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8734 - sar_accuracy: 0.6646 - fus_accuracy: 0.8668 - opt_loss: 0.0996 - sar_loss: 0.1756 - fus_loss: 0.1005 - loss: 0.3758\n",
      "Epoch 00009: val_loss improved from 0.34678 to 0.34102, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 134ms/step - opt_accuracy: 0.8734 - sar_accuracy: 0.6646 - fus_accuracy: 0.8668 - opt_loss: 0.0996 - sar_loss: 0.1756 - fus_loss: 0.1005 - loss: 0.3758 - val_opt_accuracy: 0.8407 - val_sar_accuracy: 0.6650 - val_fus_accuracy: 0.8335 - val_opt_loss: 0.0886 - val_sar_loss: 0.1586 - val_fus_loss: 0.0938 - val_loss: 0.3410\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8755 - sar_accuracy: 0.6655 - fus_accuracy: 0.8691 - opt_loss: 0.0965 - sar_loss: 0.1723 - fus_loss: 0.0972 - loss: 0.3661\n",
      "Epoch 00010: val_loss improved from 0.34102 to 0.33288, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 136ms/step - opt_accuracy: 0.8755 - sar_accuracy: 0.6655 - fus_accuracy: 0.8691 - opt_loss: 0.0965 - sar_loss: 0.1723 - fus_loss: 0.0972 - loss: 0.3661 - val_opt_accuracy: 0.8358 - val_sar_accuracy: 0.6658 - val_fus_accuracy: 0.8302 - val_opt_loss: 0.0863 - val_sar_loss: 0.1558 - val_fus_loss: 0.0907 - val_loss: 0.3329\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8778 - sar_accuracy: 0.6660 - fus_accuracy: 0.8725 - opt_loss: 0.0931 - sar_loss: 0.1693 - fus_loss: 0.0937 - loss: 0.3562\n",
      "Epoch 00011: val_loss improved from 0.33288 to 0.32589, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8778 - sar_accuracy: 0.6660 - fus_accuracy: 0.8725 - opt_loss: 0.0931 - sar_loss: 0.1693 - fus_loss: 0.0937 - loss: 0.3562 - val_opt_accuracy: 0.8391 - val_sar_accuracy: 0.6662 - val_fus_accuracy: 0.8335 - val_opt_loss: 0.0851 - val_sar_loss: 0.1533 - val_fus_loss: 0.0875 - val_loss: 0.3259\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8773 - sar_accuracy: 0.6663 - fus_accuracy: 0.8731 - opt_loss: 0.0995 - sar_loss: 0.1700 - fus_loss: 0.0991 - loss: 0.3687\n",
      "Epoch 00012: val_loss improved from 0.32589 to 0.32307, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8773 - sar_accuracy: 0.6663 - fus_accuracy: 0.8731 - opt_loss: 0.0995 - sar_loss: 0.1700 - fus_loss: 0.0991 - loss: 0.3687 - val_opt_accuracy: 0.8408 - val_sar_accuracy: 0.6664 - val_fus_accuracy: 0.8369 - val_opt_loss: 0.0850 - val_sar_loss: 0.1513 - val_fus_loss: 0.0868 - val_loss: 0.3231\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8781 - sar_accuracy: 0.6665 - fus_accuracy: 0.8758 - opt_loss: 0.0928 - sar_loss: 0.1664 - fus_loss: 0.0927 - loss: 0.3519\n",
      "Epoch 00013: val_loss improved from 0.32307 to 0.32028, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8781 - sar_accuracy: 0.6665 - fus_accuracy: 0.8758 - opt_loss: 0.0928 - sar_loss: 0.1664 - fus_loss: 0.0927 - loss: 0.3519 - val_opt_accuracy: 0.8436 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8391 - val_opt_loss: 0.0847 - val_sar_loss: 0.1492 - val_fus_loss: 0.0864 - val_loss: 0.3203\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8772 - sar_accuracy: 0.6666 - fus_accuracy: 0.8765 - opt_loss: 0.0994 - sar_loss: 0.1671 - fus_loss: 0.0976 - loss: 0.3641\n",
      "Epoch 00014: val_loss did not improve from 0.32028\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8772 - sar_accuracy: 0.6666 - fus_accuracy: 0.8765 - opt_loss: 0.0994 - sar_loss: 0.1671 - fus_loss: 0.0976 - loss: 0.3641 - val_opt_accuracy: 0.8346 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8323 - val_opt_loss: 0.0868 - val_sar_loss: 0.1476 - val_fus_loss: 0.0909 - val_loss: 0.3253\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8773 - sar_accuracy: 0.6666 - fus_accuracy: 0.8771 - opt_loss: 0.0931 - sar_loss: 0.1637 - fus_loss: 0.0924 - loss: 0.3492\n",
      "Epoch 00015: val_loss improved from 0.32028 to 0.31110, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8773 - sar_accuracy: 0.6666 - fus_accuracy: 0.8771 - opt_loss: 0.0931 - sar_loss: 0.1637 - fus_loss: 0.0924 - loss: 0.3492 - val_opt_accuracy: 0.8410 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8396 - val_opt_loss: 0.0820 - val_sar_loss: 0.1458 - val_fus_loss: 0.0833 - val_loss: 0.3111\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8771 - sar_accuracy: 0.6666 - fus_accuracy: 0.8779 - opt_loss: 0.0950 - sar_loss: 0.1621 - fus_loss: 0.0933 - loss: 0.3504\n",
      "Epoch 00016: val_loss did not improve from 0.31110\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8771 - sar_accuracy: 0.6666 - fus_accuracy: 0.8779 - opt_loss: 0.0950 - sar_loss: 0.1621 - fus_loss: 0.0933 - loss: 0.3504 - val_opt_accuracy: 0.8366 - val_sar_accuracy: 0.6667 - val_fus_accuracy: 0.8355 - val_opt_loss: 0.0817 - val_sar_loss: 0.1445 - val_fus_loss: 0.0870 - val_loss: 0.3133\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8775 - sar_accuracy: 0.6666 - fus_accuracy: 0.8780 - opt_loss: 0.0875 - sar_loss: 0.1595 - fus_loss: 0.0873 - loss: 0.3343\n",
      "Epoch 00017: val_loss improved from 0.31110 to 0.30999, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8775 - sar_accuracy: 0.6666 - fus_accuracy: 0.8780 - opt_loss: 0.0875 - sar_loss: 0.1595 - fus_loss: 0.0873 - loss: 0.3343 - val_opt_accuracy: 0.8337 - val_sar_accuracy: 0.6667 - val_fus_accuracy: 0.8342 - val_opt_loss: 0.0808 - val_sar_loss: 0.1432 - val_fus_loss: 0.0860 - val_loss: 0.3100\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8751 - sar_accuracy: 0.6666 - fus_accuracy: 0.8754 - opt_loss: 0.0878 - sar_loss: 0.1600 - fus_loss: 0.0890 - loss: 0.3368\n",
      "Epoch 00018: val_loss improved from 0.30999 to 0.30650, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8751 - sar_accuracy: 0.6666 - fus_accuracy: 0.8754 - opt_loss: 0.0878 - sar_loss: 0.1600 - fus_loss: 0.0890 - loss: 0.3368 - val_opt_accuracy: 0.8323 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8319 - val_opt_loss: 0.0782 - val_sar_loss: 0.1428 - val_fus_loss: 0.0855 - val_loss: 0.3065\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8767 - sar_accuracy: 0.6666 - fus_accuracy: 0.8768 - opt_loss: 0.0835 - sar_loss: 0.1570 - fus_loss: 0.0845 - loss: 0.3250\n",
      "Epoch 00019: val_loss improved from 0.30650 to 0.30592, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8767 - sar_accuracy: 0.6666 - fus_accuracy: 0.8768 - opt_loss: 0.0835 - sar_loss: 0.1570 - fus_loss: 0.0845 - loss: 0.3250 - val_opt_accuracy: 0.8365 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8350 - val_opt_loss: 0.0759 - val_sar_loss: 0.1417 - val_fus_loss: 0.0883 - val_loss: 0.3059\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8766 - sar_accuracy: 0.6666 - fus_accuracy: 0.8770 - opt_loss: 0.0865 - sar_loss: 0.1579 - fus_loss: 0.0878 - loss: 0.3323\n",
      "Epoch 00020: val_loss improved from 0.30592 to 0.29943, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8766 - sar_accuracy: 0.6666 - fus_accuracy: 0.8770 - opt_loss: 0.0865 - sar_loss: 0.1579 - fus_loss: 0.0878 - loss: 0.3323 - val_opt_accuracy: 0.8356 - val_sar_accuracy: 0.6666 - val_fus_accuracy: 0.8318 - val_opt_loss: 0.0735 - val_sar_loss: 0.1409 - val_fus_loss: 0.0850 - val_loss: 0.2994\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8781 - sar_accuracy: 0.7417 - fus_accuracy: 0.8772 - opt_loss: 0.0831 - sar_loss: 0.1532 - fus_loss: 0.0833 - loss: 0.3195\n",
      "Epoch 00021: val_loss improved from 0.29943 to 0.28898, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8781 - sar_accuracy: 0.7417 - fus_accuracy: 0.8772 - opt_loss: 0.0831 - sar_loss: 0.1532 - fus_loss: 0.0833 - loss: 0.3195 - val_opt_accuracy: 0.8315 - val_sar_accuracy: 0.7313 - val_fus_accuracy: 0.8255 - val_opt_loss: 0.0729 - val_sar_loss: 0.1280 - val_fus_loss: 0.0881 - val_loss: 0.2890\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8780 - sar_accuracy: 0.7745 - fus_accuracy: 0.8813 - opt_loss: 0.0792 - sar_loss: 0.1429 - fus_loss: 0.0791 - loss: 0.3012\n",
      "Epoch 00022: val_loss did not improve from 0.28898\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8780 - sar_accuracy: 0.7745 - fus_accuracy: 0.8813 - opt_loss: 0.0792 - sar_loss: 0.1429 - fus_loss: 0.0791 - loss: 0.3012 - val_opt_accuracy: 0.8334 - val_sar_accuracy: 0.7321 - val_fus_accuracy: 0.8321 - val_opt_loss: 0.0734 - val_sar_loss: 0.1257 - val_fus_loss: 0.0935 - val_loss: 0.2926\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8817 - sar_accuracy: 0.7803 - fus_accuracy: 0.8855 - opt_loss: 0.0770 - sar_loss: 0.1373 - fus_loss: 0.0776 - loss: 0.2920\n",
      "Epoch 00023: val_loss improved from 0.28898 to 0.28670, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8817 - sar_accuracy: 0.7803 - fus_accuracy: 0.8855 - opt_loss: 0.0770 - sar_loss: 0.1373 - fus_loss: 0.0776 - loss: 0.2920 - val_opt_accuracy: 0.8352 - val_sar_accuracy: 0.7322 - val_fus_accuracy: 0.8318 - val_opt_loss: 0.0727 - val_sar_loss: 0.1217 - val_fus_loss: 0.0923 - val_loss: 0.2867\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8838 - sar_accuracy: 0.7912 - fus_accuracy: 0.8783 - opt_loss: 0.0732 - sar_loss: 0.1304 - fus_loss: 0.0759 - loss: 0.2795\n",
      "Epoch 00024: val_loss improved from 0.28670 to 0.28393, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8838 - sar_accuracy: 0.7912 - fus_accuracy: 0.8783 - opt_loss: 0.0732 - sar_loss: 0.1304 - fus_loss: 0.0759 - loss: 0.2795 - val_opt_accuracy: 0.8380 - val_sar_accuracy: 0.7371 - val_fus_accuracy: 0.8245 - val_opt_loss: 0.0767 - val_sar_loss: 0.1170 - val_fus_loss: 0.0902 - val_loss: 0.2839\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8767 - sar_accuracy: 0.8249 - fus_accuracy: 0.8637 - opt_loss: 0.0977 - sar_loss: 0.1378 - fus_loss: 0.1028 - loss: 0.3383\n",
      "Epoch 00025: val_loss did not improve from 0.28393\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8767 - sar_accuracy: 0.8249 - fus_accuracy: 0.8637 - opt_loss: 0.0977 - sar_loss: 0.1378 - fus_loss: 0.1028 - loss: 0.3383 - val_opt_accuracy: 0.8373 - val_sar_accuracy: 0.7360 - val_fus_accuracy: 0.8266 - val_opt_loss: 0.0827 - val_sar_loss: 0.1191 - val_fus_loss: 0.1053 - val_loss: 0.3072\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8803 - sar_accuracy: 0.8236 - fus_accuracy: 0.8619 - opt_loss: 0.0884 - sar_loss: 0.1241 - fus_loss: 0.0983 - loss: 0.3107\n",
      "Epoch 00026: val_loss did not improve from 0.28393\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8803 - sar_accuracy: 0.8236 - fus_accuracy: 0.8619 - opt_loss: 0.0884 - sar_loss: 0.1241 - fus_loss: 0.0983 - loss: 0.3107 - val_opt_accuracy: 0.8457 - val_sar_accuracy: 0.7629 - val_fus_accuracy: 0.8147 - val_opt_loss: 0.0892 - val_sar_loss: 0.1126 - val_fus_loss: 0.1258 - val_loss: 0.3276\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8842 - sar_accuracy: 0.8266 - fus_accuracy: 0.8578 - opt_loss: 0.0796 - sar_loss: 0.1246 - fus_loss: 0.0898 - loss: 0.2940\n",
      "Epoch 00027: val_loss did not improve from 0.28393\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8842 - sar_accuracy: 0.8266 - fus_accuracy: 0.8578 - opt_loss: 0.0796 - sar_loss: 0.1246 - fus_loss: 0.0898 - loss: 0.2940 - val_opt_accuracy: 0.8320 - val_sar_accuracy: 0.7781 - val_fus_accuracy: 0.7837 - val_opt_loss: 0.0800 - val_sar_loss: 0.1083 - val_fus_loss: 0.1069 - val_loss: 0.2952\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8858 - sar_accuracy: 0.8299 - fus_accuracy: 0.8620 - opt_loss: 0.0780 - sar_loss: 0.1269 - fus_loss: 0.0870 - loss: 0.2919\n",
      "Epoch 00028: val_loss did not improve from 0.28393\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8858 - sar_accuracy: 0.8299 - fus_accuracy: 0.8620 - opt_loss: 0.0780 - sar_loss: 0.1269 - fus_loss: 0.0870 - loss: 0.2919 - val_opt_accuracy: 0.8426 - val_sar_accuracy: 0.7843 - val_fus_accuracy: 0.8144 - val_opt_loss: 0.0778 - val_sar_loss: 0.1084 - val_fus_loss: 0.1061 - val_loss: 0.2923\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8862 - sar_accuracy: 0.8249 - fus_accuracy: 0.8704 - opt_loss: 0.0747 - sar_loss: 0.1242 - fus_loss: 0.0821 - loss: 0.2810\n",
      "Epoch 00029: val_loss improved from 0.28393 to 0.27630, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8862 - sar_accuracy: 0.8249 - fus_accuracy: 0.8704 - opt_loss: 0.0747 - sar_loss: 0.1242 - fus_loss: 0.0821 - loss: 0.2810 - val_opt_accuracy: 0.8441 - val_sar_accuracy: 0.7545 - val_fus_accuracy: 0.8061 - val_opt_loss: 0.0721 - val_sar_loss: 0.1115 - val_fus_loss: 0.0927 - val_loss: 0.2763\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8878 - sar_accuracy: 0.8315 - fus_accuracy: 0.8715 - opt_loss: 0.0719 - sar_loss: 0.1194 - fus_loss: 0.0781 - loss: 0.2694\n",
      "Epoch 00030: val_loss did not improve from 0.27630\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8878 - sar_accuracy: 0.8315 - fus_accuracy: 0.8715 - opt_loss: 0.0719 - sar_loss: 0.1194 - fus_loss: 0.0781 - loss: 0.2694 - val_opt_accuracy: 0.8390 - val_sar_accuracy: 0.7842 - val_fus_accuracy: 0.8075 - val_opt_loss: 0.0748 - val_sar_loss: 0.1070 - val_fus_loss: 0.0971 - val_loss: 0.2789\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8877 - sar_accuracy: 0.8326 - fus_accuracy: 0.8695 - opt_loss: 0.0733 - sar_loss: 0.1208 - fus_loss: 0.0792 - loss: 0.2733\n",
      "Epoch 00031: val_loss improved from 0.27630 to 0.27343, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8877 - sar_accuracy: 0.8326 - fus_accuracy: 0.8695 - opt_loss: 0.0733 - sar_loss: 0.1208 - fus_loss: 0.0792 - loss: 0.2733 - val_opt_accuracy: 0.8365 - val_sar_accuracy: 0.7848 - val_fus_accuracy: 0.7803 - val_opt_loss: 0.0744 - val_sar_loss: 0.1054 - val_fus_loss: 0.0936 - val_loss: 0.2734\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8853 - sar_accuracy: 0.8273 - fus_accuracy: 0.8767 - opt_loss: 0.0841 - sar_loss: 0.1376 - fus_loss: 0.0887 - loss: 0.3104\n",
      "Epoch 00032: val_loss did not improve from 0.27343\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8853 - sar_accuracy: 0.8273 - fus_accuracy: 0.8767 - opt_loss: 0.0841 - sar_loss: 0.1376 - fus_loss: 0.0887 - loss: 0.3104 - val_opt_accuracy: 0.8374 - val_sar_accuracy: 0.7798 - val_fus_accuracy: 0.8118 - val_opt_loss: 0.0757 - val_sar_loss: 0.1074 - val_fus_loss: 0.0998 - val_loss: 0.2829\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8891 - sar_accuracy: 0.8345 - fus_accuracy: 0.8670 - opt_loss: 0.0708 - sar_loss: 0.1215 - fus_loss: 0.0776 - loss: 0.2700\n",
      "Epoch 00033: val_loss did not improve from 0.27343\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8891 - sar_accuracy: 0.8345 - fus_accuracy: 0.8670 - opt_loss: 0.0708 - sar_loss: 0.1215 - fus_loss: 0.0776 - loss: 0.2700 - val_opt_accuracy: 0.8295 - val_sar_accuracy: 0.7930 - val_fus_accuracy: 0.8064 - val_opt_loss: 0.0788 - val_sar_loss: 0.1061 - val_fus_loss: 0.0944 - val_loss: 0.2794\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8915 - sar_accuracy: 0.8360 - fus_accuracy: 0.8763 - opt_loss: 0.0719 - sar_loss: 0.1241 - fus_loss: 0.0751 - loss: 0.2711\n",
      "Epoch 00034: val_loss did not improve from 0.27343\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8915 - sar_accuracy: 0.8360 - fus_accuracy: 0.8763 - opt_loss: 0.0719 - sar_loss: 0.1241 - fus_loss: 0.0751 - loss: 0.2711 - val_opt_accuracy: 0.8351 - val_sar_accuracy: 0.7868 - val_fus_accuracy: 0.8075 - val_opt_loss: 0.0766 - val_sar_loss: 0.1056 - val_fus_loss: 0.1009 - val_loss: 0.2831\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8893 - sar_accuracy: 0.8357 - fus_accuracy: 0.8804 - opt_loss: 0.0688 - sar_loss: 0.1200 - fus_loss: 0.0721 - loss: 0.2609\n",
      "Epoch 00035: val_loss did not improve from 0.27343\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8893 - sar_accuracy: 0.8357 - fus_accuracy: 0.8804 - opt_loss: 0.0688 - sar_loss: 0.1200 - fus_loss: 0.0721 - loss: 0.2609 - val_opt_accuracy: 0.8354 - val_sar_accuracy: 0.7998 - val_fus_accuracy: 0.8099 - val_opt_loss: 0.0823 - val_sar_loss: 0.1036 - val_fus_loss: 0.1093 - val_loss: 0.2951\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8906 - sar_accuracy: 0.8358 - fus_accuracy: 0.8819 - opt_loss: 0.0736 - sar_loss: 0.1285 - fus_loss: 0.0765 - loss: 0.2786\n",
      "Epoch 00036: val_loss did not improve from 0.27343\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8906 - sar_accuracy: 0.8358 - fus_accuracy: 0.8819 - opt_loss: 0.0736 - sar_loss: 0.1285 - fus_loss: 0.0765 - loss: 0.2786 - val_opt_accuracy: 0.8314 - val_sar_accuracy: 0.7971 - val_fus_accuracy: 0.7903 - val_opt_loss: 0.0801 - val_sar_loss: 0.1046 - val_fus_loss: 0.1074 - val_loss: 0.2921\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8911 - sar_accuracy: 0.8348 - fus_accuracy: 0.8772 - opt_loss: 0.0679 - sar_loss: 0.1195 - fus_loss: 0.0728 - loss: 0.2602\n",
      "Epoch 00037: val_loss improved from 0.27343 to 0.27205, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8911 - sar_accuracy: 0.8348 - fus_accuracy: 0.8772 - opt_loss: 0.0679 - sar_loss: 0.1195 - fus_loss: 0.0728 - loss: 0.2602 - val_opt_accuracy: 0.8383 - val_sar_accuracy: 0.7988 - val_fus_accuracy: 0.8128 - val_opt_loss: 0.0754 - val_sar_loss: 0.1031 - val_fus_loss: 0.0936 - val_loss: 0.2720\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8925 - sar_accuracy: 0.8357 - fus_accuracy: 0.8817 - opt_loss: 0.0723 - sar_loss: 0.1214 - fus_loss: 0.0780 - loss: 0.2717\n",
      "Epoch 00038: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8925 - sar_accuracy: 0.8357 - fus_accuracy: 0.8817 - opt_loss: 0.0723 - sar_loss: 0.1214 - fus_loss: 0.0780 - loss: 0.2717 - val_opt_accuracy: 0.8187 - val_sar_accuracy: 0.7991 - val_fus_accuracy: 0.7687 - val_opt_loss: 0.0809 - val_sar_loss: 0.1033 - val_fus_loss: 0.0979 - val_loss: 0.2821\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8925 - sar_accuracy: 0.8364 - fus_accuracy: 0.8866 - opt_loss: 0.0691 - sar_loss: 0.1260 - fus_loss: 0.0703 - loss: 0.2654\n",
      "Epoch 00039: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8925 - sar_accuracy: 0.8364 - fus_accuracy: 0.8866 - opt_loss: 0.0691 - sar_loss: 0.1260 - fus_loss: 0.0703 - loss: 0.2654 - val_opt_accuracy: 0.8333 - val_sar_accuracy: 0.7800 - val_fus_accuracy: 0.8225 - val_opt_loss: 0.0775 - val_sar_loss: 0.1059 - val_fus_loss: 0.1035 - val_loss: 0.2868\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8903 - sar_accuracy: 0.8338 - fus_accuracy: 0.8849 - opt_loss: 0.0668 - sar_loss: 0.1173 - fus_loss: 0.0717 - loss: 0.2557\n",
      "Epoch 00040: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8903 - sar_accuracy: 0.8338 - fus_accuracy: 0.8849 - opt_loss: 0.0668 - sar_loss: 0.1173 - fus_loss: 0.0717 - loss: 0.2557 - val_opt_accuracy: 0.8346 - val_sar_accuracy: 0.8028 - val_fus_accuracy: 0.7906 - val_opt_loss: 0.0762 - val_sar_loss: 0.1024 - val_fus_loss: 0.0968 - val_loss: 0.2754\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8957 - sar_accuracy: 0.8383 - fus_accuracy: 0.8909 - opt_loss: 0.0645 - sar_loss: 0.1201 - fus_loss: 0.0672 - loss: 0.2518\n",
      "Epoch 00041: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8957 - sar_accuracy: 0.8383 - fus_accuracy: 0.8909 - opt_loss: 0.0645 - sar_loss: 0.1201 - fus_loss: 0.0672 - loss: 0.2518 - val_opt_accuracy: 0.8316 - val_sar_accuracy: 0.7984 - val_fus_accuracy: 0.8111 - val_opt_loss: 0.0790 - val_sar_loss: 0.1046 - val_fus_loss: 0.1094 - val_loss: 0.2929\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8915 - sar_accuracy: 0.8345 - fus_accuracy: 0.8901 - opt_loss: 0.0693 - sar_loss: 0.1222 - fus_loss: 0.0714 - loss: 0.2630\n",
      "Epoch 00042: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8915 - sar_accuracy: 0.8345 - fus_accuracy: 0.8901 - opt_loss: 0.0693 - sar_loss: 0.1222 - fus_loss: 0.0714 - loss: 0.2630 - val_opt_accuracy: 0.8311 - val_sar_accuracy: 0.8037 - val_fus_accuracy: 0.8150 - val_opt_loss: 0.0849 - val_sar_loss: 0.1037 - val_fus_loss: 0.1117 - val_loss: 0.3003\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8940 - sar_accuracy: 0.8377 - fus_accuracy: 0.8904 - opt_loss: 0.0661 - sar_loss: 0.1218 - fus_loss: 0.0687 - loss: 0.2566\n",
      "Epoch 00043: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8940 - sar_accuracy: 0.8377 - fus_accuracy: 0.8904 - opt_loss: 0.0661 - sar_loss: 0.1218 - fus_loss: 0.0687 - loss: 0.2566 - val_opt_accuracy: 0.8121 - val_sar_accuracy: 0.7957 - val_fus_accuracy: 0.8149 - val_opt_loss: 0.1039 - val_sar_loss: 0.1043 - val_fus_loss: 0.1373 - val_loss: 0.3456\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8911 - sar_accuracy: 0.8370 - fus_accuracy: 0.8823 - opt_loss: 0.0704 - sar_loss: 0.1260 - fus_loss: 0.0743 - loss: 0.2708\n",
      "Epoch 00044: val_loss did not improve from 0.27205\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8911 - sar_accuracy: 0.8370 - fus_accuracy: 0.8823 - opt_loss: 0.0704 - sar_loss: 0.1260 - fus_loss: 0.0743 - loss: 0.2708 - val_opt_accuracy: 0.8222 - val_sar_accuracy: 0.8044 - val_fus_accuracy: 0.7986 - val_opt_loss: 0.0835 - val_sar_loss: 0.1049 - val_fus_loss: 0.1045 - val_loss: 0.2929\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8930 - sar_accuracy: 0.8375 - fus_accuracy: 0.8930 - opt_loss: 0.0650 - sar_loss: 0.1199 - fus_loss: 0.0667 - loss: 0.2516\n",
      "Epoch 00045: val_loss improved from 0.27205 to 0.27176, saving model to imgs/experiments/exp3/models\\unet_2.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8930 - sar_accuracy: 0.8375 - fus_accuracy: 0.8930 - opt_loss: 0.0650 - sar_loss: 0.1199 - fus_loss: 0.0667 - loss: 0.2516 - val_opt_accuracy: 0.8408 - val_sar_accuracy: 0.7878 - val_fus_accuracy: 0.8078 - val_opt_loss: 0.0724 - val_sar_loss: 0.1040 - val_fus_loss: 0.0954 - val_loss: 0.2718\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8940 - sar_accuracy: 0.8342 - fus_accuracy: 0.8890 - opt_loss: 0.0650 - sar_loss: 0.1199 - fus_loss: 0.0678 - loss: 0.2528\n",
      "Epoch 00046: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8940 - sar_accuracy: 0.8342 - fus_accuracy: 0.8890 - opt_loss: 0.0650 - sar_loss: 0.1199 - fus_loss: 0.0678 - loss: 0.2528 - val_opt_accuracy: 0.8318 - val_sar_accuracy: 0.8005 - val_fus_accuracy: 0.8072 - val_opt_loss: 0.0792 - val_sar_loss: 0.1045 - val_fus_loss: 0.1016 - val_loss: 0.2852\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8934 - sar_accuracy: 0.8377 - fus_accuracy: 0.8924 - opt_loss: 0.0625 - sar_loss: 0.1173 - fus_loss: 0.0648 - loss: 0.2446\n",
      "Epoch 00047: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8934 - sar_accuracy: 0.8377 - fus_accuracy: 0.8924 - opt_loss: 0.0625 - sar_loss: 0.1173 - fus_loss: 0.0648 - loss: 0.2446 - val_opt_accuracy: 0.8363 - val_sar_accuracy: 0.7825 - val_fus_accuracy: 0.8241 - val_opt_loss: 0.0807 - val_sar_loss: 0.1037 - val_fus_loss: 0.1094 - val_loss: 0.2938\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8928 - sar_accuracy: 0.8349 - fus_accuracy: 0.8962 - opt_loss: 0.0652 - sar_loss: 0.1250 - fus_loss: 0.0650 - loss: 0.2551\n",
      "Epoch 00048: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8928 - sar_accuracy: 0.8349 - fus_accuracy: 0.8962 - opt_loss: 0.0652 - sar_loss: 0.1250 - fus_loss: 0.0650 - loss: 0.2551 - val_opt_accuracy: 0.8348 - val_sar_accuracy: 0.7805 - val_fus_accuracy: 0.8169 - val_opt_loss: 0.0808 - val_sar_loss: 0.1049 - val_fus_loss: 0.1132 - val_loss: 0.2988\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8924 - sar_accuracy: 0.8391 - fus_accuracy: 0.8908 - opt_loss: 0.0642 - sar_loss: 0.1189 - fus_loss: 0.0659 - loss: 0.2490\n",
      "Epoch 00049: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8924 - sar_accuracy: 0.8391 - fus_accuracy: 0.8908 - opt_loss: 0.0642 - sar_loss: 0.1189 - fus_loss: 0.0659 - loss: 0.2490 - val_opt_accuracy: 0.8267 - val_sar_accuracy: 0.8064 - val_fus_accuracy: 0.8006 - val_opt_loss: 0.0885 - val_sar_loss: 0.1030 - val_fus_loss: 0.1164 - val_loss: 0.3079\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8934 - sar_accuracy: 0.8392 - fus_accuracy: 0.8947 - opt_loss: 0.0656 - sar_loss: 0.1214 - fus_loss: 0.0666 - loss: 0.2537\n",
      "Epoch 00050: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8934 - sar_accuracy: 0.8392 - fus_accuracy: 0.8947 - opt_loss: 0.0656 - sar_loss: 0.1214 - fus_loss: 0.0666 - loss: 0.2537 - val_opt_accuracy: 0.8332 - val_sar_accuracy: 0.7797 - val_fus_accuracy: 0.8151 - val_opt_loss: 0.0799 - val_sar_loss: 0.1061 - val_fus_loss: 0.1104 - val_loss: 0.2965\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8938 - sar_accuracy: 0.8376 - fus_accuracy: 0.8976 - opt_loss: 0.0652 - sar_loss: 0.1234 - fus_loss: 0.0656 - loss: 0.2542\n",
      "Epoch 00051: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8938 - sar_accuracy: 0.8376 - fus_accuracy: 0.8976 - opt_loss: 0.0652 - sar_loss: 0.1234 - fus_loss: 0.0656 - loss: 0.2542 - val_opt_accuracy: 0.8252 - val_sar_accuracy: 0.8013 - val_fus_accuracy: 0.8147 - val_opt_loss: 0.0849 - val_sar_loss: 0.1030 - val_fus_loss: 0.1029 - val_loss: 0.2908\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8937 - sar_accuracy: 0.8372 - fus_accuracy: 0.8938 - opt_loss: 0.0623 - sar_loss: 0.1132 - fus_loss: 0.0648 - loss: 0.2403\n",
      "Epoch 00052: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8937 - sar_accuracy: 0.8372 - fus_accuracy: 0.8938 - opt_loss: 0.0623 - sar_loss: 0.1132 - fus_loss: 0.0648 - loss: 0.2403 - val_opt_accuracy: 0.8247 - val_sar_accuracy: 0.8001 - val_fus_accuracy: 0.8023 - val_opt_loss: 0.0817 - val_sar_loss: 0.1022 - val_fus_loss: 0.1019 - val_loss: 0.2858\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9018 - sar_accuracy: 0.8392 - fus_accuracy: 0.8997 - opt_loss: 0.0616 - sar_loss: 0.1172 - fus_loss: 0.0635 - loss: 0.2424\n",
      "Epoch 00053: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.9018 - sar_accuracy: 0.8392 - fus_accuracy: 0.8997 - opt_loss: 0.0616 - sar_loss: 0.1172 - fus_loss: 0.0635 - loss: 0.2424 - val_opt_accuracy: 0.8315 - val_sar_accuracy: 0.8030 - val_fus_accuracy: 0.8068 - val_opt_loss: 0.0786 - val_sar_loss: 0.1018 - val_fus_loss: 0.0964 - val_loss: 0.2767\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9019 - sar_accuracy: 0.8385 - fus_accuracy: 0.8952 - opt_loss: 0.0631 - sar_loss: 0.1207 - fus_loss: 0.0637 - loss: 0.2475\n",
      "Epoch 00054: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.9019 - sar_accuracy: 0.8385 - fus_accuracy: 0.8952 - opt_loss: 0.0631 - sar_loss: 0.1207 - fus_loss: 0.0637 - loss: 0.2475 - val_opt_accuracy: 0.8282 - val_sar_accuracy: 0.7931 - val_fus_accuracy: 0.7974 - val_opt_loss: 0.0794 - val_sar_loss: 0.1028 - val_fus_loss: 0.1004 - val_loss: 0.2826\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.9066 - sar_accuracy: 0.8401 - fus_accuracy: 0.9000 - opt_loss: 0.0618 - sar_loss: 0.1233 - fus_loss: 0.0624 - loss: 0.2475\n",
      "Epoch 00055: val_loss did not improve from 0.27176\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.9066 - sar_accuracy: 0.8401 - fus_accuracy: 0.9000 - opt_loss: 0.0618 - sar_loss: 0.1233 - fus_loss: 0.0624 - loss: 0.2475 - val_opt_accuracy: 0.8284 - val_sar_accuracy: 0.8048 - val_fus_accuracy: 0.8136 - val_opt_loss: 0.0842 - val_sar_loss: 0.1042 - val_fus_loss: 0.1069 - val_loss: 0.2953\n",
      "Epoch 00055: early stopping\n",
      "time:  3\n",
      "Model: \"model_3_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "opt_encoder (UNET_Encoder)   multiple                  2486      \n",
      "_________________________________________________________________\n",
      "sar_encoder (UNET_Encoder)   multiple                  2198      \n",
      "_________________________________________________________________\n",
      "opt_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "sar_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "opt_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "sar_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "fus_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "combination (CombinationLaye multiple                  3         \n",
      "_________________________________________________________________\n",
      "opt_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "opt_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.6614 - sar_accuracy: 0.6044 - fus_accuracy: 0.5036 - opt_loss: 0.1531 - sar_loss: 0.1960 - fus_loss: 0.3638 - loss: 0.7129\n",
      "Epoch 00001: val_loss improved from inf to 0.40288, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 145ms/step - opt_accuracy: 0.6614 - sar_accuracy: 0.6044 - fus_accuracy: 0.5036 - opt_loss: 0.1531 - sar_loss: 0.1960 - fus_loss: 0.3638 - loss: 0.7129 - val_opt_accuracy: 0.6176 - val_sar_accuracy: 0.6866 - val_fus_accuracy: 0.6900 - val_opt_loss: 0.1202 - val_sar_loss: 0.1419 - val_fus_loss: 0.1407 - val_loss: 0.4029\n",
      "Epoch 2/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.6972 - sar_accuracy: 0.6527 - fus_accuracy: 0.7118 - opt_loss: 0.1371 - sar_loss: 0.1877 - fus_loss: 0.1717 - loss: 0.4965\n",
      "Epoch 00002: val_loss improved from 0.40288 to 0.36888, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 128ms/step - opt_accuracy: 0.6974 - sar_accuracy: 0.6533 - fus_accuracy: 0.7119 - opt_loss: 0.1348 - sar_loss: 0.1831 - fus_loss: 0.1694 - loss: 0.4873 - val_opt_accuracy: 0.6574 - val_sar_accuracy: 0.7059 - val_fus_accuracy: 0.6605 - val_opt_loss: 0.1118 - val_sar_loss: 0.1213 - val_fus_loss: 0.1358 - val_loss: 0.3689\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7046 - sar_accuracy: 0.7067 - fus_accuracy: 0.7047 - opt_loss: 0.1342 - sar_loss: 0.1603 - fus_loss: 0.1581 - loss: 0.4526\n",
      "Epoch 00003: val_loss improved from 0.36888 to 0.36371, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.7046 - sar_accuracy: 0.7067 - fus_accuracy: 0.7047 - opt_loss: 0.1342 - sar_loss: 0.1603 - fus_loss: 0.1581 - loss: 0.4526 - val_opt_accuracy: 0.6747 - val_sar_accuracy: 0.7028 - val_fus_accuracy: 0.6884 - val_opt_loss: 0.1135 - val_sar_loss: 0.1123 - val_fus_loss: 0.1379 - val_loss: 0.3637\n",
      "Epoch 4/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.7199 - sar_accuracy: 0.7069 - fus_accuracy: 0.7062 - opt_loss: 0.1205 - sar_loss: 0.1431 - fus_loss: 0.1362 - loss: 0.3998\n",
      "Epoch 00004: val_loss did not improve from 0.36371\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.7202 - sar_accuracy: 0.7070 - fus_accuracy: 0.7066 - opt_loss: 0.1184 - sar_loss: 0.1426 - fus_loss: 0.1343 - loss: 0.3954 - val_opt_accuracy: 0.6803 - val_sar_accuracy: 0.7007 - val_fus_accuracy: 0.6804 - val_opt_loss: 0.1246 - val_sar_loss: 0.1118 - val_fus_loss: 0.1371 - val_loss: 0.3734\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7257 - sar_accuracy: 0.7125 - fus_accuracy: 0.7459 - opt_loss: 0.1273 - sar_loss: 0.1464 - fus_loss: 0.1382 - loss: 0.4120\n",
      "Epoch 00005: val_loss improved from 0.36371 to 0.30525, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.7257 - sar_accuracy: 0.7125 - fus_accuracy: 0.7459 - opt_loss: 0.1273 - sar_loss: 0.1464 - fus_loss: 0.1382 - loss: 0.4120 - val_opt_accuracy: 0.7112 - val_sar_accuracy: 0.7002 - val_fus_accuracy: 0.6949 - val_opt_loss: 0.0931 - val_sar_loss: 0.1111 - val_fus_loss: 0.1011 - val_loss: 0.3052\n",
      "Epoch 6/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.7441 - sar_accuracy: 0.7136 - fus_accuracy: 0.7469 - opt_loss: 0.1223 - sar_loss: 0.1507 - fus_loss: 0.1382 - loss: 0.4112\n",
      "Epoch 00006: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.7442 - sar_accuracy: 0.7133 - fus_accuracy: 0.7470 - opt_loss: 0.1239 - sar_loss: 0.1532 - fus_loss: 0.1396 - loss: 0.4167 - val_opt_accuracy: 0.6885 - val_sar_accuracy: 0.7001 - val_fus_accuracy: 0.7245 - val_opt_loss: 0.1008 - val_sar_loss: 0.1113 - val_fus_loss: 0.1040 - val_loss: 0.3162\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7687 - sar_accuracy: 0.7020 - fus_accuracy: 0.7660 - opt_loss: 0.1063 - sar_loss: 0.1339 - fus_loss: 0.1150 - loss: 0.3552\n",
      "Epoch 00007: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.7687 - sar_accuracy: 0.7020 - fus_accuracy: 0.7660 - opt_loss: 0.1063 - sar_loss: 0.1339 - fus_loss: 0.1150 - loss: 0.3552 - val_opt_accuracy: 0.7269 - val_sar_accuracy: 0.6996 - val_fus_accuracy: 0.6976 - val_opt_loss: 0.0985 - val_sar_loss: 0.1119 - val_fus_loss: 0.1088 - val_loss: 0.3192\n",
      "Epoch 8/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.7792 - sar_accuracy: 0.7173 - fus_accuracy: 0.7606 - opt_loss: 0.1024 - sar_loss: 0.1352 - fus_loss: 0.1137 - loss: 0.3512\n",
      "Epoch 00008: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 113ms/step - opt_accuracy: 0.7794 - sar_accuracy: 0.7175 - fus_accuracy: 0.7606 - opt_loss: 0.1007 - sar_loss: 0.1332 - fus_loss: 0.1118 - loss: 0.3458 - val_opt_accuracy: 0.7415 - val_sar_accuracy: 0.7018 - val_fus_accuracy: 0.6936 - val_opt_loss: 0.0930 - val_sar_loss: 0.1116 - val_fus_loss: 0.1022 - val_loss: 0.3067\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8047 - sar_accuracy: 0.7214 - fus_accuracy: 0.7534 - opt_loss: 0.1002 - sar_loss: 0.1351 - fus_loss: 0.1144 - loss: 0.3496\n",
      "Epoch 00009: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8047 - sar_accuracy: 0.7214 - fus_accuracy: 0.7534 - opt_loss: 0.1002 - sar_loss: 0.1351 - fus_loss: 0.1144 - loss: 0.3496 - val_opt_accuracy: 0.7537 - val_sar_accuracy: 0.7015 - val_fus_accuracy: 0.6917 - val_opt_loss: 0.0952 - val_sar_loss: 0.1120 - val_fus_loss: 0.1064 - val_loss: 0.3135\n",
      "Epoch 10/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8199 - sar_accuracy: 0.7213 - fus_accuracy: 0.7548 - opt_loss: 0.0941 - sar_loss: 0.1334 - fus_loss: 0.1081 - loss: 0.3356\n",
      "Epoch 00010: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8197 - sar_accuracy: 0.7212 - fus_accuracy: 0.7543 - opt_loss: 0.0944 - sar_loss: 0.1331 - fus_loss: 0.1095 - loss: 0.3370 - val_opt_accuracy: 0.7737 - val_sar_accuracy: 0.7000 - val_fus_accuracy: 0.6740 - val_opt_loss: 0.1047 - val_sar_loss: 0.1127 - val_fus_loss: 0.1272 - val_loss: 0.3446\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8293 - sar_accuracy: 0.7219 - fus_accuracy: 0.7564 - opt_loss: 0.1046 - sar_loss: 0.1450 - fus_loss: 0.1222 - loss: 0.3718\n",
      "Epoch 00011: val_loss did not improve from 0.30525\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8293 - sar_accuracy: 0.7219 - fus_accuracy: 0.7564 - opt_loss: 0.1046 - sar_loss: 0.1450 - fus_loss: 0.1222 - loss: 0.3718 - val_opt_accuracy: 0.7826 - val_sar_accuracy: 0.6980 - val_fus_accuracy: 0.6872 - val_opt_loss: 0.1012 - val_sar_loss: 0.1147 - val_fus_loss: 0.1205 - val_loss: 0.3364\n",
      "Epoch 12/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8357 - sar_accuracy: 0.7187 - fus_accuracy: 0.7595 - opt_loss: 0.0933 - sar_loss: 0.1325 - fus_loss: 0.1104 - loss: 0.3363\n",
      "Epoch 00012: val_loss improved from 0.30525 to 0.29560, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8360 - sar_accuracy: 0.7191 - fus_accuracy: 0.7596 - opt_loss: 0.0919 - sar_loss: 0.1311 - fus_loss: 0.1084 - loss: 0.3314 - val_opt_accuracy: 0.7704 - val_sar_accuracy: 0.6992 - val_fus_accuracy: 0.6737 - val_opt_loss: 0.0876 - val_sar_loss: 0.1112 - val_fus_loss: 0.0969 - val_loss: 0.2956\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8342 - sar_accuracy: 0.7301 - fus_accuracy: 0.7496 - opt_loss: 0.0915 - sar_loss: 0.1369 - fus_loss: 0.1079 - loss: 0.3363\n",
      "Epoch 00013: val_loss did not improve from 0.29560\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8342 - sar_accuracy: 0.7301 - fus_accuracy: 0.7496 - opt_loss: 0.0915 - sar_loss: 0.1369 - fus_loss: 0.1079 - loss: 0.3363 - val_opt_accuracy: 0.7868 - val_sar_accuracy: 0.6941 - val_fus_accuracy: 0.6905 - val_opt_loss: 0.0868 - val_sar_loss: 0.1152 - val_fus_loss: 0.1006 - val_loss: 0.3027\n",
      "Epoch 14/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8468 - sar_accuracy: 0.7281 - fus_accuracy: 0.7638 - opt_loss: 0.0859 - sar_loss: 0.1330 - fus_loss: 0.1037 - loss: 0.3226\n",
      "Epoch 00014: val_loss did not improve from 0.29560\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8464 - sar_accuracy: 0.7279 - fus_accuracy: 0.7636 - opt_loss: 0.0883 - sar_loss: 0.1347 - fus_loss: 0.1060 - loss: 0.3290 - val_opt_accuracy: 0.7972 - val_sar_accuracy: 0.6961 - val_fus_accuracy: 0.7006 - val_opt_loss: 0.0900 - val_sar_loss: 0.1126 - val_fus_loss: 0.1071 - val_loss: 0.3097\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8486 - sar_accuracy: 0.7363 - fus_accuracy: 0.7747 - opt_loss: 0.0878 - sar_loss: 0.1376 - fus_loss: 0.1050 - loss: 0.3304\n",
      "Epoch 00015: val_loss did not improve from 0.29560\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8486 - sar_accuracy: 0.7363 - fus_accuracy: 0.7747 - opt_loss: 0.0878 - sar_loss: 0.1376 - fus_loss: 0.1050 - loss: 0.3304 - val_opt_accuracy: 0.7890 - val_sar_accuracy: 0.6965 - val_fus_accuracy: 0.7026 - val_opt_loss: 0.0873 - val_sar_loss: 0.1142 - val_fus_loss: 0.0985 - val_loss: 0.3000\n",
      "Epoch 16/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8521 - sar_accuracy: 0.7267 - fus_accuracy: 0.7793 - opt_loss: 0.0853 - sar_loss: 0.1383 - fus_loss: 0.1025 - loss: 0.3260\n",
      "Epoch 00016: val_loss did not improve from 0.29560\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8523 - sar_accuracy: 0.7269 - fus_accuracy: 0.7799 - opt_loss: 0.0847 - sar_loss: 0.1382 - fus_loss: 0.1016 - loss: 0.3245 - val_opt_accuracy: 0.7854 - val_sar_accuracy: 0.6953 - val_fus_accuracy: 0.6917 - val_opt_loss: 0.0873 - val_sar_loss: 0.1135 - val_fus_loss: 0.0987 - val_loss: 0.2995\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8505 - sar_accuracy: 0.7397 - fus_accuracy: 0.7704 - opt_loss: 0.0862 - sar_loss: 0.1330 - fus_loss: 0.1046 - loss: 0.3239\n",
      "Epoch 00017: val_loss improved from 0.29560 to 0.28821, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8505 - sar_accuracy: 0.7397 - fus_accuracy: 0.7704 - opt_loss: 0.0862 - sar_loss: 0.1330 - fus_loss: 0.1046 - loss: 0.3239 - val_opt_accuracy: 0.7958 - val_sar_accuracy: 0.6944 - val_fus_accuracy: 0.7103 - val_opt_loss: 0.0842 - val_sar_loss: 0.1118 - val_fus_loss: 0.0923 - val_loss: 0.2882\n",
      "Epoch 18/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8525 - sar_accuracy: 0.7422 - fus_accuracy: 0.7884 - opt_loss: 0.0827 - sar_loss: 0.1340 - fus_loss: 0.0996 - loss: 0.3163\n",
      "Epoch 00018: val_loss did not improve from 0.28821\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8522 - sar_accuracy: 0.7418 - fus_accuracy: 0.7876 - opt_loss: 0.0831 - sar_loss: 0.1324 - fus_loss: 0.1008 - loss: 0.3163 - val_opt_accuracy: 0.7968 - val_sar_accuracy: 0.6936 - val_fus_accuracy: 0.7036 - val_opt_loss: 0.0881 - val_sar_loss: 0.1123 - val_fus_loss: 0.1051 - val_loss: 0.3055\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8525 - sar_accuracy: 0.7390 - fus_accuracy: 0.7921 - opt_loss: 0.0881 - sar_loss: 0.1427 - fus_loss: 0.1053 - loss: 0.3362\n",
      "Epoch 00019: val_loss did not improve from 0.28821\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8525 - sar_accuracy: 0.7390 - fus_accuracy: 0.7921 - opt_loss: 0.0881 - sar_loss: 0.1427 - fus_loss: 0.1053 - loss: 0.3362 - val_opt_accuracy: 0.8025 - val_sar_accuracy: 0.6979 - val_fus_accuracy: 0.7305 - val_opt_loss: 0.0853 - val_sar_loss: 0.1177 - val_fus_loss: 0.0993 - val_loss: 0.3023\n",
      "Epoch 20/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8560 - sar_accuracy: 0.7428 - fus_accuracy: 0.8028 - opt_loss: 0.0832 - sar_loss: 0.1319 - fus_loss: 0.1008 - loss: 0.3159\n",
      "Epoch 00020: val_loss improved from 0.28821 to 0.27656, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8560 - sar_accuracy: 0.7433 - fus_accuracy: 0.8029 - opt_loss: 0.0824 - sar_loss: 0.1299 - fus_loss: 0.0995 - loss: 0.3118 - val_opt_accuracy: 0.7969 - val_sar_accuracy: 0.6967 - val_fus_accuracy: 0.7442 - val_opt_loss: 0.0803 - val_sar_loss: 0.1090 - val_fus_loss: 0.0873 - val_loss: 0.2766\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8565 - sar_accuracy: 0.7492 - fus_accuracy: 0.8098 - opt_loss: 0.0806 - sar_loss: 0.1296 - fus_loss: 0.0978 - loss: 0.3081\n",
      "Epoch 00021: val_loss did not improve from 0.27656\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8565 - sar_accuracy: 0.7492 - fus_accuracy: 0.8098 - opt_loss: 0.0806 - sar_loss: 0.1296 - fus_loss: 0.0978 - loss: 0.3081 - val_opt_accuracy: 0.7958 - val_sar_accuracy: 0.7001 - val_fus_accuracy: 0.7363 - val_opt_loss: 0.0877 - val_sar_loss: 0.1097 - val_fus_loss: 0.0985 - val_loss: 0.2959\n",
      "Epoch 22/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8569 - sar_accuracy: 0.7535 - fus_accuracy: 0.8178 - opt_loss: 0.0808 - sar_loss: 0.1338 - fus_loss: 0.0949 - loss: 0.3095\n",
      "Epoch 00022: val_loss did not improve from 0.27656\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8570 - sar_accuracy: 0.7535 - fus_accuracy: 0.8180 - opt_loss: 0.0804 - sar_loss: 0.1343 - fus_loss: 0.0945 - loss: 0.3092 - val_opt_accuracy: 0.7994 - val_sar_accuracy: 0.7049 - val_fus_accuracy: 0.7475 - val_opt_loss: 0.0838 - val_sar_loss: 0.1113 - val_fus_loss: 0.0912 - val_loss: 0.2862\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8565 - sar_accuracy: 0.7578 - fus_accuracy: 0.8191 - opt_loss: 0.0784 - sar_loss: 0.1279 - fus_loss: 0.0930 - loss: 0.2994\n",
      "Epoch 00023: val_loss improved from 0.27656 to 0.27471, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 134ms/step - opt_accuracy: 0.8565 - sar_accuracy: 0.7578 - fus_accuracy: 0.8191 - opt_loss: 0.0784 - sar_loss: 0.1279 - fus_loss: 0.0930 - loss: 0.2994 - val_opt_accuracy: 0.8040 - val_sar_accuracy: 0.7063 - val_fus_accuracy: 0.7490 - val_opt_loss: 0.0800 - val_sar_loss: 0.1072 - val_fus_loss: 0.0875 - val_loss: 0.2747\n",
      "Epoch 24/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8578 - sar_accuracy: 0.7590 - fus_accuracy: 0.8221 - opt_loss: 0.0761 - sar_loss: 0.1270 - fus_loss: 0.0892 - loss: 0.2923\n",
      "Epoch 00024: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8581 - sar_accuracy: 0.7594 - fus_accuracy: 0.8224 - opt_loss: 0.0751 - sar_loss: 0.1266 - fus_loss: 0.0878 - loss: 0.2894 - val_opt_accuracy: 0.8079 - val_sar_accuracy: 0.7117 - val_fus_accuracy: 0.7485 - val_opt_loss: 0.0834 - val_sar_loss: 0.1091 - val_fus_loss: 0.0945 - val_loss: 0.2870\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8599 - sar_accuracy: 0.7589 - fus_accuracy: 0.8240 - opt_loss: 0.0838 - sar_loss: 0.1407 - fus_loss: 0.0980 - loss: 0.3224\n",
      "Epoch 00025: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8599 - sar_accuracy: 0.7589 - fus_accuracy: 0.8240 - opt_loss: 0.0838 - sar_loss: 0.1407 - fus_loss: 0.0980 - loss: 0.3224 - val_opt_accuracy: 0.8071 - val_sar_accuracy: 0.7175 - val_fus_accuracy: 0.7479 - val_opt_loss: 0.0845 - val_sar_loss: 0.1155 - val_fus_loss: 0.0975 - val_loss: 0.2974\n",
      "Epoch 26/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8590 - sar_accuracy: 0.7650 - fus_accuracy: 0.8244 - opt_loss: 0.0796 - sar_loss: 0.1302 - fus_loss: 0.0951 - loss: 0.3049\n",
      "Epoch 00026: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 114ms/step - opt_accuracy: 0.8590 - sar_accuracy: 0.7652 - fus_accuracy: 0.8245 - opt_loss: 0.0797 - sar_loss: 0.1300 - fus_loss: 0.0949 - loss: 0.3046 - val_opt_accuracy: 0.8016 - val_sar_accuracy: 0.7130 - val_fus_accuracy: 0.7660 - val_opt_loss: 0.0824 - val_sar_loss: 0.1082 - val_fus_loss: 0.0872 - val_loss: 0.2778\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8601 - sar_accuracy: 0.7635 - fus_accuracy: 0.8270 - opt_loss: 0.0823 - sar_loss: 0.1348 - fus_loss: 0.0958 - loss: 0.3128\n",
      "Epoch 00027: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8601 - sar_accuracy: 0.7635 - fus_accuracy: 0.8270 - opt_loss: 0.0823 - sar_loss: 0.1348 - fus_loss: 0.0958 - loss: 0.3128 - val_opt_accuracy: 0.8084 - val_sar_accuracy: 0.7205 - val_fus_accuracy: 0.7669 - val_opt_loss: 0.0809 - val_sar_loss: 0.1120 - val_fus_loss: 0.0889 - val_loss: 0.2818\n",
      "Epoch 28/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8599 - sar_accuracy: 0.7683 - fus_accuracy: 0.8320 - opt_loss: 0.0780 - sar_loss: 0.1280 - fus_loss: 0.0918 - loss: 0.2978\n",
      "Epoch 00028: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8597 - sar_accuracy: 0.7678 - fus_accuracy: 0.8317 - opt_loss: 0.0788 - sar_loss: 0.1300 - fus_loss: 0.0930 - loss: 0.3019 - val_opt_accuracy: 0.8047 - val_sar_accuracy: 0.7185 - val_fus_accuracy: 0.7744 - val_opt_loss: 0.0818 - val_sar_loss: 0.1103 - val_fus_loss: 0.0865 - val_loss: 0.2786\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8607 - sar_accuracy: 0.7594 - fus_accuracy: 0.8294 - opt_loss: 0.0827 - sar_loss: 0.1376 - fus_loss: 0.0946 - loss: 0.3149\n",
      "Epoch 00029: val_loss did not improve from 0.27471\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8607 - sar_accuracy: 0.7594 - fus_accuracy: 0.8294 - opt_loss: 0.0827 - sar_loss: 0.1376 - fus_loss: 0.0946 - loss: 0.3149 - val_opt_accuracy: 0.8139 - val_sar_accuracy: 0.7174 - val_fus_accuracy: 0.7730 - val_opt_loss: 0.0796 - val_sar_loss: 0.1130 - val_fus_loss: 0.0882 - val_loss: 0.2808\n",
      "Epoch 30/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8633 - sar_accuracy: 0.7673 - fus_accuracy: 0.8361 - opt_loss: 0.0781 - sar_loss: 0.1330 - fus_loss: 0.0900 - loss: 0.3011\n",
      "Epoch 00030: val_loss improved from 0.27471 to 0.27165, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8635 - sar_accuracy: 0.7673 - fus_accuracy: 0.8363 - opt_loss: 0.0768 - sar_loss: 0.1315 - fus_loss: 0.0887 - loss: 0.2971 - val_opt_accuracy: 0.8072 - val_sar_accuracy: 0.7191 - val_fus_accuracy: 0.7737 - val_opt_loss: 0.0786 - val_sar_loss: 0.1095 - val_fus_loss: 0.0836 - val_loss: 0.2716\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8622 - sar_accuracy: 0.7658 - fus_accuracy: 0.8325 - opt_loss: 0.0823 - sar_loss: 0.1416 - fus_loss: 0.0940 - loss: 0.3179\n",
      "Epoch 00031: val_loss did not improve from 0.27165\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8622 - sar_accuracy: 0.7658 - fus_accuracy: 0.8325 - opt_loss: 0.0823 - sar_loss: 0.1416 - fus_loss: 0.0940 - loss: 0.3179 - val_opt_accuracy: 0.8139 - val_sar_accuracy: 0.7237 - val_fus_accuracy: 0.7726 - val_opt_loss: 0.0825 - val_sar_loss: 0.1207 - val_fus_loss: 0.0933 - val_loss: 0.2964\n",
      "Epoch 32/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8616 - sar_accuracy: 0.7676 - fus_accuracy: 0.8324 - opt_loss: 0.0815 - sar_loss: 0.1344 - fus_loss: 0.0951 - loss: 0.3109\n",
      "Epoch 00032: val_loss improved from 0.27165 to 0.26159, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8618 - sar_accuracy: 0.7681 - fus_accuracy: 0.8326 - opt_loss: 0.0804 - sar_loss: 0.1315 - fus_loss: 0.0935 - loss: 0.3054 - val_opt_accuracy: 0.8102 - val_sar_accuracy: 0.7196 - val_fus_accuracy: 0.7850 - val_opt_loss: 0.0764 - val_sar_loss: 0.1065 - val_fus_loss: 0.0786 - val_loss: 0.2616\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8636 - sar_accuracy: 0.7700 - fus_accuracy: 0.8435 - opt_loss: 0.0779 - sar_loss: 0.1314 - fus_loss: 0.0891 - loss: 0.2983\n",
      "Epoch 00033: val_loss did not improve from 0.26159\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8636 - sar_accuracy: 0.7700 - fus_accuracy: 0.8435 - opt_loss: 0.0779 - sar_loss: 0.1314 - fus_loss: 0.0891 - loss: 0.2983 - val_opt_accuracy: 0.8164 - val_sar_accuracy: 0.7229 - val_fus_accuracy: 0.7885 - val_opt_loss: 0.0776 - val_sar_loss: 0.1115 - val_fus_loss: 0.0811 - val_loss: 0.2702\n",
      "Epoch 34/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8646 - sar_accuracy: 0.7719 - fus_accuracy: 0.8449 - opt_loss: 0.0719 - sar_loss: 0.1228 - fus_loss: 0.0814 - loss: 0.2761\n",
      "Epoch 00034: val_loss did not improve from 0.26159\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8648 - sar_accuracy: 0.7719 - fus_accuracy: 0.8452 - opt_loss: 0.0707 - sar_loss: 0.1231 - fus_loss: 0.0801 - loss: 0.2740 - val_opt_accuracy: 0.8188 - val_sar_accuracy: 0.7257 - val_fus_accuracy: 0.7972 - val_opt_loss: 0.0763 - val_sar_loss: 0.1111 - val_fus_loss: 0.0783 - val_loss: 0.2657\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8668 - sar_accuracy: 0.7730 - fus_accuracy: 0.8462 - opt_loss: 0.0754 - sar_loss: 0.1293 - fus_loss: 0.0844 - loss: 0.2891\n",
      "Epoch 00035: val_loss did not improve from 0.26159\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8668 - sar_accuracy: 0.7730 - fus_accuracy: 0.8462 - opt_loss: 0.0754 - sar_loss: 0.1293 - fus_loss: 0.0844 - loss: 0.2891 - val_opt_accuracy: 0.8151 - val_sar_accuracy: 0.7263 - val_fus_accuracy: 0.7952 - val_opt_loss: 0.0778 - val_sar_loss: 0.1073 - val_fus_loss: 0.0809 - val_loss: 0.2660\n",
      "Epoch 36/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8670 - sar_accuracy: 0.7734 - fus_accuracy: 0.8493 - opt_loss: 0.0728 - sar_loss: 0.1299 - fus_loss: 0.0812 - loss: 0.2839\n",
      "Epoch 00036: val_loss did not improve from 0.26159\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8669 - sar_accuracy: 0.7733 - fus_accuracy: 0.8492 - opt_loss: 0.0738 - sar_loss: 0.1306 - fus_loss: 0.0833 - loss: 0.2877 - val_opt_accuracy: 0.8193 - val_sar_accuracy: 0.7239 - val_fus_accuracy: 0.7885 - val_opt_loss: 0.0784 - val_sar_loss: 0.1086 - val_fus_loss: 0.0815 - val_loss: 0.2685\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8648 - sar_accuracy: 0.7748 - fus_accuracy: 0.8379 - opt_loss: 0.0756 - sar_loss: 0.1260 - fus_loss: 0.0858 - loss: 0.2874\n",
      "Epoch 00037: val_loss improved from 0.26159 to 0.26090, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8648 - sar_accuracy: 0.7748 - fus_accuracy: 0.8379 - opt_loss: 0.0756 - sar_loss: 0.1260 - fus_loss: 0.0858 - loss: 0.2874 - val_opt_accuracy: 0.8171 - val_sar_accuracy: 0.7232 - val_fus_accuracy: 0.7921 - val_opt_loss: 0.0759 - val_sar_loss: 0.1065 - val_fus_loss: 0.0785 - val_loss: 0.2609\n",
      "Epoch 38/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8669 - sar_accuracy: 0.7689 - fus_accuracy: 0.8425 - opt_loss: 0.0767 - sar_loss: 0.1363 - fus_loss: 0.0867 - loss: 0.2997\n",
      "Epoch 00038: val_loss did not improve from 0.26090\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8666 - sar_accuracy: 0.7684 - fus_accuracy: 0.8420 - opt_loss: 0.0764 - sar_loss: 0.1356 - fus_loss: 0.0862 - loss: 0.2982 - val_opt_accuracy: 0.8048 - val_sar_accuracy: 0.7248 - val_fus_accuracy: 0.7730 - val_opt_loss: 0.0810 - val_sar_loss: 0.1061 - val_fus_loss: 0.0884 - val_loss: 0.2755\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8668 - sar_accuracy: 0.7702 - fus_accuracy: 0.8408 - opt_loss: 0.0782 - sar_loss: 0.1363 - fus_loss: 0.0883 - loss: 0.3029\n",
      "Epoch 00039: val_loss did not improve from 0.26090\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8668 - sar_accuracy: 0.7702 - fus_accuracy: 0.8408 - opt_loss: 0.0782 - sar_loss: 0.1363 - fus_loss: 0.0883 - loss: 0.3029 - val_opt_accuracy: 0.8212 - val_sar_accuracy: 0.7242 - val_fus_accuracy: 0.7883 - val_opt_loss: 0.0798 - val_sar_loss: 0.1076 - val_fus_loss: 0.0834 - val_loss: 0.2708\n",
      "Epoch 40/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8681 - sar_accuracy: 0.7731 - fus_accuracy: 0.8467 - opt_loss: 0.0757 - sar_loss: 0.1300 - fus_loss: 0.0860 - loss: 0.2917\n",
      "Epoch 00040: val_loss improved from 0.26090 to 0.25853, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8682 - sar_accuracy: 0.7735 - fus_accuracy: 0.8468 - opt_loss: 0.0747 - sar_loss: 0.1274 - fus_loss: 0.0852 - loss: 0.2873 - val_opt_accuracy: 0.8238 - val_sar_accuracy: 0.7254 - val_fus_accuracy: 0.8017 - val_opt_loss: 0.0752 - val_sar_loss: 0.1068 - val_fus_loss: 0.0765 - val_loss: 0.2585\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8680 - sar_accuracy: 0.7741 - fus_accuracy: 0.8503 - opt_loss: 0.0712 - sar_loss: 0.1251 - fus_loss: 0.0795 - loss: 0.2759\n",
      "Epoch 00041: val_loss did not improve from 0.25853\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8680 - sar_accuracy: 0.7741 - fus_accuracy: 0.8503 - opt_loss: 0.0712 - sar_loss: 0.1251 - fus_loss: 0.0795 - loss: 0.2759 - val_opt_accuracy: 0.8164 - val_sar_accuracy: 0.7297 - val_fus_accuracy: 0.8061 - val_opt_loss: 0.0771 - val_sar_loss: 0.1122 - val_fus_loss: 0.0778 - val_loss: 0.2671\n",
      "Epoch 42/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8699 - sar_accuracy: 0.7775 - fus_accuracy: 0.8505 - opt_loss: 0.0734 - sar_loss: 0.1257 - fus_loss: 0.0819 - loss: 0.2810\n",
      "Epoch 00042: val_loss improved from 0.25853 to 0.25807, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 127ms/step - opt_accuracy: 0.8700 - sar_accuracy: 0.7778 - fus_accuracy: 0.8506 - opt_loss: 0.0727 - sar_loss: 0.1234 - fus_loss: 0.0813 - loss: 0.2774 - val_opt_accuracy: 0.8218 - val_sar_accuracy: 0.7293 - val_fus_accuracy: 0.8059 - val_opt_loss: 0.0749 - val_sar_loss: 0.1076 - val_fus_loss: 0.0755 - val_loss: 0.2581\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8690 - sar_accuracy: 0.7781 - fus_accuracy: 0.8496 - opt_loss: 0.0720 - sar_loss: 0.1257 - fus_loss: 0.0815 - loss: 0.2791\n",
      "Epoch 00043: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8690 - sar_accuracy: 0.7781 - fus_accuracy: 0.8496 - opt_loss: 0.0720 - sar_loss: 0.1257 - fus_loss: 0.0815 - loss: 0.2791 - val_opt_accuracy: 0.8173 - val_sar_accuracy: 0.7298 - val_fus_accuracy: 0.8101 - val_opt_loss: 0.0784 - val_sar_loss: 0.1146 - val_fus_loss: 0.0774 - val_loss: 0.2704\n",
      "Epoch 44/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8708 - sar_accuracy: 0.7744 - fus_accuracy: 0.8520 - opt_loss: 0.0706 - sar_loss: 0.1252 - fus_loss: 0.0780 - loss: 0.2738\n",
      "Epoch 00044: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8709 - sar_accuracy: 0.7744 - fus_accuracy: 0.8521 - opt_loss: 0.0694 - sar_loss: 0.1250 - fus_loss: 0.0768 - loss: 0.2713 - val_opt_accuracy: 0.8249 - val_sar_accuracy: 0.7280 - val_fus_accuracy: 0.8165 - val_opt_loss: 0.0754 - val_sar_loss: 0.1134 - val_fus_loss: 0.0747 - val_loss: 0.2635\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8737 - sar_accuracy: 0.7642 - fus_accuracy: 0.8512 - opt_loss: 0.0724 - sar_loss: 0.1359 - fus_loss: 0.0810 - loss: 0.2892\n",
      "Epoch 00045: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8737 - sar_accuracy: 0.7642 - fus_accuracy: 0.8512 - opt_loss: 0.0724 - sar_loss: 0.1359 - fus_loss: 0.0810 - loss: 0.2892 - val_opt_accuracy: 0.8219 - val_sar_accuracy: 0.7297 - val_fus_accuracy: 0.8124 - val_opt_loss: 0.0753 - val_sar_loss: 0.1139 - val_fus_loss: 0.0763 - val_loss: 0.2655\n",
      "Epoch 46/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8716 - sar_accuracy: 0.7738 - fus_accuracy: 0.8558 - opt_loss: 0.0725 - sar_loss: 0.1297 - fus_loss: 0.0798 - loss: 0.2820\n",
      "Epoch 00046: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8718 - sar_accuracy: 0.7740 - fus_accuracy: 0.8559 - opt_loss: 0.0718 - sar_loss: 0.1296 - fus_loss: 0.0789 - loss: 0.2803 - val_opt_accuracy: 0.8229 - val_sar_accuracy: 0.7282 - val_fus_accuracy: 0.8136 - val_opt_loss: 0.0757 - val_sar_loss: 0.1171 - val_fus_loss: 0.0747 - val_loss: 0.2675\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8743 - sar_accuracy: 0.7763 - fus_accuracy: 0.8576 - opt_loss: 0.0709 - sar_loss: 0.1276 - fus_loss: 0.0782 - loss: 0.2767\n",
      "Epoch 00047: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8743 - sar_accuracy: 0.7763 - fus_accuracy: 0.8576 - opt_loss: 0.0709 - sar_loss: 0.1276 - fus_loss: 0.0782 - loss: 0.2767 - val_opt_accuracy: 0.8218 - val_sar_accuracy: 0.7293 - val_fus_accuracy: 0.8163 - val_opt_loss: 0.0753 - val_sar_loss: 0.1092 - val_fus_loss: 0.0745 - val_loss: 0.2589\n",
      "Epoch 48/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8734 - sar_accuracy: 0.7778 - fus_accuracy: 0.8533 - opt_loss: 0.0734 - sar_loss: 0.1278 - fus_loss: 0.0817 - loss: 0.2829\n",
      "Epoch 00048: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8730 - sar_accuracy: 0.7774 - fus_accuracy: 0.8530 - opt_loss: 0.0752 - sar_loss: 0.1317 - fus_loss: 0.0833 - loss: 0.2903 - val_opt_accuracy: 0.8217 - val_sar_accuracy: 0.7303 - val_fus_accuracy: 0.8096 - val_opt_loss: 0.0761 - val_sar_loss: 0.1110 - val_fus_loss: 0.0768 - val_loss: 0.2639\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8723 - sar_accuracy: 0.7792 - fus_accuracy: 0.8546 - opt_loss: 0.0717 - sar_loss: 0.1255 - fus_loss: 0.0788 - loss: 0.2759\n",
      "Epoch 00049: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8723 - sar_accuracy: 0.7792 - fus_accuracy: 0.8546 - opt_loss: 0.0717 - sar_loss: 0.1255 - fus_loss: 0.0788 - loss: 0.2759 - val_opt_accuracy: 0.8188 - val_sar_accuracy: 0.7313 - val_fus_accuracy: 0.8149 - val_opt_loss: 0.0769 - val_sar_loss: 0.1153 - val_fus_loss: 0.0768 - val_loss: 0.2689\n",
      "Epoch 50/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8716 - sar_accuracy: 0.7767 - fus_accuracy: 0.8510 - opt_loss: 0.0720 - sar_loss: 0.1242 - fus_loss: 0.0803 - loss: 0.2765\n",
      "Epoch 00050: val_loss did not improve from 0.25807\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8719 - sar_accuracy: 0.7770 - fus_accuracy: 0.8515 - opt_loss: 0.0703 - sar_loss: 0.1235 - fus_loss: 0.0783 - loss: 0.2721 - val_opt_accuracy: 0.8128 - val_sar_accuracy: 0.7302 - val_fus_accuracy: 0.7982 - val_opt_loss: 0.0800 - val_sar_loss: 0.1075 - val_fus_loss: 0.0834 - val_loss: 0.2709\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8742 - sar_accuracy: 0.7831 - fus_accuracy: 0.8601 - opt_loss: 0.0664 - sar_loss: 0.1192 - fus_loss: 0.0729 - loss: 0.2584\n",
      "Epoch 00051: val_loss improved from 0.25807 to 0.25775, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 135ms/step - opt_accuracy: 0.8742 - sar_accuracy: 0.7831 - fus_accuracy: 0.8601 - opt_loss: 0.0664 - sar_loss: 0.1192 - fus_loss: 0.0729 - loss: 0.2584 - val_opt_accuracy: 0.8235 - val_sar_accuracy: 0.7339 - val_fus_accuracy: 0.8131 - val_opt_loss: 0.0733 - val_sar_loss: 0.1112 - val_fus_loss: 0.0733 - val_loss: 0.2578\n",
      "Epoch 52/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8769 - sar_accuracy: 0.7855 - fus_accuracy: 0.8626 - opt_loss: 0.0668 - sar_loss: 0.1195 - fus_loss: 0.0728 - loss: 0.2591\n",
      "Epoch 00052: val_loss did not improve from 0.25775\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8768 - sar_accuracy: 0.7854 - fus_accuracy: 0.8623 - opt_loss: 0.0665 - sar_loss: 0.1180 - fus_loss: 0.0722 - loss: 0.2568 - val_opt_accuracy: 0.8157 - val_sar_accuracy: 0.7302 - val_fus_accuracy: 0.7939 - val_opt_loss: 0.0791 - val_sar_loss: 0.1062 - val_fus_loss: 0.0844 - val_loss: 0.2697\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8764 - sar_accuracy: 0.7837 - fus_accuracy: 0.8623 - opt_loss: 0.0701 - sar_loss: 0.1251 - fus_loss: 0.0770 - loss: 0.2722\n",
      "Epoch 00053: val_loss did not improve from 0.25775\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8764 - sar_accuracy: 0.7837 - fus_accuracy: 0.8623 - opt_loss: 0.0701 - sar_loss: 0.1251 - fus_loss: 0.0770 - loss: 0.2722 - val_opt_accuracy: 0.8231 - val_sar_accuracy: 0.7328 - val_fus_accuracy: 0.8168 - val_opt_loss: 0.0752 - val_sar_loss: 0.1168 - val_fus_loss: 0.0744 - val_loss: 0.2665\n",
      "Epoch 54/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8750 - sar_accuracy: 0.7851 - fus_accuracy: 0.8583 - opt_loss: 0.0705 - sar_loss: 0.1199 - fus_loss: 0.0770 - loss: 0.2674\n",
      "Epoch 00054: val_loss improved from 0.25775 to 0.25337, saving model to imgs/experiments/exp3/models\\unet_3.h5\n",
      "15/15 [==============================] - 2s 126ms/step - opt_accuracy: 0.8750 - sar_accuracy: 0.7851 - fus_accuracy: 0.8583 - opt_loss: 0.0713 - sar_loss: 0.1215 - fus_loss: 0.0780 - loss: 0.2709 - val_opt_accuracy: 0.8239 - val_sar_accuracy: 0.7377 - val_fus_accuracy: 0.8176 - val_opt_loss: 0.0742 - val_sar_loss: 0.1071 - val_fus_loss: 0.0721 - val_loss: 0.2534\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8783 - sar_accuracy: 0.7889 - fus_accuracy: 0.8623 - opt_loss: 0.0691 - sar_loss: 0.1192 - fus_loss: 0.0757 - loss: 0.2641\n",
      "Epoch 00055: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8783 - sar_accuracy: 0.7889 - fus_accuracy: 0.8623 - opt_loss: 0.0691 - sar_loss: 0.1192 - fus_loss: 0.0757 - loss: 0.2641 - val_opt_accuracy: 0.8224 - val_sar_accuracy: 0.7298 - val_fus_accuracy: 0.8043 - val_opt_loss: 0.0744 - val_sar_loss: 0.1093 - val_fus_loss: 0.0766 - val_loss: 0.2603\n",
      "Epoch 56/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8779 - sar_accuracy: 0.7888 - fus_accuracy: 0.8648 - opt_loss: 0.0681 - sar_loss: 0.1194 - fus_loss: 0.0734 - loss: 0.2608\n",
      "Epoch 00056: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8784 - sar_accuracy: 0.7890 - fus_accuracy: 0.8652 - opt_loss: 0.0655 - sar_loss: 0.1190 - fus_loss: 0.0709 - loss: 0.2555 - val_opt_accuracy: 0.8243 - val_sar_accuracy: 0.7406 - val_fus_accuracy: 0.8174 - val_opt_loss: 0.0742 - val_sar_loss: 0.1139 - val_fus_loss: 0.0736 - val_loss: 0.2617\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8810 - sar_accuracy: 0.7927 - fus_accuracy: 0.8679 - opt_loss: 0.0657 - sar_loss: 0.1158 - fus_loss: 0.0717 - loss: 0.2532\n",
      "Epoch 00057: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8810 - sar_accuracy: 0.7927 - fus_accuracy: 0.8679 - opt_loss: 0.0657 - sar_loss: 0.1158 - fus_loss: 0.0717 - loss: 0.2532 - val_opt_accuracy: 0.8247 - val_sar_accuracy: 0.7310 - val_fus_accuracy: 0.8136 - val_opt_loss: 0.0745 - val_sar_loss: 0.1067 - val_fus_loss: 0.0743 - val_loss: 0.2556\n",
      "Epoch 58/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8797 - sar_accuracy: 0.7888 - fus_accuracy: 0.8655 - opt_loss: 0.0680 - sar_loss: 0.1201 - fus_loss: 0.0738 - loss: 0.2620\n",
      "Epoch 00058: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8799 - sar_accuracy: 0.7893 - fus_accuracy: 0.8657 - opt_loss: 0.0665 - sar_loss: 0.1172 - fus_loss: 0.0719 - loss: 0.2556 - val_opt_accuracy: 0.8199 - val_sar_accuracy: 0.7300 - val_fus_accuracy: 0.8042 - val_opt_loss: 0.0785 - val_sar_loss: 0.1079 - val_fus_loss: 0.0825 - val_loss: 0.2689\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8814 - sar_accuracy: 0.7869 - fus_accuracy: 0.8641 - opt_loss: 0.0656 - sar_loss: 0.1190 - fus_loss: 0.0713 - loss: 0.2559\n",
      "Epoch 00059: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8814 - sar_accuracy: 0.7869 - fus_accuracy: 0.8641 - opt_loss: 0.0656 - sar_loss: 0.1190 - fus_loss: 0.0713 - loss: 0.2559 - val_opt_accuracy: 0.8224 - val_sar_accuracy: 0.7425 - val_fus_accuracy: 0.8216 - val_opt_loss: 0.0746 - val_sar_loss: 0.1110 - val_fus_loss: 0.0724 - val_loss: 0.2580\n",
      "Epoch 60/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8834 - sar_accuracy: 0.7798 - fus_accuracy: 0.8651 - opt_loss: 0.0634 - sar_loss: 0.1247 - fus_loss: 0.0696 - loss: 0.2578\n",
      "Epoch 00060: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 116ms/step - opt_accuracy: 0.8836 - sar_accuracy: 0.7799 - fus_accuracy: 0.8653 - opt_loss: 0.0625 - sar_loss: 0.1227 - fus_loss: 0.0685 - loss: 0.2537 - val_opt_accuracy: 0.8256 - val_sar_accuracy: 0.7363 - val_fus_accuracy: 0.8067 - val_opt_loss: 0.0748 - val_sar_loss: 0.1068 - val_fus_loss: 0.0801 - val_loss: 0.2618\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8841 - sar_accuracy: 0.7915 - fus_accuracy: 0.8683 - opt_loss: 0.0653 - sar_loss: 0.1169 - fus_loss: 0.0711 - loss: 0.2532\n",
      "Epoch 00061: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8841 - sar_accuracy: 0.7915 - fus_accuracy: 0.8683 - opt_loss: 0.0653 - sar_loss: 0.1169 - fus_loss: 0.0711 - loss: 0.2532 - val_opt_accuracy: 0.8211 - val_sar_accuracy: 0.7314 - val_fus_accuracy: 0.8119 - val_opt_loss: 0.0754 - val_sar_loss: 0.1086 - val_fus_loss: 0.0762 - val_loss: 0.2601\n",
      "Epoch 62/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8825 - sar_accuracy: 0.7883 - fus_accuracy: 0.8666 - opt_loss: 0.0667 - sar_loss: 0.1176 - fus_loss: 0.0729 - loss: 0.2573\n",
      "Epoch 00062: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 118ms/step - opt_accuracy: 0.8826 - sar_accuracy: 0.7883 - fus_accuracy: 0.8666 - opt_loss: 0.0666 - sar_loss: 0.1180 - fus_loss: 0.0725 - loss: 0.2571 - val_opt_accuracy: 0.8249 - val_sar_accuracy: 0.7391 - val_fus_accuracy: 0.8241 - val_opt_loss: 0.0739 - val_sar_loss: 0.1138 - val_fus_loss: 0.0726 - val_loss: 0.2603\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8847 - sar_accuracy: 0.7909 - fus_accuracy: 0.8678 - opt_loss: 0.0657 - sar_loss: 0.1168 - fus_loss: 0.0705 - loss: 0.2531\n",
      "Epoch 00063: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8847 - sar_accuracy: 0.7909 - fus_accuracy: 0.8678 - opt_loss: 0.0657 - sar_loss: 0.1168 - fus_loss: 0.0705 - loss: 0.2531 - val_opt_accuracy: 0.8261 - val_sar_accuracy: 0.7332 - val_fus_accuracy: 0.8098 - val_opt_loss: 0.0739 - val_sar_loss: 0.1075 - val_fus_loss: 0.0770 - val_loss: 0.2585\n",
      "Epoch 64/100\n",
      "14/15 [===========================>..] - ETA: 0s - opt_accuracy: 0.8845 - sar_accuracy: 0.7943 - fus_accuracy: 0.8672 - opt_loss: 0.0663 - sar_loss: 0.1156 - fus_loss: 0.0722 - loss: 0.2541\n",
      "Epoch 00064: val_loss did not improve from 0.25337\n",
      "15/15 [==============================] - 2s 117ms/step - opt_accuracy: 0.8846 - sar_accuracy: 0.7942 - fus_accuracy: 0.8673 - opt_loss: 0.0658 - sar_loss: 0.1166 - fus_loss: 0.0716 - loss: 0.2539 - val_opt_accuracy: 0.8278 - val_sar_accuracy: 0.7429 - val_fus_accuracy: 0.8212 - val_opt_loss: 0.0737 - val_sar_loss: 0.1094 - val_fus_loss: 0.0754 - val_loss: 0.2585\n",
      "Epoch 00064: early stopping\n",
      "time:  4\n",
      "Model: \"model_3_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "opt_encoder (UNET_Encoder)   multiple                  2486      \n",
      "_________________________________________________________________\n",
      "sar_encoder (UNET_Encoder)   multiple                  2198      \n",
      "_________________________________________________________________\n",
      "opt_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "sar_decoder (UNET_Decoder)   multiple                  1310      \n",
      "_________________________________________________________________\n",
      "opt_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "sar_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "fus_classifier (Classifier)  multiple                  15        \n",
      "_________________________________________________________________\n",
      "combination (CombinationLaye multiple                  3         \n",
      "_________________________________________________________________\n",
      "opt_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_accuracy (BinaryAccuracy multiple                  2         \n",
      "_________________________________________________________________\n",
      "opt_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "sar_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "fus_loss (Mean)              multiple                  2         \n",
      "_________________________________________________________________\n",
      "loss (Mean)                  multiple                  2         \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,349\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.6819 - sar_accuracy: 0.6185 - fus_accuracy: 0.6645 - opt_loss: 0.1608 - sar_loss: 0.2003 - fus_loss: 0.1600 - loss: 0.5211\n",
      "Epoch 00001: val_loss improved from inf to 0.40072, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 145ms/step - opt_accuracy: 0.6819 - sar_accuracy: 0.6185 - fus_accuracy: 0.6645 - opt_loss: 0.1608 - sar_loss: 0.2003 - fus_loss: 0.1600 - loss: 0.5211 - val_opt_accuracy: 0.7338 - val_sar_accuracy: 0.6269 - val_fus_accuracy: 0.6402 - val_opt_loss: 0.1225 - val_sar_loss: 0.1706 - val_fus_loss: 0.1076 - val_loss: 0.4007\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7834 - sar_accuracy: 0.6544 - fus_accuracy: 0.7426 - opt_loss: 0.1333 - sar_loss: 0.1786 - fus_loss: 0.1488 - loss: 0.4607\n",
      "Epoch 00002: val_loss improved from 0.40072 to 0.38633, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.7834 - sar_accuracy: 0.6544 - fus_accuracy: 0.7426 - opt_loss: 0.1333 - sar_loss: 0.1786 - fus_loss: 0.1488 - loss: 0.4607 - val_opt_accuracy: 0.7408 - val_sar_accuracy: 0.6398 - val_fus_accuracy: 0.7302 - val_opt_loss: 0.1140 - val_sar_loss: 0.1548 - val_fus_loss: 0.1176 - val_loss: 0.3863\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7851 - sar_accuracy: 0.6622 - fus_accuracy: 0.8002 - opt_loss: 0.1200 - sar_loss: 0.1693 - fus_loss: 0.1319 - loss: 0.4212\n",
      "Epoch 00003: val_loss improved from 0.38633 to 0.36070, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 146ms/step - opt_accuracy: 0.7851 - sar_accuracy: 0.6622 - fus_accuracy: 0.8002 - opt_loss: 0.1200 - sar_loss: 0.1693 - fus_loss: 0.1319 - loss: 0.4212 - val_opt_accuracy: 0.7425 - val_sar_accuracy: 0.6303 - val_fus_accuracy: 0.7991 - val_opt_loss: 0.1055 - val_sar_loss: 0.1548 - val_fus_loss: 0.1004 - val_loss: 0.3607\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.7940 - sar_accuracy: 0.6656 - fus_accuracy: 0.8171 - opt_loss: 0.1175 - sar_loss: 0.1684 - fus_loss: 0.1243 - loss: 0.4102\n",
      "Epoch 00004: val_loss improved from 0.36070 to 0.33973, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.7940 - sar_accuracy: 0.6656 - fus_accuracy: 0.8171 - opt_loss: 0.1175 - sar_loss: 0.1684 - fus_loss: 0.1243 - loss: 0.4102 - val_opt_accuracy: 0.7488 - val_sar_accuracy: 0.6101 - val_fus_accuracy: 0.8278 - val_opt_loss: 0.0979 - val_sar_loss: 0.1537 - val_fus_loss: 0.0882 - val_loss: 0.3397\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8389 - sar_accuracy: 0.6566 - fus_accuracy: 0.8328 - opt_loss: 0.1086 - sar_loss: 0.1633 - fus_loss: 0.1159 - loss: 0.3878\n",
      "Epoch 00005: val_loss improved from 0.33973 to 0.32887, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8389 - sar_accuracy: 0.6566 - fus_accuracy: 0.8328 - opt_loss: 0.1086 - sar_loss: 0.1633 - fus_loss: 0.1159 - loss: 0.3878 - val_opt_accuracy: 0.8276 - val_sar_accuracy: 0.5986 - val_fus_accuracy: 0.8374 - val_opt_loss: 0.0878 - val_sar_loss: 0.1514 - val_fus_loss: 0.0896 - val_loss: 0.3289\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8679 - sar_accuracy: 0.6471 - fus_accuracy: 0.8479 - opt_loss: 0.1075 - sar_loss: 0.1647 - fus_loss: 0.1193 - loss: 0.3916\n",
      "Epoch 00006: val_loss improved from 0.32887 to 0.32616, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8679 - sar_accuracy: 0.6471 - fus_accuracy: 0.8479 - opt_loss: 0.1075 - sar_loss: 0.1647 - fus_loss: 0.1193 - loss: 0.3916 - val_opt_accuracy: 0.8377 - val_sar_accuracy: 0.5988 - val_fus_accuracy: 0.8409 - val_opt_loss: 0.0848 - val_sar_loss: 0.1485 - val_fus_loss: 0.0928 - val_loss: 0.3262\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8738 - sar_accuracy: 0.6471 - fus_accuracy: 0.8655 - opt_loss: 0.1000 - sar_loss: 0.1595 - fus_loss: 0.1074 - loss: 0.3669\n",
      "Epoch 00007: val_loss improved from 0.32616 to 0.31734, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8738 - sar_accuracy: 0.6471 - fus_accuracy: 0.8655 - opt_loss: 0.1000 - sar_loss: 0.1595 - fus_loss: 0.1074 - loss: 0.3669 - val_opt_accuracy: 0.8375 - val_sar_accuracy: 0.6051 - val_fus_accuracy: 0.8400 - val_opt_loss: 0.0857 - val_sar_loss: 0.1446 - val_fus_loss: 0.0871 - val_loss: 0.3173\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8722 - sar_accuracy: 0.6476 - fus_accuracy: 0.8645 - opt_loss: 0.1021 - sar_loss: 0.1584 - fus_loss: 0.1080 - loss: 0.3685\n",
      "Epoch 00008: val_loss improved from 0.31734 to 0.31382, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8722 - sar_accuracy: 0.6476 - fus_accuracy: 0.8645 - opt_loss: 0.1021 - sar_loss: 0.1584 - fus_loss: 0.1080 - loss: 0.3685 - val_opt_accuracy: 0.8388 - val_sar_accuracy: 0.6044 - val_fus_accuracy: 0.8418 - val_opt_loss: 0.0854 - val_sar_loss: 0.1421 - val_fus_loss: 0.0863 - val_loss: 0.3138\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8774 - sar_accuracy: 0.6547 - fus_accuracy: 0.8686 - opt_loss: 0.0959 - sar_loss: 0.1526 - fus_loss: 0.1015 - loss: 0.3501\n",
      "Epoch 00009: val_loss improved from 0.31382 to 0.31148, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8774 - sar_accuracy: 0.6547 - fus_accuracy: 0.8686 - opt_loss: 0.0959 - sar_loss: 0.1526 - fus_loss: 0.1015 - loss: 0.3501 - val_opt_accuracy: 0.8390 - val_sar_accuracy: 0.6062 - val_fus_accuracy: 0.8432 - val_opt_loss: 0.0858 - val_sar_loss: 0.1393 - val_fus_loss: 0.0864 - val_loss: 0.3115\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8760 - sar_accuracy: 0.6687 - fus_accuracy: 0.8650 - opt_loss: 0.0949 - sar_loss: 0.1487 - fus_loss: 0.0998 - loss: 0.3435\n",
      "Epoch 00010: val_loss did not improve from 0.31148\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8760 - sar_accuracy: 0.6687 - fus_accuracy: 0.8650 - opt_loss: 0.0949 - sar_loss: 0.1487 - fus_loss: 0.0998 - loss: 0.3435 - val_opt_accuracy: 0.8326 - val_sar_accuracy: 0.6088 - val_fus_accuracy: 0.8428 - val_opt_loss: 0.0883 - val_sar_loss: 0.1362 - val_fus_loss: 0.0870 - val_loss: 0.3115\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8778 - sar_accuracy: 0.6825 - fus_accuracy: 0.8629 - opt_loss: 0.0945 - sar_loss: 0.1475 - fus_loss: 0.0985 - loss: 0.3405\n",
      "Epoch 00011: val_loss improved from 0.31148 to 0.30791, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 134ms/step - opt_accuracy: 0.8778 - sar_accuracy: 0.6825 - fus_accuracy: 0.8629 - opt_loss: 0.0945 - sar_loss: 0.1475 - fus_loss: 0.0985 - loss: 0.3405 - val_opt_accuracy: 0.8409 - val_sar_accuracy: 0.6130 - val_fus_accuracy: 0.8437 - val_opt_loss: 0.0877 - val_sar_loss: 0.1342 - val_fus_loss: 0.0860 - val_loss: 0.3079\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8793 - sar_accuracy: 0.6994 - fus_accuracy: 0.8602 - opt_loss: 0.0908 - sar_loss: 0.1462 - fus_loss: 0.0965 - loss: 0.3335\n",
      "Epoch 00012: val_loss improved from 0.30791 to 0.30613, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 128ms/step - opt_accuracy: 0.8793 - sar_accuracy: 0.6994 - fus_accuracy: 0.8602 - opt_loss: 0.0908 - sar_loss: 0.1462 - fus_loss: 0.0965 - loss: 0.3335 - val_opt_accuracy: 0.8347 - val_sar_accuracy: 0.6162 - val_fus_accuracy: 0.8439 - val_opt_loss: 0.0890 - val_sar_loss: 0.1313 - val_fus_loss: 0.0858 - val_loss: 0.3061\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8803 - sar_accuracy: 0.7100 - fus_accuracy: 0.8573 - opt_loss: 0.0894 - sar_loss: 0.1410 - fus_loss: 0.0961 - loss: 0.3265\n",
      "Epoch 00013: val_loss did not improve from 0.30613\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8803 - sar_accuracy: 0.7100 - fus_accuracy: 0.8573 - opt_loss: 0.0894 - sar_loss: 0.1410 - fus_loss: 0.0961 - loss: 0.3265 - val_opt_accuracy: 0.8339 - val_sar_accuracy: 0.6163 - val_fus_accuracy: 0.8442 - val_opt_loss: 0.0901 - val_sar_loss: 0.1297 - val_fus_loss: 0.0873 - val_loss: 0.3071\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8817 - sar_accuracy: 0.7114 - fus_accuracy: 0.8614 - opt_loss: 0.0911 - sar_loss: 0.1426 - fus_loss: 0.0955 - loss: 0.3291\n",
      "Epoch 00014: val_loss did not improve from 0.30613\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8817 - sar_accuracy: 0.7114 - fus_accuracy: 0.8614 - opt_loss: 0.0911 - sar_loss: 0.1426 - fus_loss: 0.0955 - loss: 0.3291 - val_opt_accuracy: 0.8306 - val_sar_accuracy: 0.6168 - val_fus_accuracy: 0.8380 - val_opt_loss: 0.0921 - val_sar_loss: 0.1296 - val_fus_loss: 0.0888 - val_loss: 0.3104\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8799 - sar_accuracy: 0.7103 - fus_accuracy: 0.8549 - opt_loss: 0.0868 - sar_loss: 0.1388 - fus_loss: 0.0924 - loss: 0.3179\n",
      "Epoch 00015: val_loss did not improve from 0.30613\n",
      "15/15 [==============================] - 2s 121ms/step - opt_accuracy: 0.8799 - sar_accuracy: 0.7103 - fus_accuracy: 0.8549 - opt_loss: 0.0868 - sar_loss: 0.1388 - fus_loss: 0.0924 - loss: 0.3179 - val_opt_accuracy: 0.8171 - val_sar_accuracy: 0.6160 - val_fus_accuracy: 0.8310 - val_opt_loss: 0.0965 - val_sar_loss: 0.1270 - val_fus_loss: 0.0903 - val_loss: 0.3138\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8839 - sar_accuracy: 0.7166 - fus_accuracy: 0.8586 - opt_loss: 0.0855 - sar_loss: 0.1391 - fus_loss: 0.0921 - loss: 0.3167\n",
      "Epoch 00016: val_loss did not improve from 0.30613\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8839 - sar_accuracy: 0.7166 - fus_accuracy: 0.8586 - opt_loss: 0.0855 - sar_loss: 0.1391 - fus_loss: 0.0921 - loss: 0.3167 - val_opt_accuracy: 0.8242 - val_sar_accuracy: 0.6159 - val_fus_accuracy: 0.8383 - val_opt_loss: 0.0928 - val_sar_loss: 0.1260 - val_fus_loss: 0.0877 - val_loss: 0.3066\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8805 - sar_accuracy: 0.7105 - fus_accuracy: 0.8611 - opt_loss: 0.0829 - sar_loss: 0.1358 - fus_loss: 0.0882 - loss: 0.3068\n",
      "Epoch 00017: val_loss improved from 0.30613 to 0.30456, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 133ms/step - opt_accuracy: 0.8805 - sar_accuracy: 0.7105 - fus_accuracy: 0.8611 - opt_loss: 0.0829 - sar_loss: 0.1358 - fus_loss: 0.0882 - loss: 0.3068 - val_opt_accuracy: 0.8260 - val_sar_accuracy: 0.6150 - val_fus_accuracy: 0.8379 - val_opt_loss: 0.0924 - val_sar_loss: 0.1258 - val_fus_loss: 0.0864 - val_loss: 0.3046\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8788 - sar_accuracy: 0.7123 - fus_accuracy: 0.8508 - opt_loss: 0.0946 - sar_loss: 0.1436 - fus_loss: 0.1024 - loss: 0.3406\n",
      "Epoch 00018: val_loss improved from 0.30456 to 0.30215, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8788 - sar_accuracy: 0.7123 - fus_accuracy: 0.8508 - opt_loss: 0.0946 - sar_loss: 0.1436 - fus_loss: 0.1024 - loss: 0.3406 - val_opt_accuracy: 0.8320 - val_sar_accuracy: 0.6169 - val_fus_accuracy: 0.8389 - val_opt_loss: 0.0901 - val_sar_loss: 0.1259 - val_fus_loss: 0.0861 - val_loss: 0.3022\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8828 - sar_accuracy: 0.7129 - fus_accuracy: 0.8697 - opt_loss: 0.0881 - sar_loss: 0.1371 - fus_loss: 0.0902 - loss: 0.3154\n",
      "Epoch 00019: val_loss improved from 0.30215 to 0.29894, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 135ms/step - opt_accuracy: 0.8828 - sar_accuracy: 0.7129 - fus_accuracy: 0.8697 - opt_loss: 0.0881 - sar_loss: 0.1371 - fus_loss: 0.0902 - loss: 0.3154 - val_opt_accuracy: 0.8324 - val_sar_accuracy: 0.6154 - val_fus_accuracy: 0.8424 - val_opt_loss: 0.0907 - val_sar_loss: 0.1239 - val_fus_loss: 0.0843 - val_loss: 0.2989\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8826 - sar_accuracy: 0.7122 - fus_accuracy: 0.8671 - opt_loss: 0.0895 - sar_loss: 0.1412 - fus_loss: 0.0912 - loss: 0.3219\n",
      "Epoch 00020: val_loss did not improve from 0.29894\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8826 - sar_accuracy: 0.7122 - fus_accuracy: 0.8671 - opt_loss: 0.0895 - sar_loss: 0.1412 - fus_loss: 0.0912 - loss: 0.3219 - val_opt_accuracy: 0.8261 - val_sar_accuracy: 0.6145 - val_fus_accuracy: 0.8384 - val_opt_loss: 0.0913 - val_sar_loss: 0.1237 - val_fus_loss: 0.0860 - val_loss: 0.3010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8850 - sar_accuracy: 0.7100 - fus_accuracy: 0.8729 - opt_loss: 0.0842 - sar_loss: 0.1377 - fus_loss: 0.0854 - loss: 0.3073\n",
      "Epoch 00021: val_loss did not improve from 0.29894\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8850 - sar_accuracy: 0.7100 - fus_accuracy: 0.8729 - opt_loss: 0.0842 - sar_loss: 0.1377 - fus_loss: 0.0854 - loss: 0.3073 - val_opt_accuracy: 0.8277 - val_sar_accuracy: 0.6149 - val_fus_accuracy: 0.8368 - val_opt_loss: 0.0917 - val_sar_loss: 0.1237 - val_fus_loss: 0.0869 - val_loss: 0.3023\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8846 - sar_accuracy: 0.7090 - fus_accuracy: 0.8678 - opt_loss: 0.0825 - sar_loss: 0.1333 - fus_loss: 0.0853 - loss: 0.3011\n",
      "Epoch 00022: val_loss improved from 0.29894 to 0.29379, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 128ms/step - opt_accuracy: 0.8846 - sar_accuracy: 0.7090 - fus_accuracy: 0.8678 - opt_loss: 0.0825 - sar_loss: 0.1333 - fus_loss: 0.0853 - loss: 0.3011 - val_opt_accuracy: 0.8266 - val_sar_accuracy: 0.6145 - val_fus_accuracy: 0.8394 - val_opt_loss: 0.0896 - val_sar_loss: 0.1215 - val_fus_loss: 0.0827 - val_loss: 0.2938\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8853 - sar_accuracy: 0.7176 - fus_accuracy: 0.8712 - opt_loss: 0.0853 - sar_loss: 0.1380 - fus_loss: 0.0870 - loss: 0.3103\n",
      "Epoch 00023: val_loss did not improve from 0.29379\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8853 - sar_accuracy: 0.7176 - fus_accuracy: 0.8712 - opt_loss: 0.0853 - sar_loss: 0.1380 - fus_loss: 0.0870 - loss: 0.3103 - val_opt_accuracy: 0.8260 - val_sar_accuracy: 0.6166 - val_fus_accuracy: 0.8365 - val_opt_loss: 0.0895 - val_sar_loss: 0.1216 - val_fus_loss: 0.0843 - val_loss: 0.2953\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8863 - sar_accuracy: 0.7128 - fus_accuracy: 0.8764 - opt_loss: 0.0824 - sar_loss: 0.1357 - fus_loss: 0.0838 - loss: 0.3019\n",
      "Epoch 00024: val_loss improved from 0.29379 to 0.29256, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8863 - sar_accuracy: 0.7128 - fus_accuracy: 0.8764 - opt_loss: 0.0824 - sar_loss: 0.1357 - fus_loss: 0.0838 - loss: 0.3019 - val_opt_accuracy: 0.8222 - val_sar_accuracy: 0.6152 - val_fus_accuracy: 0.8338 - val_opt_loss: 0.0886 - val_sar_loss: 0.1217 - val_fus_loss: 0.0822 - val_loss: 0.2926\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8857 - sar_accuracy: 0.7164 - fus_accuracy: 0.8746 - opt_loss: 0.0848 - sar_loss: 0.1401 - fus_loss: 0.0863 - loss: 0.3112\n",
      "Epoch 00025: val_loss did not improve from 0.29256\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8857 - sar_accuracy: 0.7164 - fus_accuracy: 0.8746 - opt_loss: 0.0848 - sar_loss: 0.1401 - fus_loss: 0.0863 - loss: 0.3112 - val_opt_accuracy: 0.8117 - val_sar_accuracy: 0.6252 - val_fus_accuracy: 0.8173 - val_opt_loss: 0.0910 - val_sar_loss: 0.1211 - val_fus_loss: 0.0880 - val_loss: 0.3002\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8863 - sar_accuracy: 0.7194 - fus_accuracy: 0.8773 - opt_loss: 0.0736 - sar_loss: 0.1290 - fus_loss: 0.0750 - loss: 0.2777\n",
      "Epoch 00026: val_loss improved from 0.29256 to 0.28705, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 131ms/step - opt_accuracy: 0.8863 - sar_accuracy: 0.7194 - fus_accuracy: 0.8773 - opt_loss: 0.0736 - sar_loss: 0.1290 - fus_loss: 0.0750 - loss: 0.2777 - val_opt_accuracy: 0.8253 - val_sar_accuracy: 0.6181 - val_fus_accuracy: 0.8370 - val_opt_loss: 0.0874 - val_sar_loss: 0.1183 - val_fus_loss: 0.0814 - val_loss: 0.2871\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8853 - sar_accuracy: 0.7204 - fus_accuracy: 0.8721 - opt_loss: 0.0786 - sar_loss: 0.1306 - fus_loss: 0.0814 - loss: 0.2905\n",
      "Epoch 00027: val_loss did not improve from 0.28705\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8853 - sar_accuracy: 0.7204 - fus_accuracy: 0.8721 - opt_loss: 0.0786 - sar_loss: 0.1306 - fus_loss: 0.0814 - loss: 0.2905 - val_opt_accuracy: 0.8166 - val_sar_accuracy: 0.6230 - val_fus_accuracy: 0.8225 - val_opt_loss: 0.0899 - val_sar_loss: 0.1181 - val_fus_loss: 0.0840 - val_loss: 0.2920\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8852 - sar_accuracy: 0.7246 - fus_accuracy: 0.8744 - opt_loss: 0.0779 - sar_loss: 0.1300 - fus_loss: 0.0787 - loss: 0.2865\n",
      "Epoch 00028: val_loss did not improve from 0.28705\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8852 - sar_accuracy: 0.7246 - fus_accuracy: 0.8744 - opt_loss: 0.0779 - sar_loss: 0.1300 - fus_loss: 0.0787 - loss: 0.2865 - val_opt_accuracy: 0.8196 - val_sar_accuracy: 0.6220 - val_fus_accuracy: 0.8232 - val_opt_loss: 0.0866 - val_sar_loss: 0.1173 - val_fus_loss: 0.0866 - val_loss: 0.2905\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8852 - sar_accuracy: 0.7240 - fus_accuracy: 0.8786 - opt_loss: 0.0882 - sar_loss: 0.1447 - fus_loss: 0.0881 - loss: 0.3210\n",
      "Epoch 00029: val_loss did not improve from 0.28705\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8852 - sar_accuracy: 0.7240 - fus_accuracy: 0.8786 - opt_loss: 0.0882 - sar_loss: 0.1447 - fus_loss: 0.0881 - loss: 0.3210 - val_opt_accuracy: 0.8232 - val_sar_accuracy: 0.6375 - val_fus_accuracy: 0.8215 - val_opt_loss: 0.0848 - val_sar_loss: 0.1195 - val_fus_loss: 0.0847 - val_loss: 0.2890\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8864 - sar_accuracy: 0.7214 - fus_accuracy: 0.8771 - opt_loss: 0.0753 - sar_loss: 0.1305 - fus_loss: 0.0762 - loss: 0.2819\n",
      "Epoch 00030: val_loss improved from 0.28705 to 0.27942, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8864 - sar_accuracy: 0.7214 - fus_accuracy: 0.8771 - opt_loss: 0.0753 - sar_loss: 0.1305 - fus_loss: 0.0762 - loss: 0.2819 - val_opt_accuracy: 0.8230 - val_sar_accuracy: 0.6276 - val_fus_accuracy: 0.8279 - val_opt_loss: 0.0836 - val_sar_loss: 0.1171 - val_fus_loss: 0.0787 - val_loss: 0.2794\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8882 - sar_accuracy: 0.7236 - fus_accuracy: 0.8799 - opt_loss: 0.0747 - sar_loss: 0.1296 - fus_loss: 0.0754 - loss: 0.2796\n",
      "Epoch 00031: val_loss improved from 0.27942 to 0.27751, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 132ms/step - opt_accuracy: 0.8882 - sar_accuracy: 0.7236 - fus_accuracy: 0.8799 - opt_loss: 0.0747 - sar_loss: 0.1296 - fus_loss: 0.0754 - loss: 0.2796 - val_opt_accuracy: 0.8281 - val_sar_accuracy: 0.6301 - val_fus_accuracy: 0.8293 - val_opt_loss: 0.0813 - val_sar_loss: 0.1158 - val_fus_loss: 0.0804 - val_loss: 0.2775\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8865 - sar_accuracy: 0.7399 - fus_accuracy: 0.8792 - opt_loss: 0.0775 - sar_loss: 0.1346 - fus_loss: 0.0777 - loss: 0.2898\n",
      "Epoch 00032: val_loss did not improve from 0.27751\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8865 - sar_accuracy: 0.7399 - fus_accuracy: 0.8792 - opt_loss: 0.0775 - sar_loss: 0.1346 - fus_loss: 0.0777 - loss: 0.2898 - val_opt_accuracy: 0.8306 - val_sar_accuracy: 0.6401 - val_fus_accuracy: 0.8277 - val_opt_loss: 0.0812 - val_sar_loss: 0.1163 - val_fus_loss: 0.0823 - val_loss: 0.2798\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8911 - sar_accuracy: 0.7288 - fus_accuracy: 0.8850 - opt_loss: 0.0730 - sar_loss: 0.1290 - fus_loss: 0.0734 - loss: 0.2755\n",
      "Epoch 00033: val_loss improved from 0.27751 to 0.27406, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 136ms/step - opt_accuracy: 0.8911 - sar_accuracy: 0.7288 - fus_accuracy: 0.8850 - opt_loss: 0.0730 - sar_loss: 0.1290 - fus_loss: 0.0734 - loss: 0.2755 - val_opt_accuracy: 0.8255 - val_sar_accuracy: 0.6234 - val_fus_accuracy: 0.8293 - val_opt_loss: 0.0810 - val_sar_loss: 0.1161 - val_fus_loss: 0.0770 - val_loss: 0.2741\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8852 - sar_accuracy: 0.7291 - fus_accuracy: 0.8797 - opt_loss: 0.0802 - sar_loss: 0.1358 - fus_loss: 0.0812 - loss: 0.2972\n",
      "Epoch 00034: val_loss improved from 0.27406 to 0.27335, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 130ms/step - opt_accuracy: 0.8852 - sar_accuracy: 0.7291 - fus_accuracy: 0.8797 - opt_loss: 0.0802 - sar_loss: 0.1358 - fus_loss: 0.0812 - loss: 0.2972 - val_opt_accuracy: 0.8330 - val_sar_accuracy: 0.6378 - val_fus_accuracy: 0.8311 - val_opt_loss: 0.0803 - val_sar_loss: 0.1166 - val_fus_loss: 0.0765 - val_loss: 0.2733\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8858 - sar_accuracy: 0.7300 - fus_accuracy: 0.8747 - opt_loss: 0.0747 - sar_loss: 0.1269 - fus_loss: 0.0754 - loss: 0.2771\n",
      "Epoch 00035: val_loss did not improve from 0.27335\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8858 - sar_accuracy: 0.7300 - fus_accuracy: 0.8747 - opt_loss: 0.0747 - sar_loss: 0.1269 - fus_loss: 0.0754 - loss: 0.2771 - val_opt_accuracy: 0.8271 - val_sar_accuracy: 0.6443 - val_fus_accuracy: 0.8226 - val_opt_loss: 0.0809 - val_sar_loss: 0.1166 - val_fus_loss: 0.0808 - val_loss: 0.2784\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8911 - sar_accuracy: 0.7321 - fus_accuracy: 0.8856 - opt_loss: 0.0725 - sar_loss: 0.1296 - fus_loss: 0.0724 - loss: 0.2746\n",
      "Epoch 00036: val_loss did not improve from 0.27335\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8911 - sar_accuracy: 0.7321 - fus_accuracy: 0.8856 - opt_loss: 0.0725 - sar_loss: 0.1296 - fus_loss: 0.0724 - loss: 0.2746 - val_opt_accuracy: 0.8226 - val_sar_accuracy: 0.6330 - val_fus_accuracy: 0.8168 - val_opt_loss: 0.0832 - val_sar_loss: 0.1158 - val_fus_loss: 0.0856 - val_loss: 0.2847\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8883 - sar_accuracy: 0.7311 - fus_accuracy: 0.8820 - opt_loss: 0.0719 - sar_loss: 0.1280 - fus_loss: 0.0720 - loss: 0.2718\n",
      "Epoch 00037: val_loss did not improve from 0.27335\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8883 - sar_accuracy: 0.7311 - fus_accuracy: 0.8820 - opt_loss: 0.0719 - sar_loss: 0.1280 - fus_loss: 0.0720 - loss: 0.2718 - val_opt_accuracy: 0.8252 - val_sar_accuracy: 0.6436 - val_fus_accuracy: 0.8262 - val_opt_loss: 0.0807 - val_sar_loss: 0.1145 - val_fus_loss: 0.0794 - val_loss: 0.2747\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8924 - sar_accuracy: 0.7428 - fus_accuracy: 0.8862 - opt_loss: 0.0712 - sar_loss: 0.1247 - fus_loss: 0.0717 - loss: 0.2676\n",
      "Epoch 00038: val_loss did not improve from 0.27335\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8924 - sar_accuracy: 0.7428 - fus_accuracy: 0.8862 - opt_loss: 0.0712 - sar_loss: 0.1247 - fus_loss: 0.0717 - loss: 0.2676 - val_opt_accuracy: 0.8268 - val_sar_accuracy: 0.6441 - val_fus_accuracy: 0.8244 - val_opt_loss: 0.0810 - val_sar_loss: 0.1159 - val_fus_loss: 0.0778 - val_loss: 0.2747\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8874 - sar_accuracy: 0.7374 - fus_accuracy: 0.8813 - opt_loss: 0.0756 - sar_loss: 0.1333 - fus_loss: 0.0747 - loss: 0.2837\n",
      "Epoch 00039: val_loss did not improve from 0.27335\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8874 - sar_accuracy: 0.7374 - fus_accuracy: 0.8813 - opt_loss: 0.0756 - sar_loss: 0.1333 - fus_loss: 0.0747 - loss: 0.2837 - val_opt_accuracy: 0.8192 - val_sar_accuracy: 0.6780 - val_fus_accuracy: 0.8019 - val_opt_loss: 0.0860 - val_sar_loss: 0.1168 - val_fus_loss: 0.0919 - val_loss: 0.2947\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8924 - sar_accuracy: 0.7440 - fus_accuracy: 0.8841 - opt_loss: 0.0728 - sar_loss: 0.1275 - fus_loss: 0.0738 - loss: 0.2741\n",
      "Epoch 00040: val_loss improved from 0.27335 to 0.27047, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 129ms/step - opt_accuracy: 0.8924 - sar_accuracy: 0.7440 - fus_accuracy: 0.8841 - opt_loss: 0.0728 - sar_loss: 0.1275 - fus_loss: 0.0738 - loss: 0.2741 - val_opt_accuracy: 0.8242 - val_sar_accuracy: 0.6426 - val_fus_accuracy: 0.8286 - val_opt_loss: 0.0815 - val_sar_loss: 0.1138 - val_fus_loss: 0.0751 - val_loss: 0.2705\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8908 - sar_accuracy: 0.7467 - fus_accuracy: 0.8838 - opt_loss: 0.0714 - sar_loss: 0.1277 - fus_loss: 0.0709 - loss: 0.2700\n",
      "Epoch 00041: val_loss did not improve from 0.27047\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8908 - sar_accuracy: 0.7467 - fus_accuracy: 0.8838 - opt_loss: 0.0714 - sar_loss: 0.1277 - fus_loss: 0.0709 - loss: 0.2700 - val_opt_accuracy: 0.8167 - val_sar_accuracy: 0.6619 - val_fus_accuracy: 0.8153 - val_opt_loss: 0.0826 - val_sar_loss: 0.1136 - val_fus_loss: 0.0797 - val_loss: 0.2759\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8922 - sar_accuracy: 0.7427 - fus_accuracy: 0.8861 - opt_loss: 0.0679 - sar_loss: 0.1248 - fus_loss: 0.0679 - loss: 0.2606\n",
      "Epoch 00042: val_loss improved from 0.27047 to 0.26385, saving model to imgs/experiments/exp3/models\\unet_4.h5\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8922 - sar_accuracy: 0.7427 - fus_accuracy: 0.8861 - opt_loss: 0.0679 - sar_loss: 0.1248 - fus_loss: 0.0679 - loss: 0.2606 - val_opt_accuracy: 0.8287 - val_sar_accuracy: 0.6598 - val_fus_accuracy: 0.8284 - val_opt_loss: 0.0788 - val_sar_loss: 0.1119 - val_fus_loss: 0.0731 - val_loss: 0.2638\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8905 - sar_accuracy: 0.7382 - fus_accuracy: 0.8833 - opt_loss: 0.0724 - sar_loss: 0.1296 - fus_loss: 0.0724 - loss: 0.2744\n",
      "Epoch 00043: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8905 - sar_accuracy: 0.7382 - fus_accuracy: 0.8833 - opt_loss: 0.0724 - sar_loss: 0.1296 - fus_loss: 0.0724 - loss: 0.2744 - val_opt_accuracy: 0.8170 - val_sar_accuracy: 0.6719 - val_fus_accuracy: 0.8119 - val_opt_loss: 0.0822 - val_sar_loss: 0.1123 - val_fus_loss: 0.0788 - val_loss: 0.2734\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8910 - sar_accuracy: 0.7677 - fus_accuracy: 0.8858 - opt_loss: 0.0708 - sar_loss: 0.1290 - fus_loss: 0.0694 - loss: 0.2692\n",
      "Epoch 00044: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8910 - sar_accuracy: 0.7677 - fus_accuracy: 0.8858 - opt_loss: 0.0708 - sar_loss: 0.1290 - fus_loss: 0.0694 - loss: 0.2692 - val_opt_accuracy: 0.8277 - val_sar_accuracy: 0.6475 - val_fus_accuracy: 0.8220 - val_opt_loss: 0.0805 - val_sar_loss: 0.1160 - val_fus_loss: 0.0793 - val_loss: 0.2758\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8935 - sar_accuracy: 0.7628 - fus_accuracy: 0.8873 - opt_loss: 0.0695 - sar_loss: 0.1272 - fus_loss: 0.0693 - loss: 0.2661\n",
      "Epoch 00045: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 123ms/step - opt_accuracy: 0.8935 - sar_accuracy: 0.7628 - fus_accuracy: 0.8873 - opt_loss: 0.0695 - sar_loss: 0.1272 - fus_loss: 0.0693 - loss: 0.2661 - val_opt_accuracy: 0.8262 - val_sar_accuracy: 0.6919 - val_fus_accuracy: 0.8224 - val_opt_loss: 0.0810 - val_sar_loss: 0.1079 - val_fus_loss: 0.0761 - val_loss: 0.2651\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8946 - sar_accuracy: 0.7587 - fus_accuracy: 0.8903 - opt_loss: 0.0641 - sar_loss: 0.1233 - fus_loss: 0.0637 - loss: 0.2511\n",
      "Epoch 00046: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8946 - sar_accuracy: 0.7587 - fus_accuracy: 0.8903 - opt_loss: 0.0641 - sar_loss: 0.1233 - fus_loss: 0.0637 - loss: 0.2511 - val_opt_accuracy: 0.8131 - val_sar_accuracy: 0.7031 - val_fus_accuracy: 0.7924 - val_opt_loss: 0.0843 - val_sar_loss: 0.1111 - val_fus_loss: 0.0873 - val_loss: 0.2826\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8934 - sar_accuracy: 0.7622 - fus_accuracy: 0.8869 - opt_loss: 0.0664 - sar_loss: 0.1230 - fus_loss: 0.0662 - loss: 0.2556\n",
      "Epoch 00047: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 125ms/step - opt_accuracy: 0.8934 - sar_accuracy: 0.7622 - fus_accuracy: 0.8869 - opt_loss: 0.0664 - sar_loss: 0.1230 - fus_loss: 0.0662 - loss: 0.2556 - val_opt_accuracy: 0.8153 - val_sar_accuracy: 0.6372 - val_fus_accuracy: 0.8207 - val_opt_loss: 0.0868 - val_sar_loss: 0.1157 - val_fus_loss: 0.0773 - val_loss: 0.2798\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8920 - sar_accuracy: 0.7555 - fus_accuracy: 0.8840 - opt_loss: 0.0641 - sar_loss: 0.1216 - fus_loss: 0.0651 - loss: 0.2507\n",
      "Epoch 00048: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8920 - sar_accuracy: 0.7555 - fus_accuracy: 0.8840 - opt_loss: 0.0641 - sar_loss: 0.1216 - fus_loss: 0.0651 - loss: 0.2507 - val_opt_accuracy: 0.8296 - val_sar_accuracy: 0.6544 - val_fus_accuracy: 0.8270 - val_opt_loss: 0.0787 - val_sar_loss: 0.1148 - val_fus_loss: 0.0760 - val_loss: 0.2695\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8914 - sar_accuracy: 0.7618 - fus_accuracy: 0.8871 - opt_loss: 0.0656 - sar_loss: 0.1265 - fus_loss: 0.0652 - loss: 0.2573\n",
      "Epoch 00049: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 122ms/step - opt_accuracy: 0.8914 - sar_accuracy: 0.7618 - fus_accuracy: 0.8871 - opt_loss: 0.0656 - sar_loss: 0.1265 - fus_loss: 0.0652 - loss: 0.2573 - val_opt_accuracy: 0.8172 - val_sar_accuracy: 0.6706 - val_fus_accuracy: 0.8107 - val_opt_loss: 0.0903 - val_sar_loss: 0.1138 - val_fus_loss: 0.0926 - val_loss: 0.2967\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8971 - sar_accuracy: 0.7495 - fus_accuracy: 0.8918 - opt_loss: 0.0630 - sar_loss: 0.1269 - fus_loss: 0.0627 - loss: 0.2526\n",
      "Epoch 00050: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 119ms/step - opt_accuracy: 0.8971 - sar_accuracy: 0.7495 - fus_accuracy: 0.8918 - opt_loss: 0.0630 - sar_loss: 0.1269 - fus_loss: 0.0627 - loss: 0.2526 - val_opt_accuracy: 0.8198 - val_sar_accuracy: 0.7027 - val_fus_accuracy: 0.8067 - val_opt_loss: 0.0850 - val_sar_loss: 0.1111 - val_fus_loss: 0.0853 - val_loss: 0.2813\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8945 - sar_accuracy: 0.7729 - fus_accuracy: 0.8908 - opt_loss: 0.0627 - sar_loss: 0.1232 - fus_loss: 0.0624 - loss: 0.2483\n",
      "Epoch 00051: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 124ms/step - opt_accuracy: 0.8945 - sar_accuracy: 0.7729 - fus_accuracy: 0.8908 - opt_loss: 0.0627 - sar_loss: 0.1232 - fus_loss: 0.0624 - loss: 0.2483 - val_opt_accuracy: 0.8140 - val_sar_accuracy: 0.6765 - val_fus_accuracy: 0.8080 - val_opt_loss: 0.0855 - val_sar_loss: 0.1113 - val_fus_loss: 0.0834 - val_loss: 0.2802\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - ETA: 0s - opt_accuracy: 0.8945 - sar_accuracy: 0.7741 - fus_accuracy: 0.8956 - opt_loss: 0.0644 - sar_loss: 0.1215 - fus_loss: 0.0644 - loss: 0.2503\n",
      "Epoch 00052: val_loss did not improve from 0.26385\n",
      "15/15 [==============================] - 2s 120ms/step - opt_accuracy: 0.8945 - sar_accuracy: 0.7741 - fus_accuracy: 0.8956 - opt_loss: 0.0644 - sar_loss: 0.1215 - fus_loss: 0.0644 - loss: 0.2503 - val_opt_accuracy: 0.8146 - val_sar_accuracy: 0.7003 - val_fus_accuracy: 0.8079 - val_opt_loss: 0.0872 - val_sar_loss: 0.1080 - val_fus_loss: 0.0844 - val_loss: 0.2796\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "metrics_all = []\n",
    "times=5\n",
    "for tm in range(0,times):\n",
    "    print('time: ', tm)\n",
    "\n",
    "    rows = patch_size\n",
    "    cols = patch_size\n",
    "    adam = Adam(lr = 1e-3 , beta_1=0.9)\n",
    "    \n",
    "    #loss = weighted_categorical_crossentropy(weights)\n",
    "    loss = WBCE(weights = weights)\n",
    "    #loss = WBCE(weights = weights, class_indexes = [0, 1])\n",
    "\n",
    "    #if method == 'unet':\n",
    "    #   model = build_unet(input_shape, nb_filters, number_class)\n",
    "\n",
    "    #if method == 'resunet':\n",
    "    #   model = build_resunet(input_shape, nb_filters, number_class)\n",
    "    \n",
    "    model = Model_3(nb_filters, number_class, n_opt_layers)\n",
    "    model.build((None,)+input_shape)\n",
    "    \n",
    "    model.compile(optimizer=adam, loss=loss, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min')\n",
    "    #earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min') ---- val_accuracy\n",
    "    #checkpoint = ModelCheckpoint(path_models+ '/' + method +'_'+str(tm)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    checkpoint = ModelCheckpoint(path_models+ '/' + method +'_'+str(tm)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "    #lr_reduce = ReduceLROnPlateau(factor=0.9, min_delta=0.0001, patience=5, verbose=1)\n",
    "    callbacks_list = [earlystop, checkpoint]\n",
    "    # train the model\n",
    "    start_training = time.time()\n",
    "    history = model.fit(train_gen_crops,\n",
    "                              steps_per_epoch=len(X_train)*3//train_gen.batch_size,\n",
    "                              validation_data=valid_gen_crops,\n",
    "                              validation_steps=len(X_valid)*3//valid_gen.batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks_list)\n",
    "    end_training = time.time() - start_training\n",
    "    metrics_all.append(end_training)\n",
    "    del model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nMem2rkfpL-g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 -16.0\n",
      "time:  0\n",
      "time:  1\n",
      "time:  2\n",
      "time:  3\n",
      "time:  4\n"
     ]
    }
   ],
   "source": [
    "# Test loop\n",
    "time_ts = []\n",
    "n_pool = 3\n",
    "n_rows = 5\n",
    "n_cols = 4\n",
    "rows, cols = image_array.shape[:2]\n",
    "pad_rows = rows - np.ceil(rows/(n_rows*2**n_pool))*n_rows*2**n_pool\n",
    "pad_cols = cols - np.ceil(cols/(n_cols*2**n_pool))*n_cols*2**n_pool\n",
    "print(pad_rows, pad_cols)\n",
    "\n",
    "npad = ((0, int(abs(pad_rows))), (0, int(abs(pad_cols))), (0, 0))\n",
    "image1_pad = np.pad(image_array, pad_width=npad, mode='reflect')\n",
    "\n",
    "h, w, c = image1_pad.shape\n",
    "patch_size_rows = h//n_rows\n",
    "patch_size_cols = w//n_cols\n",
    "num_patches_x = int(h/patch_size_rows)\n",
    "num_patches_y = int(w/patch_size_cols)\n",
    "\n",
    "input_shape=(patch_size_rows,patch_size_cols, c)\n",
    "\n",
    "#if method == 'unet':\n",
    "#   new_model = build_unet(input_shape, nb_filters, number_class)\n",
    "\n",
    "#if method == 'resunet':\n",
    "#   new_model = build_resunet(input_shape, nb_filters, number_class)\n",
    "\n",
    "new_model = Model_3(nb_filters, number_class, n_opt_layers)\n",
    "new_model.build((None,)+input_shape)\n",
    "adam = Adam(lr = 1e-3 , beta_1=0.9)\n",
    "loss = WBCE(weights = weights)\n",
    "#loss = weighted_categorical_crossentropy(weights)\n",
    "new_model.compile(optimizer=adam, loss=loss, metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "for tm in range(0,times):\n",
    "    print('time: ', tm)\n",
    "    #model = load_model(path_models+ '/' + method +'_'+str(tm)+'.h5', compile=False)\n",
    "    \n",
    "    #for l in range(1, len(model.layers)):\n",
    "    #    new_model.layers[l].set_weights(model.layers[l].get_weights())\n",
    "    new_model.load_weights(path_models+ '/' + method +'_'+str(tm)+'.h5')\n",
    "    \n",
    "    start_test = time.time()\n",
    "    patch_opt = []\n",
    "    patch_sar = []\n",
    "    patch_fus = []\n",
    "    patch_comb = []\n",
    "    \n",
    "    for i in range(0,num_patches_y):\n",
    "        for j in range(0,num_patches_x):\n",
    "            patch = image1_pad[patch_size_rows*j:patch_size_rows*(j+1), patch_size_cols*i:patch_size_cols*(i+1), :]\n",
    "            pred_opt, pred_sar, pred_fus, pred_comb = new_model.predict(np.expand_dims(patch, axis=0))\n",
    "            del patch \n",
    "            patch_opt.append(pred_opt[:,:,:,1])\n",
    "            patch_sar.append(pred_sar[:,:,:,1])\n",
    "            patch_fus.append(pred_fus[:,:,:,1])\n",
    "            patch_comb.append(pred_comb[:,:,:,1])\n",
    "            del pred_opt, pred_sar, pred_fus, pred_comb\n",
    "    end_test =  time.time() - start_test\n",
    "\n",
    "    patches_pred_opt = np.asarray(patch_opt).astype(np.float32)\n",
    "    patches_pred_sar = np.asarray(patch_sar).astype(np.float32)\n",
    "    patches_pred_fus = np.asarray(patch_fus).astype(np.float32)\n",
    "    patches_pred_comb = np.asarray(patch_comb).astype(np.float32)\n",
    "\n",
    "    prob_recontructed_opt = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred_opt)\n",
    "    prob_recontructed_sar = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred_sar)\n",
    "    prob_recontructed_fus = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred_fus)\n",
    "    prob_recontructed_comb = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred_comb)\n",
    "\n",
    "    del patches_pred_opt, patches_pred_sar, patches_pred_fus, patches_pred_comb\n",
    "    np.save(path_maps+'/'+'prob_opt_'+str(tm)+'.npy',prob_recontructed_opt) \n",
    "    np.save(path_maps+'/'+'prob_sar_'+str(tm)+'.npy',prob_recontructed_sar) \n",
    "    np.save(path_maps+'/'+'prob_fus_'+str(tm)+'.npy',prob_recontructed_fus) \n",
    "    np.save(path_maps+'/'+'prob_comb_'+str(tm)+'.npy',prob_recontructed_comb) \n",
    "\n",
    "    time_ts.append(end_test)\n",
    "    del prob_recontructed_opt, prob_recontructed_sar, prob_recontructed_fus, prob_recontructed_comb\n",
    "    #del model\n",
    "time_ts_array = np.asarray(time_ts)\n",
    "# Save test time\n",
    "np.save(path_exp+'/metrics_ts.npy', time_ts_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ehh68acZW2lR"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 430. MiB for an array with shape (4000, 2816, 5) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_22204/3725852514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute mean of the tm predictions maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprob_rec_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprob_rec_sar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprob_rec_fus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprob_rec_comb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage1_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 430. MiB for an array with shape (4000, 2816, 5) and data type float64"
     ]
    }
   ],
   "source": [
    "# Compute mean of the tm predictions maps\n",
    "prob_rec_opt = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n",
    "prob_rec_sar = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n",
    "prob_rec_fus = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n",
    "prob_rec_comb = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n",
    "\n",
    "for tm in range (0, times):\n",
    "    print(tm)\n",
    "    prob_rec_opt[:,:,tm] = np.load(path_maps+'/'+'prob_opt_'+str(tm)+'.npy').astype(np.float32)\n",
    "    prob_rec_sar[:,:,tm] = np.load(path_maps+'/'+'prob_sar_'+str(tm)+'.npy').astype(np.float32)\n",
    "    prob_rec_fus[:,:,tm] = np.load(path_maps+'/'+'prob_fus_'+str(tm)+'.npy').astype(np.float32)\n",
    "    prob_rec_comb[:,:,tm] = np.load(path_maps+'/'+'prob_comb_'+str(tm)+'.npy').astype(np.float32)\n",
    "\n",
    "mean_prob_opt = np.mean(prob_rec_opt, axis = -1)\n",
    "mean_prob_sar = np.mean(prob_rec_sar, axis = -1)\n",
    "mean_prob_fus = np.mean(prob_rec_fus, axis = -1)\n",
    "mean_prob_comb = np.mean(prob_rec_comb, axis = -1)\n",
    "\n",
    "np.save(path_maps+'/prob_mean_opt.npy', mean_prob_opt)\n",
    "np.save(path_maps+'/prob_mean_sar.npy', mean_prob_sar)\n",
    "np.save(path_maps+'/prob_mean_fus.npy', mean_prob_fus)\n",
    "np.save(path_maps+'/prob_mean_comb.npy', mean_prob_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVDldxUWckvg"
   },
   "outputs": [],
   "source": [
    "# Plot mean map and reference\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(151)\n",
    "plt.title('OPT Prediction')\n",
    "ax1.imshow(mean_prob_opt, cmap ='jet')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax1 = fig.add_subplot(152)\n",
    "plt.title('SAR Prediction')\n",
    "ax1.imshow(mean_prob_sar, cmap ='jet')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax1 = fig.add_subplot(153)\n",
    "plt.title('FUSION Prediction')\n",
    "ax1.imshow(mean_prob_fus, cmap ='jet')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax1 = fig.add_subplot(154)\n",
    "plt.title('COMBINATION Prediction')\n",
    "ax1.imshow(mean_prob_comb, cmap ='jet')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(155)\n",
    "plt.title('Reference')\n",
    "ax2.imshow(final_mask1, cmap ='jet')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4P8pVKDxW6Lh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computing metrics\n",
    "mean_prob_opt = mean_prob_opt[:final_mask1.shape[0], :final_mask1.shape[1]]\n",
    "mean_prob_sar = mean_prob_sar[:final_mask1.shape[0], :final_mask1.shape[1]]\n",
    "mean_prob_fus = mean_prob_fus[:final_mask1.shape[0], :final_mask1.shape[1]]\n",
    "mean_prob_comb = mean_prob_comb[:final_mask1.shape[0], :final_mask1.shape[1]]\n",
    "\n",
    "ref1 = np.ones_like(final_mask1).astype(np.float32)\n",
    "\n",
    "ref1 [final_mask1 == 2] = 0\n",
    "TileMask = mask_amazon_ts * ref1\n",
    "GTTruePositives = final_mask1==1\n",
    "    \n",
    "Npoints = 10\n",
    "\n",
    "Pmax_opt = np.max(mean_prob_opt[GTTruePositives * TileMask ==1])\n",
    "ProbList_opt = np.linspace(Pmax_opt,0,Npoints)\n",
    "\n",
    "Pmax_sar = np.max(mean_prob_sar[GTTruePositives * TileMask ==1])\n",
    "ProbList_sar = np.linspace(Pmax_sar,0,Npoints)\n",
    "\n",
    "Pmax_fus = np.max(mean_prob_fus[GTTruePositives * TileMask ==1])\n",
    "ProbList_fus = np.linspace(Pmax_fus,0,Npoints)\n",
    "\n",
    "Pmax_comb = np.max(mean_prob_comb[GTTruePositives * TileMask ==1])\n",
    "ProbList_comb = np.linspace(Pmax_comb,0,Npoints)\n",
    "    \n",
    "metrics_opt = matrics_AA_recall(ProbList_opt, mean_prob_opt, final_mask1, mask_amazon_ts, 625)\n",
    "metrics_sar = matrics_AA_recall(ProbList_sar, mean_prob_sar, final_mask1, mask_amazon_ts, 625)\n",
    "metrics_fus = matrics_AA_recall(ProbList_fus, mean_prob_fus, final_mask1, mask_amazon_ts, 625)\n",
    "metrics_comb = matrics_AA_recall(ProbList_comb, mean_prob_comb, final_mask1, mask_amazon_ts, 625)\n",
    "\n",
    "np.save(path_exp+'/acc_metrics_opt.npy',metrics_opt)\n",
    "np.save(path_exp+'/acc_metrics_sar.npy',metrics_sar)\n",
    "np.save(path_exp+'/acc_metrics_fus.npy',metrics_fus)\n",
    "np.save(path_exp+'/acc_metrics_comb.npy',metrics_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB-vr1sq6PwK"
   },
   "outputs": [],
   "source": [
    "# Complete NaN values\n",
    "metrics_copy_opt = metrics_opt.copy()\n",
    "metrics_copy_opt = complete_nan_values(metrics_copy_opt)\n",
    "\n",
    "metrics_copy_sar = metrics_sar.copy()\n",
    "metrics_copy_sar = complete_nan_values(metrics_copy_sar)\n",
    "\n",
    "metrics_copy_fus = metrics_fus.copy()\n",
    "metrics_copy_fus = complete_nan_values(metrics_copy_fus)\n",
    "\n",
    "metrics_copy_comb = metrics_comb.copy()\n",
    "metrics_copy_comb = complete_nan_values(metrics_copy_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HNG_I2cW8JF"
   },
   "outputs": [],
   "source": [
    "# Comput Mean Average Precision (mAP) score \n",
    "Recall_opt = metrics_copy_opt[:,0]\n",
    "Precision_opt = metrics_copy_opt[:,1]\n",
    "AA_opt = metrics_copy_opt[:,2]\n",
    "\n",
    "Recall_sar = metrics_copy_sar[:,0]\n",
    "Precision_sar = metrics_copy_sar[:,1]\n",
    "AA_sar = metrics_copy_sar[:,2]\n",
    "\n",
    "Recall_fus = metrics_copy_fus[:,0]\n",
    "Precision_fus = metrics_copy_fus[:,1]\n",
    "AA_fus = metrics_copy_fus[:,2]\n",
    "\n",
    "Recall_comb = metrics_copy_comb[:,0]\n",
    "Precision_comb = metrics_copy_comb[:,1]\n",
    "AA_comb = metrics_copy_comb[:,2]\n",
    "    \n",
    "DeltaR_opt = Recall_opt[1:]-Recall_opt[:-1]\n",
    "AP_opt = np.sum(Precision_opt[:-1]*DeltaR_opt)\n",
    "print('OPT mAP', AP_opt)\n",
    "\n",
    "DeltaR_sar = Recall_sar[1:]-Recall_sar[:-1]\n",
    "AP_sar = np.sum(Precision_sar[:-1]*DeltaR_sar)\n",
    "print('SAR mAP', AP_sar)\n",
    "\n",
    "DeltaR_fus = Recall_fus[1:]-Recall_fus[:-1]\n",
    "AP_fus = np.sum(Precision_fus[:-1]*DeltaR_fus)\n",
    "print('FUSION mAP', AP_fus)\n",
    "\n",
    "DeltaR_comb = Recall_comb[1:]-Recall_comb[:-1]\n",
    "AP_comb = np.sum(Precision_comb[:-1]*DeltaR_comb)\n",
    "print('COMBINATION mAP', AP_comb)\n",
    "\n",
    "# Plot Recall vs. Precision curve\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(metrics_copy_opt[:,0],metrics_copy_opt[:,1], 'r-', label = f'OPT (AP: {AP_opt:.4f})')\n",
    "plt.plot(metrics_copy_sar[:,0],metrics_copy_sar[:,1], 'g-', label = f'SAR (AP: {AP_sar:.4f})')\n",
    "plt.plot(metrics_copy_fus[:,0],metrics_copy_fus[:,1], 'b-', label = f'FUSION (AP: {AP_fus:.4f})')\n",
    "plt.plot(metrics_copy_comb[:,0],metrics_copy_comb[:,1], 'k-', label = f'COMBINATION (AP: {AP_comb:.4f})')\n",
    "plt.legend(loc=\"lower left\")\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlim([0,1])\n",
    "#plt.plot(metrics_copy[:,0],metrics_copy[:,2])\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net and Res-Unet tf2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b08b86eefb6f9027df8c705c57ad3330ee722a1038604439ab9df613faded208"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('proj_2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
