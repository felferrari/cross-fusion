{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import shutil, os\n",
    "from ops import load_opt, load_sar, generate_save_patches, min_max_scaler\n",
    "import numpy as np\n",
    "import logging\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "import skimage.morphology\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from model.models import Model_1\n",
    "from model.losses import FocalLoss, WBCE\n",
    "from tensorflow.keras.layers import Input\n",
    "from dataloader import DataLoader\n",
    "from tensorflow.keras.optimizers.schedules import InverseTimeDecay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the params-patches.json options\n",
    "with open(os.path.join('v1', 'params-patches.json')) as param_file:\n",
    "    params_patches = json.load(param_file)\n",
    "\n",
    "# load the params-patches.json options\n",
    "with open(os.path.join('v1', 'params-training.json')) as param_file:\n",
    "    params_training = json.load(param_file)\n",
    "    \n",
    "#load the params-model.json options\n",
    "with open(os.path.join('v1', 'params-model.json')) as param_file:\n",
    "    params_model = json.load(param_file)\n",
    "\n",
    "#load the shapes.json options\n",
    "with open('shapes.json') as param_file:\n",
    "    shapes_json = json.load(param_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patches_path = params_patches['patches_path']\n",
    "\n",
    "#train_path = os.path.join(patches_path, params_patches['train_sub'])\n",
    "#val_path = os.path.join(patches_path, params_patches['val_sub'])\n",
    "#test_path = os.path.join(patches_path, params_patches['test_sub'])\n",
    "#full_path = params_patches['full_path']\n",
    "\n",
    "img_path = params_patches['img_path']\n",
    "data_raw = os.path.join(img_path, params_patches['data_sub']) \n",
    "label_raw = os.path.join(img_path, params_patches['label_sub'])\n",
    "\n",
    "pred_path = params_patches['pred_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_1(name='modelo_1')\n",
    "\n",
    "metrics = {\n",
    "}\n",
    "\n",
    "weights = [0.2, 0.8, 0.0]\n",
    "\n",
    "\n",
    "optimizers = {\n",
    "    'opt': tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
    "    'sar': tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
    "    'fusion': tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
    "}\n",
    "\n",
    "class_indexes = [0, 1]\n",
    "\n",
    "model.compile(\n",
    "    optimizers = optimizers,\n",
    "    loss_fn = WBCE,\n",
    "    metrics_dict = metrics,\n",
    "    class_weights = weights,\n",
    "    class_indexes = class_indexes,\n",
    "    run_eagerly=params_training['run_eagerly']\n",
    ")\n",
    "\n",
    "model.build(\n",
    "    input_shape = [\n",
    "        (None, params_patches['patch_size'], params_patches['patch_size'], params_model['opt_channels']),\n",
    "        (None, params_patches['patch_size'], params_patches['patch_size'], params_model['sar_channels'])\n",
    "    ]\n",
    "    )\n",
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.load(os.path.join(data_raw, 'opt.npy'))\n",
    "sar = np.load(os.path.join(data_raw, 'sar.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights\n",
    "bn_layers_0 = [w for w in model.weights if 'bn_' in w.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9990 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer opt_encoder is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer sar_encoder is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9990/9990 [13:40<00:00, 12.18it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_from_patches(\n",
    "    (opt, sar), \n",
    "    params_patches['patch_size'], \n",
    "    params_patches['patch_stride'], \n",
    "    16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights\n",
    "bn_layers_1 = [w for w in model.weights if 'bn_' in w.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(bn_layers_1):\n",
    "    diff = bn_layers_1[i] - bn_layers_0[i] \n",
    "    print(tf.reduce_max(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(os.path.join(label_raw, 'labels.npy'))\n",
    "labels = to_categorical(labels, 3)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.squeeze(np.uint8(pred[0]*255))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize = (25,8))\n",
    "\n",
    "\n",
    "img = Image.fromarray(np.uint8(labels*255))\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title(f'Label')\n",
    "ax[0].imshow(img, cmap = 'gray')\n",
    "\n",
    "img = Image.fromarray(np.squeeze(np.uint8(pred[0]*255)))\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title(f'OPT')\n",
    "ax[1].imshow(img, cmap = 'gray')\n",
    "\n",
    "img = Image.fromarray(np.squeeze(np.uint8(pred[1]*255)))\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title(f'SAR')\n",
    "ax[2].imshow(img, cmap = 'gray')\n",
    "\n",
    "img = Image.fromarray(np.squeeze(np.uint8(pred[2]*255)))\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title(f'FUSION')\n",
    "ax[3].imshow(img, cmap = 'gray')\n",
    "\n",
    "img = Image.fromarray(np.squeeze(np.uint8(pred[3]*255)))\n",
    "ax[4].axis('off')\n",
    "ax[4].set_title(f'COMBINED')\n",
    "ax[4].imshow(img, cmap = 'gray')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(pred_path, 'opt.npy'), np.squeeze(pred[0]))\n",
    "np.save(os.path.join(pred_path, 'sar.npy'), np.squeeze(pred[1]))\n",
    "np.save(os.path.join(pred_path, 'fusion.npy'), np.squeeze(pred[2]))\n",
    "np.save(os.path.join(pred_path, 'combination.npy'), np.squeeze(pred[3]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b08b86eefb6f9027df8c705c57ad3330ee722a1038604439ab9df613faded208"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('proj_2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
