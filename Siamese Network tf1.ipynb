{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Siamese Network tf1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"2L_yKE1IgpA0"},"source":["%load_ext autoreload"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5gJbpqWtgdw"},"source":["%autoreload # When utils.py is updated\n","from utils_siamese import *\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","root_path = '/your_directory' \n","print(root_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1PrXGBIiimC0"},"source":["# Define data type (L8-Landsat8, S2-Sentinel2, S1-Sentinel1)\n","img_type = 'L8'\n","\n","if img_type = 'L8':\n","    # Load images\n","    ref_2019 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2019.tif').astype('float32') # actual 2019\n","    opt_2018 = load_tif_image(root_path+'New_Images/Landsat8/'+'cut_land8_2018.tif').astype('float32')   \n","    opt_2019 = load_tif_image(root_path+'New_Images/Landsat8/'+'cut_land8_2019.tif').astype('float32')\n","\n","    # Resize images\n","    opt_2018 = resize_image(opt_2018.copy(), ref_2019.shape[0], ref_2019.shape[1])\n","    opt_2019 = resize_image(opt_2019.copy(), ref_2019.shape[0], ref_2019.shape[1])  \n","\n","    # Filter outliers\n","    opt_2018 = filter_outliers(opt_2018.copy()) \n","    opt_2019 = filter_outliers(opt_2019.copy())\n","    \n","    image_stack = np.concatenate((opt_2018, opt_2019), axis=-1)\n","    print('landsat_resize:', image_stack.shape)\n","    del opt_2018, opt_2019\n","\n","if img_type = 'S2':\n","    # Load images\n","    sent2_2018_1 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2018_10m_b2348.tif').astype('float32')\n","    sent2_2018_2 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2018_20m_b5678a1112.tif').astype('float32')\n","    \n","    # Resize bands of 20m\n","    sent2_2018_2 = resize_image(sent2_2018_2.copy(), sent2_2018_1.shape[0], sent2_2018_1.shape[1])\n","    sent2_2018 = np.concatenate((sent2_2018_1, sent2_2018_2), axis=-1)\n","    del sent2_2018_1, sent2_2018_2\n","    \n","    sent2_2019_1 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2019_10m_b2348.tif').astype('float32')\n","    sent2_2019_2 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2019_20m_b5678a1112.tif').astype('float32')   \n","    \n","    # Resize bands of 20m\n","    sent2_2019_2 = resize_image(sent2_2019_2.copy(), sent2_2019_1.shape[0], sent2_2019_1.shape[1])\n","    sent2_2019 = np.concatenate((sent2_2019_1, sent2_2019_2), axis=-1)\n","    del sent2_2019_1, sent2_2019_2\n","    \n","    # Filter outliers\n","    sent2_2018 = filter_outliers(sent2_2018.copy()) \n","    sent2_2019 = filter_outliers(sent2_2019.copy()) \n","    \n","    image_stack = np.concatenate((sent2_2018, sent2_2019), axis=-1)\n","    print('Image stack:', image_stack.shape)\n","    del sent2_2018, sent2_2019\n","\n","if img_type = 'S1':\n","    # Load images\n","    sar_2018_vh = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vh_2018.tif').astype('float32'), axis = -1)\n","    sar_2018_vv = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vv_2018.tif').astype('float32'), axis = -1)\n","    sar_2019_vh = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vh_2019.tif').astype('float32'), axis = -1)\n","    sar_2019_vv = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vv_2019.tif').astype('float32'), axis = -1)\n","    \n","    sar_2018 = np.concatenate((sar_2018_vh, sar_2018_vv), axis=-1)\n","    sar_2019 = np.concatenate((sar_2019_vh, sar_2019_vv), axis=-1)\n","    del sar_2018_vh, sar_2018_vv, sar_2019_vh, sar_2019_vv\n","    \n","    # Filter outliers\n","    sar_2018 = filter_outliers(sar_2018.copy()) \n","    sar_2019 = filter_outliers(sar_2019.copy()) \n","\n","    image_stack = np.concatenate((sar_2018, sar_2019), axis=-1)\n","    print('Image stack:', image_stack.shape)\n","    del sar_2018, sar_2019\n","\n","# load references     \n","# Load current reference \n","ref_2019 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2019.tif').astype('float32') # actual 2019\n","# Load past references\n","#past_ref = np.load(root_path+'New_Images/References/past_ref_and_clouds.npy').astype('float32')\n","past_ref1 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_1988_2007.tif').astype('float32') # 1988_2007\n","past_ref2 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2008_2018.tif').astype('float32') # 2008_2018\n","clouds_2018 = load_tif_image(root_path+'New_Images/References/cut_b10_2018.tif').astype('float32')\n","clouds_2018 = resize_image(np.expand_dims(clouds_2018.copy(), axis = -1), ref_2019.shape[0], ref_2019.shape[1])\n","clouds_2018 = binary_mask_cloud(clouds_2018.copy(), 50)\n","clouds_2019 = load_tif_image(root_path+'New_Images/References/cut_b10_2019.tif').astype('float32') \n","clouds_2019 = resize_image(np.expand_dims(clouds_2019.copy(), axis = -1), ref_2019.shape[0], ref_2019.shape[1])\n","clouds_2019 = binary_mask_cloud(clouds_2019.copy(), 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYCYON3Vtgd4"},"source":["# Create label mask\n","past_ref = past_ref1 + past_ref2 + clouds_2018 + clouds_2019\n","past_ref[past_ref>=1] = 1\n","buffer = 2\n","final_mask1 = mask_no_considered(ref_2019, buffer, past_ref)\n","del past_ref1, past_ref2, clouds_2018, clouds_2019\n","\n","lim_x = 10000\n","lim_y = 7000\n","image_stack = image_stack[:lim_x, :lim_y, :]\n","final_mask1 = final_mask1[:lim_x, :lim_y]\n","ref_2019 = ref_2019[:lim_x, :lim_y]\n","\n","h_, w_, channels = image_stack.shape\n","print('image stack size: ', image_stack.shape)\n","\n","# Normalization\n","type_norm = 1\n","image_array = normalization(image_stack.copy(), type_norm)\n","print(np.min(image_array), np.max(image_array))\n","del image_stack\n","\n","# Print pertengate of each class (whole image)\n","print('Total no-deforestaion class is {}'.format(len(final_mask1[final_mask1==0])))\n","print('Total deforestaion class is {}'.format(len(final_mask1[final_mask1==1])))\n","print('Total past deforestaion class is {}'.format(len(final_mask1[final_mask1==1])))\n","print('Percentage of deforestaion class is {:.2f}'.format((len(final_mask1[final_mask1==1])*100)/len(final_mask1[final_mask1==0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knelmZc2HRTO"},"source":["# Create tile mask\n","mask_tiles = create_mask(final_mask1.shape[0], final_mask1.shape[1], grid_size=(5, 4))\n","image_array = image_array[:mask_tiles.shape[0], :mask_tiles.shape[1],:]\n","final_mask1 = final_mask1[:mask_tiles.shape[0], :mask_tiles.shape[1]]\n","\n","print('mask: ',mask_tiles.shape)\n","print('image stack: ', image_array.shape)\n","print('ref :', final_mask1.shape)\n","#plt.imshow(mask_tiles)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8Goel6oxPA2"},"source":["plt.figure(figsize=(10,5))\r\n","plt.imshow(final_mask1, cmap = 'jet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKaXQmmGoxLz"},"source":["# Define tiles for training, validation, and test sets\n","tiles_tr = [1,3,5,8,11,13,14,20]\n","tiles_val = [6,19]\n","tiles_ts = (list(set(np.arange(20)+1)-set(tiles_tr)-set(tiles_val)))\n","\n","mask_tr_val = np.zeros((mask_tiles.shape)).astype('float32')\n","# Training and validation mask\n","for tr_ in tiles_tr:\n","    mask_tr_val[mask_tiles == tr_] = 1\n","\n","for val_ in tiles_val:\n","    mask_tr_val[mask_tiles == val_] = 2\n","\n","mask_amazon_ts = np.zeros((mask_tiles.shape)).astype('float32')\n","for ts_ in tiles_ts:\n","    mask_amazon_ts[mask_tiles == ts_] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QI8Gc-NQrr44"},"source":["# Create ixd image to extract patches\n","overlap = 0.7\n","patch_size = 128\n","batch_size = 32\n","im_idx = create_idx_image(final_mask1)\n","patches_idx = extract_patches(im_idx, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1,patch_size, patch_size)\n","patches_mask = extract_patches(mask_tr_val, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1, patch_size, patch_size)\n","del im_idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1V39Gf4owRBa"},"source":["# Selecting index trn val and test patches idx\n","idx_trn = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==patch_size**2))\n","idx_val = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==2*patch_size**2))\n","\n","patches_idx_trn = patches_idx[idx_trn]\n","patches_idx_val = patches_idx[idx_val]\n","\n","print('Number of training patches:  ', len(patches_idx_trn), 'Number of validation patches', len(patches_idx_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycpxzOJblJvr"},"source":["X_train = retrieve_idx_percentage(final_mask1, patches_idx_trn, pertentage = 2)\n","X_valid = retrieve_idx_percentage(final_mask1, patches_idx_val, pertentage = 2)\n","print(X_train.shape, X_valid.shape)\n","del patches_idx_trn, patches_idx_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpchvB9nZOmC"},"source":["def batch_generator(batches, image, reference, target_size, number_class, n_bands):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    image = image.reshape(-1, image.shape[-1])\n","    reference = reference.reshape(final_mask1.shape[0]*final_mask1.shape[1])\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_x = np.squeeze(batch_x.astype('int64'), axis = -1)\n","        #print(batch_x.shape)\n","        batch_img = np.zeros((batch_x.shape[0], target_size, target_size, image.shape[-1]))\n","        batch_ref = np.zeros((batch_x.shape[0], target_size, target_size, 1))\n","        \n","        for i in range(batch_x.shape[0]):\n","            if np.random.rand()>0.5:\n","                batch_x[i] = np.rot90(batch_x[i], 1)\n","            batch_img[i] = image[batch_x[i]] \n","            #batch_ref[i] = tf.keras.utils.to_categorical(reference[batch_x[i]] , number_class)\n","            batch_ref[i] = reference[np.expand_dims(batch_x[i], axis = -1)]\n","                       \n","        yield batch_img[:,:,:,:n_bands//2], batch_img[:,:,:,n_bands//2:], batch_ref\n","\n","def plot_images(img_t0, img_t1, distance, reference, figsize=(10, 5)):\n","    fig = plt.figure(figsize=figsize)\n","    x0 = img_t0[0,:,:,3:0:-1]\n","    x0 = (x0-np.min(x0))/(np.max(x0)-np.min(x0))\n","    x1 = img_t1[0,:,:,3:0:-1]\n","    x1 = (x1-np.min(x1))/(np.max(x1)-np.min(x1))\n","\n","    ax1 = fig.add_subplot(141)\n","    plt.title('Image T0')\n","    ax1.imshow(x0)\n","    ax1.axis('off')\n","\n","    ax2 = fig.add_subplot(142)\n","    plt.title('Image T1')\n","    ax2.imshow(x1)\n","    ax2.axis('off')\n","\n","    ax3 = fig.add_subplot(143)\n","    plt.title('Distance')\n","    ax3.imshow(distance[0,:,:])\n","    ax3.axis('off')\n","    \n","    ax4 = fig.add_subplot(144)\n","    plt.title('Reference')\n","    ax4.imshow(reference[0,:,:])\n","    ax4.axis('off')\n","\n","    plt.show()\n","    # fig.savefig(save_img_path+name+'_img_pt_br_2_elastic_'+str(epoch))\n","    plt.close() \n","\n","train_datagen = ImageDataGenerator(horizontal_flip = True,\n","                                   vertical_flip = True)\n","valid_datagen = ImageDataGenerator(horizontal_flip = True, \n","                                   vertical_flip = True)\n","\n","y_train = np.zeros((len(X_train)))\n","y_valid = np.zeros((len(X_valid)))\n","\n","train_gen = train_datagen.flow(np.expand_dims(X_train, axis = -1), y_train,\n","                              batch_size=batch_size,\n","                              shuffle=True)\n","\n","valid_gen = valid_datagen.flow(np.expand_dims(X_valid, axis = -1), y_valid,\n","                              batch_size=batch_size,\n","                              shuffle=False)\n","\n","number_class = 3\n","train_gen_batch = batch_generator(train_gen, image_array, final_mask1, patch_size, number_class, channels)\n","valid_gen_batch = batch_generator(valid_gen, image_array, final_mask1, patch_size, number_class, channels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfJK-atSgFTG"},"source":["exp = 3\n","path_exp = root_path+'experiments/exp'+str(exp)\n","path_models = path_exp+'/models'\n","path_maps = path_exp+'/pred_maps'\n","\n","if not os.path.exists(path_exp):\n","    os.makedirs(path_exp)   \n","if not os.path.exists(path_models):\n","    os.makedirs(path_models)   \n","if not os.path.exists(path_maps):\n","    os.makedirs(path_maps)\n","    \n","name = 'siamese'\n","times = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5yETDgPtgd_"},"source":["metrics_all = []\n","\n","## computation graph\n","K.clear_session()\n","# parameters\n","\n","input_shape_enc = (patch_size, patch_size, channels//2)\n","input_shape_dec = (patch_size, patch_size, 1)\n","\n","img_size, img_size, cdims = input_shape_enc\n","lr = 1e-3\n","\n","# network definition\n","encoder = build_base_encoder(input_shape_enc)\n","encoder.summary()\n","decoder = build_base_decoder(input_shape_dec)\n","decoder.summary()\n","\n","img_a = K.placeholder(dtype=tf.float32, name=\"img_a\", shape=(batch_size, img_size, img_size, cdims))\n","img_b = K.placeholder(dtype=tf.float32, name=\"img_b\", shape=(batch_size, img_size, img_size, cdims))\n","y_true = K.placeholder(dtype=tf.float32, name=\"y_true\", shape=(batch_size, img_size, img_size, 1))\n","\n","[feat1_a, feat2_a, feat3_a, feat4_a] = encoder(img_a)\n","[feat1_b, feat2_b, feat3_b, feat4_b] = encoder(img_b)\n","\n","distance1 = euclidean_distance(feat4_a, feat4_b)\n","\n","distance = decoder([distance1, feat1_a, feat2_a, feat3_a, feat1_b, feat2_b, feat3_b])\n","\n","loss = contrastive_loss(y_true, distance, weights)\n","\n","t_vars = tf.trainable_variables()\n","net_vars = [var for var in t_vars if '_net' in var.name]\n","optim = tf.train.AdamOptimizer(lr).minimize(loss, var_list=net_vars)\n","\n","sess = K.get_session()\n","\n","init_op = tf.variables_initializer(net_vars)\n","\n","# **************\n","for tm in range(0,times):\n","    print('time: ', tm)\n","    \n","    sess.run(tf.global_variables_initializer())\n","    # print(net_vars)\n","\n","    num_of_trn_batches = len(X_train) // batch_size\n","    num_of_val_batches = len(X_valid) // batch_size\n","    epochs = 100\n","    best_val_loss = np.inf\n","    # train the model\n","   \n","    for epoch in range(epochs):\n","        print('epoch :', epoch)\n","        trn_loss, trn_acc, t_dist = [], [], []\n","        start_time = time.time()\n","        for idx in range(0, num_of_trn_batches):\n","\n","            # selecting a batch of images\n","            batch_t0, batch_t1, batch_ref = next(train_gen_batch)\n","            if batch_t0.shape[0] != batch_size:\n","                continue\n","\n","            feed_dict={img_a: batch_t0, img_b: batch_t1, y_true: batch_ref}\n","\n","            sess.run([optim], feed_dict=feed_dict)\n","\n","            with sess.as_default():\n","                t_loss = loss.eval(feed_dict)\n","                #print('loss', t_loss)\n","                t_distance = distance.eval(feed_dict)\n","                trn_loss.append(t_loss)\n","                t_acc_cpu = accuracy_cpu(batch_ref, t_distance)\n","                trn_acc.append(t_acc_cpu)\n","                t_dist.append(t_distance)             \n","\n","        # Evaluating model on validation,\n","        val_loss, val_acc, v_dist = [], [], []\n","        for _ in range(0, num_of_val_batches):\n","            batch_t0, batch_t1, batch_ref = next(valid_gen_batch)\n","            if batch_t0.shape[0] != batch_size:\n","                continue\n","            feed_dict={img_a: batch_t0, img_b: batch_t1, y_true: batch_ref}\n","            with sess.as_default():\n","                v_loss = loss.eval(feed_dict)\n","                v_distance = distance.eval(feed_dict)\n","                val_loss.append(v_loss)\n","                v_acc_cpu = accuracy_cpu(batch_ref, v_distance)\n","                val_acc.append(v_acc_cpu)\n","                v_dist.append(v_distance) \n","\n","        if best_val_loss > np.mean(val_loss):\n","            patience = 10\n","            best_val_loss = np.mean(val_loss)\n","            print('Saving best model and checkpoints')\n","            save_model(encoder, path_models +'/'+'net_enc_'+str(tm)+'.h5')\n","            save_model(decoder, path_models +'/'+'net_dec_'+str(tm)+'.h5')\n","            # Save the variables to disk.\n","            print('Ok')\n","        else:\n","            patience -= 1\n","        if patience < 0:\n","            break\n","\n","        elapsed_time = time.time() - start_time\n","        print('loss trn: ', np.mean(trn_loss), 'Acc trn: ', np.mean(trn_acc), 'loss val: ', np.mean(val_loss), 'Acc val: ', np.mean(val_acc))\n","        [feat1_a, feat2_a, feat3_a, feat4_a] = encoder.predict(batch_t0)\n","        [feat1_b, feat2_b, feat3_b, feat4_b] = encoder.predict(batch_t1)        \n","        dist = euclidean_distance_np(feat4_a, feat4_b)\n","        up_distance = decoder.predict([dist, feat1_a, feat2_a, feat3_a, feat1_b, feat2_b, feat3_b])\n","        plot_images(batch_t0, batch_t1, up_distance, batch_ref)\n","    \n","    metrics_all.append(elapsed_time)\n","\n","np.save(path_exp+'/metrics_tr.npy', metrics_all)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znNh_qh3OHd-"},"source":["metrics_ts = []\n","n_pool = 3\n","n_rows = 7\n","n_cols = 5\n","rows, cols = image_array.shape[:2]\n","pad_rows = rows - np.ceil(rows/(n_rows*2**n_pool))*n_rows*2**n_pool\n","pad_cols = cols - np.ceil(cols/(n_cols*2**n_pool))*n_cols*2**n_pool\n","print(pad_rows, pad_cols)\n","\n","npad = ((0, int(abs(pad_rows))), (0, int(abs(pad_cols))), (0, 0))\n","image1_pad = np.pad(image_array, pad_width=npad, mode='reflect')\n","\n","h, w, c = image1_pad.shape\n","patch_size_rows = h//n_rows\n","patch_size_cols = w//n_cols\n","num_patches_x = int(h/patch_size_rows)\n","num_patches_y = int(w/patch_size_cols)\n","\n","new_enc = build_base_encoder((patch_size_rows, patch_size_cols, channels//2))\n","new_dec = build_base_decoder((patch_size_rows, patch_size_cols, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XgM3bawtgeA"},"source":["metrics_all =[]\n","\n","for tm in range(0,times):\n","    print('time: ', tm)\n","    \n","    model = load_model(path_models+'/'+'net_enc_'+str(tm)+'.h5', compile=False)\n","    for l in range(1, len(model.layers)):\n","        new_enc.layers[l].set_weights(model.layers[l].get_weights())\n","\n","    dec_model = load_model(path_models +'/'+'net_dec_'+str(tm)+'.h5', compile=False)\n","    for l in range(1, len(dec_model.layers)):\n","        new_dec.layers[l].set_weights(dec_model.layers[l].get_weights())\n","    \n","    start_test = time.time()\n","    patch_t = []\n","\n","    for i in range(0,num_patches_y):\n","        for j in range(0,num_patches_x):\n","            patch = image1_pad[patch_size_rows*j:patch_size_rows*(j+1), patch_size_cols*i:patch_size_cols*(i+1), :]\n","            [pred1_a, pred2_a, pred3_a, pred4_a] = new_enc.predict(np.expand_dims(patch[:,:,:channels//2], axis=0))\n","            [pred1_b, pred2_b, pred3_b, pred4_b] = new_enc.predict(np.expand_dims(patch[:,:,channels//2:], axis=0))\n","            dist = euclidean_distance_np(pred4_a, pred4_b)\n","            up_distance = new_dec.predict([dist, pred1_a, pred2_a, pred3_a, pred1_b, pred2_b, pred3_b])\n","            print(up_distance.shape)\n","            del patch \n","            patch_t.append(up_distance[:,:,:,0])\n","            del dist\n","    ts_time =  time.time() - start_test\n","    metrics_all.append(ts_time)\n","    patches_pred = np.asarray(patch_t).astype(np.float32)\n","    \n","    prob_recontructed = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred)\n","    np.save(path_maps+'/'+'prob_'+str(tm)+'.npy',prob_recontructed) \n","\n","    del prob_recontructed, model, patches_pred\n","metrics_ = np.asarray(metrics_all)\n","np.save(path_exp+'/metrics_ts.npy', metrics_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59iG3gs7tgeA"},"source":["prob_rec = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n","\n","for tm in range (0, times):\n","    print(tm)\n","    prob_rec[:,:,tm] = np.load(path_maps+'/'+'prob_'+str(tm)+'.npy').astype(np.float32)\n","\n","mean_prob = np.mean(prob_rec, axis = -1)\n","np.save(path_maps+'/prob_mean.npy', mean_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrkzaTxFtgeB"},"source":["# Plot mean map and reference\n","fig = plt.figure(figsize=(10,15))\n","ax1 = fig.add_subplot(121)\n","plt.title('Prediction')\n","plt.imshow(mean_prob, cmap ='jet')\n","ax1.axis('off')\n","\n","ax2 = fig.add_subplot(122)\n","plt.title('Reference')\n","plt.imshow(ref_2019, cmap ='jet')\n","ax2.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fu8MjC_atgeB"},"source":["# Computing metrics\n","mean_prob = mean_prob[:final_mask1.shape[0], :final_mask1.shape[1]]\n","ref1 = np.ones_like(final_mask1).astype(np.float32)\n","\n","ref1 [final_mask1 == 2] = 0\n","TileMask = mask_amazon_ts * ref1\n","GTTruePositives = final_mask1==1\n","    \n","Npoints = 50\n","Pmax = np.max(mean_prob[GTTruePositives * TileMask ==1])\n","Pmin = np.min(mean_prob[GTTruePositives * TileMask ==1])\n","ProbList = np.linspace(Pmax,Pmin,Npoints)\n"," \n","metrics_ = matrics_AA_recall(ProbList, mean_prob, final_mask1, mask_amazon_ts, 625)\n","np.save(path_exp+'/acc_metrics.npy',metrics_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-f6njabUtgeB"},"source":["#  Complete NaN values\n","metrics_copy = metrics_.copy()\n","metrics_copy = complete_nan_values(metrics_copy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-VLNS9-tgeC"},"source":["# Comput Mean Average Precision (mAP) score \n","Recall = metrics_copy[:,0]\n","Precision = metrics_copy[:,1]\n","AA = metrics_copy[:,2]\n","    \n","DeltaR = Recall[1:]-Recall[:-1]\n","AP = np.sum(Precision[:-1]*DeltaR)\n","print('mAP', AP)\n","\n","# Plot Recall vs. Precision curve\n","plt.close('all')\n","plt.plot(metrics_copy[:,0],metrics_copy[:,1])\n","plt.plot(metrics_copy[:,0],metrics_copy[:,2])\n","plt.grid()"],"execution_count":null,"outputs":[]}]}